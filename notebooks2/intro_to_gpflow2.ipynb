{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPflow with TF2.0\n",
    "===\n",
    "\n",
    "##### Small steps big changes\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "\n",
    "from gpflow.config import default_float\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make `tensorbord` work inside notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_logdir = \"/tmp/tensorboard\"\n",
    "\n",
    "!rm -rf \"{output_logdir}\"\n",
    "!mkdir \"{output_logdir}\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def enumerated_logdir(_logdir_id: int = [0]):\n",
    "    logdir = Path(output_logdir, str(_logdir_id[0]))\n",
    "    _logdir_id[0] += 1\n",
    "    return str(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup random seeds and default float for `gpflow` tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpflow.config.set_default_float(np.float64)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data using TensorFlow Datasets\n",
    "\n",
    "For this example, we create a synthetic dataset (noisy sine function) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def noisy_sin(x): \n",
    "    return tf.math.sin(x) + 0.1 * tf.random.normal(x.shape, dtype=default_float())\n",
    "\n",
    "num_train_data, num_test_data = 100, 500\n",
    "\n",
    "X = tf.random.uniform((num_train_data, 1), dtype=default_float()) * 10\n",
    "Xtest = tf.random.uniform((num_test_data, 1), dtype=default_float()) * 10\n",
    "\n",
    "Y = noisy_sin(X)\n",
    "Ytest = noisy_sin(Xtest)\n",
    "\n",
    "plt.plot(X, Y, 'xk')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Tensorflow Datasets is an efficient way to rapidly shuffle, iterate and batch from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 09:44:28.191930 4664387008 deprecation.py:323] From /Users/artemav/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/data/util/random_seed.py:58: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prefetch_size=50\n",
      "shuffle_buffer_size=50\n",
      "num_batches_per_epoch=3\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((Xtest, Ytest))\n",
    "\n",
    "batch_size = 32\n",
    "num_features = 10\n",
    "prefetch_size = num_train_data // 2\n",
    "shuffle_buffer_size = num_train_data // 2\n",
    "num_batches_per_epoch = num_train_data // batch_size\n",
    "\n",
    "original_train_dataset = train_dataset\n",
    "train_dataset = train_dataset.repeat()\\\n",
    "                    .prefetch(prefetch_size)\\\n",
    "                    .shuffle(buffer_size=shuffle_buffer_size)\\\n",
    "                    .batch(batch_size)\n",
    "\n",
    "print(f\"prefetch_size={prefetch_size}\")\n",
    "print(f\"shuffle_buffer_size={shuffle_buffer_size}\")\n",
    "print(f\"num_batches_per_epoch={num_batches_per_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a GP model\n",
    "\n",
    "In GPflow2.0, we use `tf.Module` to build all our models, as well as, their components (kernels, likelihoods, parameters, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gpflow.kernels.RBF(variance=2.)\n",
    "likelihood = gpflow.likelihoods.Gaussian()\n",
    "features = np.linspace(0, 10, num_features).reshape(-1, 1)\n",
    "\n",
    "model = gpflow.models.SVGP(kernel=kernel, likelihood=likelihood, inducing_variables=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set a module (or a particular parameter) to be non-trainable using the auxiliary method ```set_trainable(module, False)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpflow.utilities import set_trainable\n",
    "\n",
    "set_trainable(likelihood, False)\n",
    "set_trainable(kernel.variance, False)\n",
    "\n",
    "set_trainable(likelihood, True)\n",
    "set_trainable(kernel.variance, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ```param.assign(value)``` to assign a value to a parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.lengthscale.assign(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these changes are reflected when we use ```print_summary(model)``` to print a detailed summary of the model. By default the output will be displayed in minimalistic and simple table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                       class      transform       trainable    shape        dtype    value\n",
      "-------------------------  ---------  --------------  -----------  -----------  -------  ----------------\n",
      "SVGP.kernel.variance       Parameter  Softplus        False        ()           float64  2.0\n",
      "SVGP.kernel.lengthscale    Parameter  Softplus        True         ()           float64  0.5\n",
      "SVGP.likelihood.variance   Parameter  Softplus        False        ()           float64  1.0\n",
      "SVGP.inducing_variables.Z  Parameter                  True         (10, 1)      float64  [[0....\n",
      "SVGP.q_mu                  Parameter                  True         (10, 1)      float64  [[0....\n",
      "SVGP.q_sqrt                Parameter  FillTriangular  True         (1, 10, 10)  float64  [[[1., 0., 0....\n"
     ]
    }
   ],
   "source": [
    "from gpflow.utilities import print_summary\n",
    "\n",
    "print_summary(model)  # same as print_summary(model, fmt=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change default printing so that it will look more nicely in our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>name                     </th><th>class    </th><th>transform     </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value           </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SVGP.kernel.variance     </td><td>Parameter</td><td>Softplus      </td><td>False      </td><td>()         </td><td>float64</td><td>2.0             </td></tr>\n",
       "<tr><td>SVGP.kernel.lengthscale  </td><td>Parameter</td><td>Softplus      </td><td>True       </td><td>()         </td><td>float64</td><td>0.5             </td></tr>\n",
       "<tr><td>SVGP.likelihood.variance </td><td>Parameter</td><td>Softplus      </td><td>False      </td><td>()         </td><td>float64</td><td>1.0             </td></tr>\n",
       "<tr><td>SVGP.inducing_variables.Z</td><td>Parameter</td><td>              </td><td>True       </td><td>(10, 1)    </td><td>float64</td><td>[[0....         </td></tr>\n",
       "<tr><td>SVGP.q_mu                </td><td>Parameter</td><td>              </td><td>True       </td><td>(10, 1)    </td><td>float64</td><td>[[0....         </td></tr>\n",
       "<tr><td>SVGP.q_sqrt              </td><td>Parameter</td><td>FillTriangular</td><td>True       </td><td>(1, 10, 10)</td><td>float64</td><td>[[[1., 0., 0....</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpflow.config.set_summary_fmt(\"notebook\")\n",
    "\n",
    "print_summary(model)  # same as print_summary(model, fmt=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using Gradient Tapes\n",
    "\n",
    "In TensorFlow2.0, we can optimise (trainable) model parameters with Tensorflow optimizers using GradientTapes. In this simple example, we perform one gradient update of the Adam optimizer to minimize the negative marginal log likelihood (or ELBO) of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(model.trainable_variables)\n",
    "    elbo = model.elbo(X, Y)\n",
    "    grads = tape.gradient(elbo, model.trainable_variables)\n",
    "    \n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more elaborare example of a gradient update we can define an ```optimization_step``` that uses decorator ```tf.function``` on a closure. A closure is callable that returns the model objective evaluated at a given dataset when called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_step(model: gpflow.models.SVGP, batch: Tuple[tf.Tensor, tf.Tensor]):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "        tape.watch(model.trainable_variables)\n",
    "        elbo = model.elbo(*batch)\n",
    "        grads = tape.gradient(elbo, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make use the functionality of TensorFlow Datasets to define a simple training loop that iterates over batches of the training dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_training_loop(model: gpflow.models.SVGP, epochs: int = 1, logging_epoch_freq: int = 10):\n",
    "    batches = iter(train_dataset)\n",
    "    tf_optimization_step = tf.function(optimization_step, autograph=False)\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(num_batches_per_epoch):\n",
    "            tf_optimization_step(model, next(batches))\n",
    "\n",
    "        epoch_id = epoch + 1\n",
    "        if epoch_id % logging_epoch_freq == 0:\n",
    "            tf.print(f\"Epoch {epoch_id}: ELBO (train) {model.elbo(X, Y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: ELBO (train) 212.29663302150476\n",
      "Epoch 4: ELBO (train) 211.04060658136456\n",
      "Epoch 6: ELBO (train) 209.76161048220303\n",
      "Epoch 8: ELBO (train) 208.46305694165406\n",
      "Epoch 10: ELBO (train) 207.13941719416468\n"
     ]
    }
   ],
   "source": [
    "simple_training_loop(model, epochs=10, logging_epoch_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring \n",
    "\n",
    "We can monitor the training procedure using TensorFlow summary. First we create a summary writer object under which we can write scalar and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intro_to_gpflow2_plotting import plotting_regression, summary_matplotlib_image\n",
    "\n",
    "samples_input = tf.cast(np.linspace(0, 10, 100).reshape(100, 1), default_float())\n",
    "\n",
    "def monitored_training_loop(model: gpflow.models.SVGP, logdir: str, \n",
    "                            epochs: int = 1, logging_epoch_freq: int = 10,\n",
    "                            num_samples: int = 10):\n",
    "    summary_writer = tf.summary.create_file_writer(logdir)\n",
    "    tf_optimization_step = tf.function(optimization_step)\n",
    "    batches = iter(train_dataset)\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        for epoch in range(epochs):\n",
    "            for _ in range(num_batches_per_epoch):\n",
    "                tf_optimization_step(model, next(batches))\n",
    "\n",
    "            epoch_id = epoch + 1\n",
    "            if epoch_id % logging_epoch_freq == 0:\n",
    "                tf.print(f\"Epoch {epoch_id}: ELBO (train) {model.elbo(X, Y)}\")\n",
    "\n",
    "                mean, var = model.predict_f(samples_input)\n",
    "                samples = model.predict_f_samples(samples_input, num_samples)\n",
    "                fig = plotting_regression(X, Y, samples_input, mean, var, samples)\n",
    "                \n",
    "                summary_matplotlib_image(dict(model_samples=fig), step=epoch)\n",
    "                tf.summary.scalar('elbo', data=model.elbo(X, Y), step=epoch)\n",
    "                tf.summary.scalar('likelihood/variance', data=model.likelihood.variance, step=epoch)\n",
    "                tf.summary.scalar('kernel/lengthscale', data=model.kernel.lengthscale, step=epoch)\n",
    "                tf.summary.scalar('kernel/variance', data=model.kernel.variance, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100: ELBO (train) 144.1003268158425\n",
      "Epoch 200: ELBO (train) 118.73314230122062\n",
      "Epoch 300: ELBO (train) 111.3655437033495\n",
      "Epoch 400: ELBO (train) 108.96588488244478\n",
      "Epoch 500: ELBO (train) 107.86750152223229\n",
      "Epoch 600: ELBO (train) 107.16676225220195\n",
      "Epoch 700: ELBO (train) 106.64546597598033\n",
      "Epoch 800: ELBO (train) 106.24762543511272\n",
      "Epoch 900: ELBO (train) 105.9467871167052\n",
      "Epoch 1000: ELBO (train) 105.73645267771897\n"
     ]
    }
   ],
   "source": [
    "model = gpflow.models.SVGP(kernel=kernel, likelihood=likelihood, inducing_variables=features)\n",
    "\n",
    "output_logdir = enumerated_logdir()\n",
    "monitored_training_loop(model, output_logdir, epochs=1000, logging_epoch_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can then use TensorBoard to examine the training procedure more in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir \"{output_logdir}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing: saving and loading models\n",
    "\n",
    "With the help of `tf.train.CheckpointManager` and `tf.train.Checkpoint`, we can checkpoint the model throughout the training procedure. Let's start with a simple example using checkpointing to save and load `tf.Variables`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_value = 1.2\n",
    "a = tf.Variable(initial_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `Checkpoint` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(a=a)\n",
    "manager = tf.train.CheckpointManager(ckpt, output_logdir, max_to_keep=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save `a` variable and change its value right after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.save()\n",
    "_ = a.assign(0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can restore old variable value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current value of variable a: 0.330\n",
      "Value of variable a: 1.200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current value of variable a: {a.numpy():0.3f}\")\n",
    "\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "\n",
    "print(f\"Value of variable a: {a.numpy():0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example below, we modify a simple training loop to save the model every 100 epochs using the `CheckpointManager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gpflow.models.SVGP(kernel=kernel, likelihood=likelihood, inducing_variables=features)\n",
    "\n",
    "def checkpointing_training_loop(model: gpflow.models.SVGP,\n",
    "                                batch_size: int,\n",
    "                                epochs: int,\n",
    "                                manager: tf.train.CheckpointManager,\n",
    "                                logging_epoch_freq: int = 100,\n",
    "                                epoch_var: Optional[tf.Variable] = None,\n",
    "                                step_var: Optional[tf.Variable] = None):\n",
    "    tf_optimization_step = tf.function(optimization_step)\n",
    "    batches = iter(train_dataset)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for step in range(num_batches_per_epoch):\n",
    "            tf_optimization_step(model, next(batches))\n",
    "            if step_var is not None:\n",
    "                step_var.assign(epoch * num_batches_per_epoch + step + 1)\n",
    "        if epoch_var is not None:\n",
    "            epoch_var.assign(epoch + 1)\n",
    "            \n",
    "        epoch_id = epoch + 1\n",
    "        if epoch_id % logging_epoch_freq == 0:\n",
    "            ckpt_path = manager.save()\n",
    "            tf.print(f\"Epoch {epoch_id}: ELBO (train) {model.elbo(X, Y)}, saved at {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint folder path at: /tmp/tensorboard/0\n",
      "Epoch 100: ELBO (train) 107.12611073182977, saved at /tmp/tensorboard/0/ckpt-1\n",
      "Epoch 200: ELBO (train) 105.7096004606031, saved at /tmp/tensorboard/0/ckpt-2\n",
      "Epoch 300: ELBO (train) 105.50229957811227, saved at /tmp/tensorboard/0/ckpt-3\n",
      "Epoch 400: ELBO (train) 105.45306944316962, saved at /tmp/tensorboard/0/ckpt-4\n",
      "Epoch 500: ELBO (train) 105.44900530876282, saved at /tmp/tensorboard/0/ckpt-5\n",
      "Epoch 600: ELBO (train) 105.45458916465034, saved at /tmp/tensorboard/0/ckpt-6\n",
      "Epoch 700: ELBO (train) 105.46405124670649, saved at /tmp/tensorboard/0/ckpt-7\n",
      "Epoch 800: ELBO (train) 105.47239171116901, saved at /tmp/tensorboard/0/ckpt-8\n",
      "Epoch 900: ELBO (train) 105.48157117742376, saved at /tmp/tensorboard/0/ckpt-9\n",
      "Epoch 1000: ELBO (train) 105.48582543328294, saved at /tmp/tensorboard/0/ckpt-10\n"
     ]
    }
   ],
   "source": [
    "step_var = tf.Variable(1, dtype=tf.int32, trainable=False)\n",
    "epoch_var = tf.Variable(1, dtype=tf.int32, trainable=False)\n",
    "ckpt = tf.train.Checkpoint(model=model, step=step_var, epoch=epoch_var)\n",
    "manager = tf.train.CheckpointManager(ckpt, output_logdir, max_to_keep=5)\n",
    "\n",
    "print(f\"Checkpoint folder path at: {output_logdir}\")\n",
    "\n",
    "checkpointing_training_loop(model, batch_size=batch_size, epochs=1000, manager=manager, epoch_var=epoch_var, step_var=step_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the models have been saved, we can resore them using ```tf.train.Checkpoint.restore``` and assert their performance corresponds to the logs during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 restored model from epoch 600 [step:1800] : ELBO training set 105.45458916465034\n",
      "1 restored model from epoch 700 [step:2100] : ELBO training set 105.46405124670649\n",
      "2 restored model from epoch 800 [step:2400] : ELBO training set 105.47239171116901\n",
      "3 restored model from epoch 900 [step:2700] : ELBO training set 105.48157117742376\n",
      "4 restored model from epoch 1000 [step:3000] : ELBO training set 105.48582543328294\n"
     ]
    }
   ],
   "source": [
    "for i, recorded_checkpoint in enumerate(manager.checkpoints):\n",
    "    ckpt.restore(recorded_checkpoint)\n",
    "    print(f\"{i} restored model from epoch {int(epoch_var)} [step:{int(step_var)}] : ELBO training set {model.elbo(X, Y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
