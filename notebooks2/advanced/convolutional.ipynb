{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Gaussian Processes\n",
    "Mark van der Wilk (July 2019)\n",
    "\n",
    "Here we show a simple example of the rectangles experiment, where we compare a normal SE GP, and a convolutional GP. This is similar to the experiment in [1].\n",
    "\n",
    "[1] Van der Wilk, Rasmussen, Hensman (2017). Convolutional Gaussian Processes. *Advances in Neural Information Processing Systems 30*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset\n",
    "Generate a simple dataset of rectangles. We want to classify whether they are tall or wide. Note that here we take some care to make sure that the rectangles don't touch the edge, which is different to the original paper. We do this to avoid needing to use patch weights, which are needed to correctly account for edge effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import os\n",
    "\n",
    "gpflow.config.set_default_float(np.float64)\n",
    "gpflow.config.set_default_jitter(1e-4)\n",
    "gpflow.config.set_summary_fmt(\"notebook\")\n",
    "\n",
    "def is_continuous_integration():\n",
    "    return os.environ.get('CI', None) is not None\n",
    "\n",
    "MAXITER = 2 if is_continuous_integration() else 1000\n",
    "NUM_TRAIN_DATA = 3 if is_continuous_integration() else 100\n",
    "NUM_TEST_DATA = 7 if is_continuous_integration() else 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rectangle(arr, x0, y0, x1, y1):\n",
    "    arr[y0:y1, x0] = 1\n",
    "    arr[y0:y1, x1] = 1\n",
    "    arr[y0, x0:x1] = 1\n",
    "    arr[y1, x0:x1+1] = 1\n",
    "    \n",
    "def make_random_rectangle(arr):\n",
    "    x0 = np.random.randint(1, arr.shape[1] - 3)\n",
    "    y0 = np.random.randint(1, arr.shape[0] - 3)\n",
    "    x1 = np.random.randint(x0 + 2, arr.shape[1] - 1)\n",
    "    y1 = np.random.randint(y0 + 2, arr.shape[0] - 1)\n",
    "    make_rectangle(arr, x0, y0, x1, y1)\n",
    "    return x0, y0, x1, y1\n",
    "    \n",
    "def make_rectangles_dataset(num, w, h):\n",
    "    d, Y = np.zeros((num, h, w)), np.zeros((num, 1))\n",
    "    for i, img in enumerate(d):\n",
    "        for j in range(1000):  # Finite number of tries tries\n",
    "            x0, y0, x1, y1 = make_random_rectangle(img)\n",
    "            rw, rh = y1 - y0, x1 - x0\n",
    "            if rw == rh:\n",
    "                img[:, :] = 0\n",
    "                continue\n",
    "            Y[i, 0] = rw > rh\n",
    "            break\n",
    "    return d.reshape(num, w * h).astype(gpflow.config.default_float()), Y.astype(gpflow.config.default_float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_rectangles_dataset(NUM_TRAIN_DATA, 28, 28)\n",
    "Xt, Yt = make_rectangles_dataset(NUM_TEST_DATA, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(X[i, :].reshape(28, 28))\n",
    "    plt.title(Y[i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squared Exponential kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_m = gpflow.models.SVGP(gpflow.kernels.SquaredExponential(), gpflow.likelihoods.Bernoulli(),\n",
    "                           gpflow.inducing_variables.InducingPoints(X.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF elbo before training: -9.94e+01\n"
     ]
    }
   ],
   "source": [
    "rbf_m_log_likelihood = rbf_m.log_likelihood\n",
    "print(\"RBF elbo before training: %.2e\" % rbf_m_log_likelihood(X, Y))\n",
    "rbf_m_log_likelihood = tf.function(rbf_m_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.621 iter/s\n"
     ]
    }
   ],
   "source": [
    "gpflow.utilities.set_trainable(rbf_m.inducing_variables, False)\n",
    "start_time = time.time()\n",
    "res = gpflow.optimizers.Scipy().minimize(lambda: -rbf_m_log_likelihood(X, Y), variables=rbf_m.trainable_variables,\n",
    "                                         method=\"l-bfgs-b\", options={\"disp\": True, \"maxiter\": MAXITER})\n",
    "print(f\"{res.nfev / (time.time() - start_time):.3f} iter/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err = np.mean((rbf_m.predict_y(X)[0] > 0.5).numpy().astype('float') == Y)\n",
    "test_err = np.mean((rbf_m.predict_y(Xt)[0] > 0.5).numpy().astype('float') == Yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 100.0%\n",
      "Test acc : 62.0%\n",
      "RBF elbo after training: -6.60e+01\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train acc: {train_err * 100}%\\nTest acc : {test_err*100}%\")\n",
    "print(\"RBF elbo after training: %.2e\" % rbf_m_log_likelihood(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f64 = lambda x: np.array(x, dtype=np.float64)\n",
    "positive_with_min = lambda: tfp.bijectors.AffineScalar(shift=f64(1e-4))(tfp.bijectors.Softplus())\n",
    "constrained = lambda: tfp.bijectors.AffineScalar(shift=f64(1e-4), scale=f64(100.0))(tfp.bijectors.Sigmoid())\n",
    "conv_k = gpflow.kernels.Convolutional(gpflow.kernels.SquaredExponential(), [28, 28], [3, 3])\n",
    "conv_k.basekern.lengthscale = gpflow.Parameter(1.0, transform=positive_with_min())\n",
    "conv_k.basekern.variance = gpflow.Parameter(1.0, transform=constrained())\n",
    "conv_f = gpflow.inducing_variables.InducingPatches(np.unique(conv_k.get_patches(X).numpy().reshape(-1, 9), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_m = gpflow.models.SVGP(conv_k, gpflow.likelihoods.Bernoulli(), conv_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpflow.utilities.set_trainable(conv_m.inducing_variables, False)\n",
    "conv_m.kernel.basekern.variance.trainable = False\n",
    "conv_m.kernel.weights.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv elbo before training: -9.38e+01\n"
     ]
    }
   ],
   "source": [
    "conv_m_log_likelihood = conv_m.log_likelihood\n",
    "print(\"conv elbo before training: %.2e\" % conv_m_log_likelihood(X, Y))\n",
    "conv_m_log_likelihood = tf.function(conv_m_log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "res = gpflow.optimizers.Scipy().minimize(lambda: -conv_m_log_likelihood(X, Y), variables=conv_m.trainable_variables,\n",
    "                                      method=\"l-bfgs-b\", options={\"disp\": True, \"maxiter\": MAXITER / 10})\n",
    "print(f\"{res.nfev / (time.time() - start_time):.3f} iter/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_m.kernel.basekern.variance.trainable = True\n",
    "start_time = time.time()\n",
    "res = gpflow.optimizers.Scipy().minimize(lambda: -conv_m.log_likelihood(X, Y), variables=conv_m.trainable_variables,\n",
    "                                      method=\"l-bfgs-b\", options={\"disp\": True, \"maxiter\": MAXITER})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train acc: {train_err * 100}%\\nTest acc : {test_err*100}%\")\n",
    "print(\"conv elbo after training: %.2e\" % conv_m_log_likelihood(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_m.kernel.weights.trainable = True\n",
    "start_time = time.time()\n",
    "res = gpflow.optimizers.Scipy().minimize(lambda: -conv_m.log_likelihood(X, Y), variables=conv_m.trainable_variables,\n",
    "                                      method=\"l-bfgs-b\", options={\"disp\": True, \"maxiter\": MAXITER})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_err = np.mean((conv_m.predict_y(X)[0] > 0.5).numpy().astype('float') == Y)\n",
    "test_err = np.mean((conv_m.predict_y(Xt)[0] > 0.5).numpy().astype('float') == Yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train acc: {train_err * 100}%\\nTest acc : {test_err*100}%\")\n",
    "print(\"conv elbo after training: %.2e\" % conv_m_log_likelihood(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpflow.utilities.print_summary(rbf_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpflow.utilities.print_summary(conv_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The convolutional kernel performs much better in this simple task. It demonstrates non-local generalisation of the strong assumptions in the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
