{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPflow with TF2.0\n",
    "===\n",
    "\n",
    "##### Small steps big changes\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "import datetime\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gpflow\n",
    "\n",
    "from gpflow.config import default_float\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make `tensorbord` work inside notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_logdir = \"/tmp/tensorboard\"\n",
    "\n",
    "!rm -rf \"{output_logdir}\"\n",
    "!mkdir \"{output_logdir}\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def enumerated_logdir(_logdir_id: int = [0]):\n",
    "    logdir = Path(output_logdir, str(_logdir_id[0]))\n",
    "    _logdir_id[0] += 1\n",
    "    return str(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup random seeds and default float for `gpflow` tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpflow.config.set_default_float(np.float64)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data using TensorFlow Datasets\n",
    "\n",
    "For this example, we create a synthetic dataset (noisy sine function) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 380.482812 248.518125\" width=\"380.482812pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 248.518125 \nL 380.482812 248.518125 \nL 380.482812 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 38.482813 224.64 \nL 373.282813 224.64 \nL 373.282813 7.2 \nL 38.482813 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m36fb7da5db\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.492135\" xlink:href=\"#m36fb7da5db\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(48.310885 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"113.442279\" xlink:href=\"#m36fb7da5db\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(110.261029 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"175.392423\" xlink:href=\"#m36fb7da5db\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(172.211173 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"237.342566\" xlink:href=\"#m36fb7da5db\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(234.161316 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"299.29271\" xlink:href=\"#m36fb7da5db\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(296.11146 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"361.242854\" xlink:href=\"#m36fb7da5db\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(354.880354 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mbfceced6ee\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mbfceced6ee\" y=\"203.389785\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- −1.0 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 207.189004)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mbfceced6ee\" y=\"161.684092\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- −0.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 165.483311)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mbfceced6ee\" y=\"119.978399\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.0 -->\n      <g transform=\"translate(15.579688 123.777618)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mbfceced6ee\" y=\"78.272706\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.5 -->\n      <g transform=\"translate(15.579688 82.071925)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#mbfceced6ee\" y=\"36.567013\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.0 -->\n      <g transform=\"translate(15.579688 40.366232)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <defs>\n     <path d=\"M -3 3 \nL 3 -3 \nM -3 -3 \nL 3 3 \n\" id=\"m202792f693\" style=\"stroke:#000000;\"/>\n    </defs>\n    <g clip-path=\"url(#p3132a18d32)\">\n     <use style=\"stroke:#000000;\" x=\"155.506993\" xlink:href=\"#m202792f693\" y=\"143.045336\"/>\n     <use style=\"stroke:#000000;\" x=\"139.190626\" xlink:href=\"#m202792f693\" y=\"87.179899\"/>\n     <use style=\"stroke:#000000;\" x=\"154.761779\" xlink:href=\"#m202792f693\" y=\"148.230018\"/>\n     <use style=\"stroke:#000000;\" x=\"344.454773\" xlink:href=\"#m202792f693\" y=\"128.89027\"/>\n     <use style=\"stroke:#000000;\" x=\"229.252298\" xlink:href=\"#m202792f693\" y=\"160.557485\"/>\n     <use style=\"stroke:#000000;\" x=\"261.668628\" xlink:href=\"#m202792f693\" y=\"72.498489\"/>\n     <use style=\"stroke:#000000;\" x=\"230.544434\" xlink:href=\"#m202792f693\" y=\"164.736321\"/>\n     <use style=\"stroke:#000000;\" x=\"164.286722\" xlink:href=\"#m202792f693\" y=\"152.476411\"/>\n     <use style=\"stroke:#000000;\" x=\"147.671227\" xlink:href=\"#m202792f693\" y=\"118.561205\"/>\n     <use style=\"stroke:#000000;\" x=\"258.340169\" xlink:href=\"#m202792f693\" y=\"78.314735\"/>\n     <use style=\"stroke:#000000;\" x=\"125.236202\" xlink:href=\"#m202792f693\" y=\"65.120228\"/>\n     <use style=\"stroke:#000000;\" x=\"302.696578\" xlink:href=\"#m202792f693\" y=\"56.021112\"/>\n     <use style=\"stroke:#000000;\" x=\"187.452349\" xlink:href=\"#m202792f693\" y=\"210.70805\"/>\n     <use style=\"stroke:#000000;\" x=\"67.634175\" xlink:href=\"#m202792f693\" y=\"75.710376\"/>\n     <use style=\"stroke:#000000;\" x=\"176.312987\" xlink:href=\"#m202792f693\" y=\"180.849211\"/>\n     <use style=\"stroke:#000000;\" x=\"169.72497\" xlink:href=\"#m202792f693\" y=\"159.789464\"/>\n     <use style=\"stroke:#000000;\" x=\"154.016778\" xlink:href=\"#m202792f693\" y=\"132.753843\"/>\n     <use style=\"stroke:#000000;\" x=\"152.27451\" xlink:href=\"#m202792f693\" y=\"128.227379\"/>\n     <use style=\"stroke:#000000;\" x=\"263.807325\" xlink:href=\"#m202792f693\" y=\"85.455534\"/>\n     <use style=\"stroke:#000000;\" x=\"150.197839\" xlink:href=\"#m202792f693\" y=\"124.948722\"/>\n     <use style=\"stroke:#000000;\" x=\"293.260139\" xlink:href=\"#m202792f693\" y=\"35.474978\"/>\n     <use style=\"stroke:#000000;\" x=\"182.632878\" xlink:href=\"#m202792f693\" y=\"197.405259\"/>\n     <use style=\"stroke:#000000;\" x=\"316.938927\" xlink:href=\"#m202792f693\" y=\"57.227097\"/>\n     <use style=\"stroke:#000000;\" x=\"164.567681\" xlink:href=\"#m202792f693\" y=\"159.439258\"/>\n     <use style=\"stroke:#000000;\" x=\"207.493395\" xlink:href=\"#m202792f693\" y=\"186.278646\"/>\n     <use style=\"stroke:#000000;\" x=\"259.463208\" xlink:href=\"#m202792f693\" y=\"84.678371\"/>\n     <use style=\"stroke:#000000;\" x=\"224.715857\" xlink:href=\"#m202792f693\" y=\"158.562931\"/>\n     <use style=\"stroke:#000000;\" x=\"182.458485\" xlink:href=\"#m202792f693\" y=\"204.236094\"/>\n     <use style=\"stroke:#000000;\" x=\"248.505875\" xlink:href=\"#m202792f693\" y=\"116.600006\"/>\n     <use style=\"stroke:#000000;\" x=\"224.486141\" xlink:href=\"#m202792f693\" y=\"177.959486\"/>\n     <use style=\"stroke:#000000;\" x=\"172.663155\" xlink:href=\"#m202792f693\" y=\"172.179221\"/>\n     <use style=\"stroke:#000000;\" x=\"281.848519\" xlink:href=\"#m202792f693\" y=\"43.875553\"/>\n     <use style=\"stroke:#000000;\" x=\"58.302379\" xlink:href=\"#m202792f693\" y=\"94.8946\"/>\n     <use style=\"stroke:#000000;\" x=\"200.31839\" xlink:href=\"#m202792f693\" y=\"185.287798\"/>\n     <use style=\"stroke:#000000;\" x=\"253.231647\" xlink:href=\"#m202792f693\" y=\"107.52169\"/>\n     <use style=\"stroke:#000000;\" x=\"117.804906\" xlink:href=\"#m202792f693\" y=\"52.777901\"/>\n     <use style=\"stroke:#000000;\" x=\"347.049693\" xlink:href=\"#m202792f693\" y=\"127.074878\"/>\n     <use style=\"stroke:#000000;\" x=\"69.602329\" xlink:href=\"#m202792f693\" y=\"64.543257\"/>\n     <use style=\"stroke:#000000;\" x=\"239.682731\" xlink:href=\"#m202792f693\" y=\"126.451024\"/>\n     <use style=\"stroke:#000000;\" x=\"306.745839\" xlink:href=\"#m202792f693\" y=\"47.348527\"/>\n     <use style=\"stroke:#000000;\" x=\"231.675432\" xlink:href=\"#m202792f693\" y=\"161.368028\"/>\n     <use style=\"stroke:#000000;\" x=\"282.409299\" xlink:href=\"#m202792f693\" y=\"34.528205\"/>\n     <use style=\"stroke:#000000;\" x=\"314.478368\" xlink:href=\"#m202792f693\" y=\"49.656767\"/>\n     <use style=\"stroke:#000000;\" x=\"325.387226\" xlink:href=\"#m202792f693\" y=\"78.881846\"/>\n     <use style=\"stroke:#000000;\" x=\"256.884364\" xlink:href=\"#m202792f693\" y=\"93.183578\"/>\n     <use style=\"stroke:#000000;\" x=\"166.98448\" xlink:href=\"#m202792f693\" y=\"166.206076\"/>\n     <use style=\"stroke:#000000;\" x=\"53.700994\" xlink:href=\"#m202792f693\" y=\"125.147803\"/>\n     <use style=\"stroke:#000000;\" x=\"245.480945\" xlink:href=\"#m202792f693\" y=\"120.083695\"/>\n     <use style=\"stroke:#000000;\" x=\"278.560006\" xlink:href=\"#m202792f693\" y=\"63.295104\"/>\n     <use style=\"stroke:#000000;\" x=\"99.752064\" xlink:href=\"#m202792f693\" y=\"44.795122\"/>\n     <use style=\"stroke:#000000;\" x=\"153.953173\" xlink:href=\"#m202792f693\" y=\"139.588988\"/>\n     <use style=\"stroke:#000000;\" x=\"218.770409\" xlink:href=\"#m202792f693\" y=\"192.142742\"/>\n     <use style=\"stroke:#000000;\" x=\"267.506902\" xlink:href=\"#m202792f693\" y=\"70.650783\"/>\n     <use style=\"stroke:#000000;\" x=\"331.500374\" xlink:href=\"#m202792f693\" y=\"91.281665\"/>\n     <use style=\"stroke:#000000;\" x=\"66.66803\" xlink:href=\"#m202792f693\" y=\"94.793212\"/>\n     <use style=\"stroke:#000000;\" x=\"168.683574\" xlink:href=\"#m202792f693\" y=\"169.798454\"/>\n     <use style=\"stroke:#000000;\" x=\"144.091832\" xlink:href=\"#m202792f693\" y=\"114.251012\"/>\n     <use style=\"stroke:#000000;\" x=\"208.055665\" xlink:href=\"#m202792f693\" y=\"209.343369\"/>\n     <use style=\"stroke:#000000;\" x=\"231.263374\" xlink:href=\"#m202792f693\" y=\"157.523001\"/>\n     <use style=\"stroke:#000000;\" x=\"278.713059\" xlink:href=\"#m202792f693\" y=\"44.85846\"/>\n     <use style=\"stroke:#000000;\" x=\"294.061953\" xlink:href=\"#m202792f693\" y=\"38.20359\"/>\n     <use style=\"stroke:#000000;\" x=\"294.776726\" xlink:href=\"#m202792f693\" y=\"17.083636\"/>\n     <use style=\"stroke:#000000;\" x=\"107.183048\" xlink:href=\"#m202792f693\" y=\"48.04728\"/>\n     <use style=\"stroke:#000000;\" x=\"71.152042\" xlink:href=\"#m202792f693\" y=\"65.396618\"/>\n     <use style=\"stroke:#000000;\" x=\"342.175775\" xlink:href=\"#m202792f693\" y=\"116.712532\"/>\n     <use style=\"stroke:#000000;\" x=\"99.609431\" xlink:href=\"#m202792f693\" y=\"33.540509\"/>\n     <use style=\"stroke:#000000;\" x=\"358.064631\" xlink:href=\"#m202792f693\" y=\"129.788165\"/>\n     <use style=\"stroke:#000000;\" x=\"276.134292\" xlink:href=\"#m202792f693\" y=\"45.334876\"/>\n     <use style=\"stroke:#000000;\" x=\"335.827802\" xlink:href=\"#m202792f693\" y=\"106.520893\"/>\n     <use style=\"stroke:#000000;\" x=\"159.183875\" xlink:href=\"#m202792f693\" y=\"139.748153\"/>\n     <use style=\"stroke:#000000;\" x=\"195.65386\" xlink:href=\"#m202792f693\" y=\"198.321255\"/>\n     <use style=\"stroke:#000000;\" x=\"124.460713\" xlink:href=\"#m202792f693\" y=\"53.131514\"/>\n     <use style=\"stroke:#000000;\" x=\"267.941577\" xlink:href=\"#m202792f693\" y=\"59.303953\"/>\n     <use style=\"stroke:#000000;\" x=\"271.643804\" xlink:href=\"#m202792f693\" y=\"56.455099\"/>\n     <use style=\"stroke:#000000;\" x=\"87.779389\" xlink:href=\"#m202792f693\" y=\"42.45913\"/>\n     <use style=\"stroke:#000000;\" x=\"193.20588\" xlink:href=\"#m202792f693\" y=\"197.86484\"/>\n     <use style=\"stroke:#000000;\" x=\"279.795441\" xlink:href=\"#m202792f693\" y=\"58.505256\"/>\n     <use style=\"stroke:#000000;\" x=\"291.181046\" xlink:href=\"#m202792f693\" y=\"32.141769\"/>\n     <use style=\"stroke:#000000;\" x=\"93.753116\" xlink:href=\"#m202792f693\" y=\"50.053618\"/>\n     <use style=\"stroke:#000000;\" x=\"207.653418\" xlink:href=\"#m202792f693\" y=\"188.663552\"/>\n     <use style=\"stroke:#000000;\" x=\"148.045368\" xlink:href=\"#m202792f693\" y=\"113.752728\"/>\n     <use style=\"stroke:#000000;\" x=\"169.639777\" xlink:href=\"#m202792f693\" y=\"159.459381\"/>\n     <use style=\"stroke:#000000;\" x=\"338.749106\" xlink:href=\"#m202792f693\" y=\"117.083306\"/>\n     <use style=\"stroke:#000000;\" x=\"236.195874\" xlink:href=\"#m202792f693\" y=\"158.573206\"/>\n     <use style=\"stroke:#000000;\" x=\"165.179617\" xlink:href=\"#m202792f693\" y=\"157.514247\"/>\n     <use style=\"stroke:#000000;\" x=\"248.862642\" xlink:href=\"#m202792f693\" y=\"104.360625\"/>\n     <use style=\"stroke:#000000;\" x=\"305.322732\" xlink:href=\"#m202792f693\" y=\"51.892913\"/>\n     <use style=\"stroke:#000000;\" x=\"166.105816\" xlink:href=\"#m202792f693\" y=\"156.270496\"/>\n     <use style=\"stroke:#000000;\" x=\"62.915078\" xlink:href=\"#m202792f693\" y=\"91.202207\"/>\n     <use style=\"stroke:#000000;\" x=\"87.772142\" xlink:href=\"#m202792f693\" y=\"35.55525\"/>\n     <use style=\"stroke:#000000;\" x=\"145.051176\" xlink:href=\"#m202792f693\" y=\"120.88574\"/>\n     <use style=\"stroke:#000000;\" x=\"245.529449\" xlink:href=\"#m202792f693\" y=\"121.10109\"/>\n     <use style=\"stroke:#000000;\" x=\"192.315336\" xlink:href=\"#m202792f693\" y=\"196.25864\"/>\n     <use style=\"stroke:#000000;\" x=\"222.374142\" xlink:href=\"#m202792f693\" y=\"178.418391\"/>\n     <use style=\"stroke:#000000;\" x=\"205.272665\" xlink:href=\"#m202792f693\" y=\"214.756364\"/>\n     <use style=\"stroke:#000000;\" x=\"147.390915\" xlink:href=\"#m202792f693\" y=\"112.359123\"/>\n     <use style=\"stroke:#000000;\" x=\"140.540246\" xlink:href=\"#m202792f693\" y=\"99.289392\"/>\n     <use style=\"stroke:#000000;\" x=\"62.35908\" xlink:href=\"#m202792f693\" y=\"98.719758\"/>\n     <use style=\"stroke:#000000;\" x=\"304.259603\" xlink:href=\"#m202792f693\" y=\"44.434309\"/>\n     <use style=\"stroke:#000000;\" x=\"221.667884\" xlink:href=\"#m202792f693\" y=\"196.742966\"/>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 38.482813 224.64 \nL 38.482813 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 373.282813 224.64 \nL 373.282813 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 38.482813 224.64 \nL 373.282812 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 38.482813 7.2 \nL 373.282812 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p3132a18d32\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"38.482813\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def noisy_sin(x): \n",
    "    return tf.math.sin(x) + 0.1 * tf.random.normal(x.shape, dtype=default_float())\n",
    "\n",
    "num_train_data, num_test_data = 100, 500\n",
    "\n",
    "X = tf.random.uniform((num_train_data, 1), dtype=default_float()) * 10\n",
    "Xtest = tf.random.uniform((num_test_data, 1), dtype=default_float()) * 10\n",
    "\n",
    "Y = noisy_sin(X)\n",
    "Ytest = noisy_sin(Xtest)\n",
    "\n",
    "plt.plot(X, Y, 'xk')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Tensorflow Datasets is an efficient way to rapidly shuffle, iterate and batch from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "prefetch_size=50\nshuffle_buffer_size=50\nnum_batches_per_epoch=3\n"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((Xtest, Ytest))\n",
    "\n",
    "batch_size = 32\n",
    "num_features = 10\n",
    "prefetch_size = num_train_data // 2\n",
    "shuffle_buffer_size = num_train_data // 2\n",
    "num_batches_per_epoch = num_train_data // batch_size\n",
    "\n",
    "original_train_dataset = train_dataset\n",
    "train_dataset = train_dataset.repeat()\\\n",
    "                    .prefetch(prefetch_size)\\\n",
    "                    .shuffle(buffer_size=shuffle_buffer_size)\\\n",
    "                    .batch(batch_size)\n",
    "\n",
    "print(f\"prefetch_size={prefetch_size}\")\n",
    "print(f\"shuffle_buffer_size={shuffle_buffer_size}\")\n",
    "print(f\"num_batches_per_epoch={num_batches_per_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a GP model\n",
    "\n",
    "In GPflow2.0, we use `tf.Module` to build all our models, as well as, their components (kernels, likelihoods, parameters, etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gpflow.kernels.RBF(variance=2.)\n",
    "likelihood = gpflow.likelihoods.Gaussian()\n",
    "inducing_variable = np.linspace(0, 10, num_features).reshape(-1, 1)\n",
    "\n",
    "model = gpflow.models.SVGP(kernel=kernel, likelihood=likelihood, inducing_variable=inducing_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set a module (or a particular parameter) to be non-trainable using the auxiliary method ```set_trainable(module, False)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpflow.utilities import set_trainable\n",
    "\n",
    "set_trainable(likelihood, False)\n",
    "set_trainable(kernel.variance, False)\n",
    "\n",
    "set_trainable(likelihood, True)\n",
    "set_trainable(kernel.variance, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ```param.assign(value)``` to assign a value to a parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel.lengthscale.assign(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these changes are reflected when we use ```print_summary(model)``` to print a detailed summary of the model. By default the output will be displayed in minimalistic and simple table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "name                      class      transform       trainable    shape        dtype    value\n------------------------  ---------  --------------  -----------  -----------  -------  ----------------\nSVGP.kernel.variance      Parameter  Softplus        True         ()           float64  2.0\nSVGP.kernel.lengthscale   Parameter  Softplus        True         ()           float64  0.5\nSVGP.likelihood.variance  Parameter  Softplus        True         ()           float64  1.0\nSVGP.inducing_variable.Z  Parameter                  True         (10, 1)      float64  [[0....\nSVGP.q_mu                 Parameter                  True         (10, 1)      float64  [[0....\nSVGP.q_sqrt               Parameter  FillTriangular  True         (1, 10, 10)  float64  [[[1., 0., 0....\n"
    }
   ],
   "source": [
    "from gpflow.utilities import print_summary\n",
    "\n",
    "print_summary(model)  # same as print_summary(model, fmt=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change default printing so that it will look more nicely in our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<table>\n<thead>\n<tr><th>name                    </th><th>class    </th><th>transform     </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value           </th></tr>\n</thead>\n<tbody>\n<tr><td>SVGP.kernel.variance    </td><td>Parameter</td><td>Softplus      </td><td>True       </td><td>()         </td><td>float64</td><td>2.0             </td></tr>\n<tr><td>SVGP.kernel.lengthscale </td><td>Parameter</td><td>Softplus      </td><td>True       </td><td>()         </td><td>float64</td><td>0.5             </td></tr>\n<tr><td>SVGP.likelihood.variance</td><td>Parameter</td><td>Softplus      </td><td>True       </td><td>()         </td><td>float64</td><td>1.0             </td></tr>\n<tr><td>SVGP.inducing_variable.Z</td><td>Parameter</td><td>              </td><td>True       </td><td>(10, 1)    </td><td>float64</td><td>[[0....         </td></tr>\n<tr><td>SVGP.q_mu               </td><td>Parameter</td><td>              </td><td>True       </td><td>(10, 1)    </td><td>float64</td><td>[[0....         </td></tr>\n<tr><td>SVGP.q_sqrt             </td><td>Parameter</td><td>FillTriangular</td><td>True       </td><td>(1, 10, 10)</td><td>float64</td><td>[[[1., 0., 0....</td></tr>\n</tbody>\n</table>",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "\n",
    "print_summary(model)  # same as print_summary(model, fmt=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training using Gradient Tapes\n",
    "\n",
    "In TensorFlow2.0, we can optimise (trainable) model parameters with Tensorflow optimizers using GradientTapes. In this simple example, we perform one gradient update of the Adam optimizer to minimize the negative marginal log likelihood (or ELBO) of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(model.trainable_variables)\n",
    "    obj = - model.elbo(X, Y)\n",
    "    grads = tape.gradient(obj, model.trainable_variables)\n",
    "    \n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more elaborare example of a gradient update we can define an ```optimization_step``` that uses decorator ```tf.function``` on a closure. A closure is callable that returns the model objective evaluated at a given dataset when called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization_step(model: gpflow.models.SVGP, batch: Tuple[tf.Tensor, tf.Tensor]):\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
    "        tape.watch(model.trainable_variables)\n",
    "        obj = - model.elbo(*batch)\n",
    "        grads = tape.gradient(obj, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make use the functionality of TensorFlow Datasets to define a simple training loop that iterates over batches of the training dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_training_loop(model: gpflow.models.SVGP, epochs: int = 1, logging_epoch_freq: int = 10):\n",
    "    batches = iter(train_dataset)\n",
    "    tf_optimization_step = tf.function(optimization_step, autograph=False)\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(num_batches_per_epoch):\n",
    "            tf_optimization_step(model, next(batches))\n",
    "\n",
    "        epoch_id = epoch + 1\n",
    "        if epoch_id % logging_epoch_freq == 0:\n",
    "            tf.print(f\"Epoch {epoch_id}: ELBO (train) {model.elbo(X, Y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 2: ELBO (train) -210.8625119267519\nEpoch 4: ELBO (train) -209.20892625785794\nEpoch 6: ELBO (train) -207.5394332593566\nEpoch 8: ELBO (train) -205.86180178943906\nEpoch 10: ELBO (train) -204.1733610588082\n"
    }
   ],
   "source": [
    "simple_training_loop(model, epochs=10, logging_epoch_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring \n",
    "\n",
    "We can monitor the training procedure using TensorFlow summary. First we create a summary writer object under which we can write scalar and images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from intro_to_gpflow2_plotting import plotting_regression, summary_matplotlib_image\n",
    "\n",
    "samples_input = tf.cast(np.linspace(0, 10, 100).reshape(100, 1), default_float())\n",
    "\n",
    "def monitored_training_loop(model: gpflow.models.SVGP, logdir: str, \n",
    "                            epochs: int = 1, logging_epoch_freq: int = 10,\n",
    "                            num_samples: int = 10):\n",
    "    summary_writer = tf.summary.create_file_writer(logdir)\n",
    "    tf_optimization_step = tf.function(optimization_step)\n",
    "    batches = iter(train_dataset)\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        for epoch in range(epochs):\n",
    "            for _ in range(num_batches_per_epoch):\n",
    "                tf_optimization_step(model, next(batches))\n",
    "\n",
    "            epoch_id = epoch + 1\n",
    "            if epoch_id % logging_epoch_freq == 0:\n",
    "                tf.print(f\"Epoch {epoch_id}: ELBO (train) {model.elbo(X, Y)}\")\n",
    "\n",
    "                mean, var = model.predict_f(samples_input)\n",
    "                samples = model.predict_f_samples(samples_input, num_samples)\n",
    "                fig = plotting_regression(X, Y, samples_input, mean, var, samples)\n",
    "                \n",
    "                summary_matplotlib_image(dict(model_samples=fig), step=epoch)\n",
    "                tf.summary.scalar('elbo', data=model.elbo(X, Y), step=epoch)\n",
    "                tf.summary.scalar('likelihood/variance', data=model.likelihood.variance, step=epoch)\n",
    "                tf.summary.scalar('kernel/lengthscale', data=model.kernel.lengthscale, step=epoch)\n",
    "                tf.summary.scalar('kernel/variance', data=model.kernel.variance, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch 100: ELBO (train) -141.17663915860257\nEpoch 200: ELBO (train) -115.73096146310812\nEpoch 300: ELBO (train) -99.34844151546484\nEpoch 400: ELBO (train) -84.81535664328625\nEpoch 500: ELBO (train) -70.54100940239245\nEpoch 600: ELBO (train) -56.26630661697824\nEpoch 700: ELBO (train) -42.13861564627565\nEpoch 800: ELBO (train) -28.37512348184815\nEpoch 900: ELBO (train) -15.137978138824892\nEpoch 1000: ELBO (train) -2.604648948302377\n"
    }
   ],
   "source": [
    "model = gpflow.models.SVGP(kernel=kernel, likelihood=likelihood, inducing_variable=inducing_variable)\n",
    "\n",
    "output_logdir = enumerated_logdir()\n",
    "monitored_training_loop(model, output_logdir, epochs=1000, logging_epoch_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can then use TensorBoard to examine the training procedure more in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir \"{output_logdir}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpointing: saving and loading models\n",
    "\n",
    "With the help of `tf.train.CheckpointManager` and `tf.train.Checkpoint`, we can checkpoint the model throughout the training procedure. Let's start with a simple example using checkpointing to save and load `tf.Variables`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_value = 1.2\n",
    "a = tf.Variable(initial_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `Checkpoint` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(a=a)\n",
    "manager = tf.train.CheckpointManager(ckpt, output_logdir, max_to_keep=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save `a` variable and change its value right after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager.save()\n",
    "_ = a.assign(0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can restore old variable value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Current value of variable a: 0.330\nValue of variable a: 1.200\n"
    }
   ],
   "source": [
    "print(f\"Current value of variable a: {a.numpy():0.3f}\")\n",
    "\n",
    "ckpt.restore(manager.latest_checkpoint)\n",
    "\n",
    "print(f\"Value of variable a: {a.numpy():0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example below, we modify a simple training loop to save the model every 100 epochs using the `CheckpointManager`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gpflow.models.SVGP(kernel=kernel, likelihood=likelihood, inducing_variable=inducing_variable)\n",
    "\n",
    "def checkpointing_training_loop(model: gpflow.models.SVGP,\n",
    "                                batch_size: int,\n",
    "                                epochs: int,\n",
    "                                manager: tf.train.CheckpointManager,\n",
    "                                logging_epoch_freq: int = 100,\n",
    "                                epoch_var: Optional[tf.Variable] = None,\n",
    "                                step_var: Optional[tf.Variable] = None):\n",
    "    tf_optimization_step = tf.function(optimization_step)\n",
    "    batches = iter(train_dataset)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for step in range(num_batches_per_epoch):\n",
    "            tf_optimization_step(model, next(batches))\n",
    "            if step_var is not None:\n",
    "                step_var.assign(epoch * num_batches_per_epoch + step + 1)\n",
    "        if epoch_var is not None:\n",
    "            epoch_var.assign(epoch + 1)\n",
    "            \n",
    "        epoch_id = epoch + 1\n",
    "        if epoch_id % logging_epoch_freq == 0:\n",
    "            ckpt_path = manager.save()\n",
    "            tf.print(f\"Epoch {epoch_id}: ELBO (train) {model.elbo(X, Y)}, saved at {ckpt_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Checkpoint folder path at: /tmp/tensorboard/0\nEpoch 100: ELBO (train) -39.885525372710866, saved at /tmp/tensorboard/0/ckpt-1\nEpoch 200: ELBO (train) -18.61674822995142, saved at /tmp/tensorboard/0/ckpt-2\nEpoch 300: ELBO (train) -9.922687181788708, saved at /tmp/tensorboard/0/ckpt-3\nEpoch 400: ELBO (train) -2.8622609405427593, saved at /tmp/tensorboard/0/ckpt-4\nEpoch 500: ELBO (train) 4.13549198794537, saved at /tmp/tensorboard/0/ckpt-5\nEpoch 600: ELBO (train) 11.350933761903836, saved at /tmp/tensorboard/0/ckpt-6\nEpoch 700: ELBO (train) 18.6985702372843, saved at /tmp/tensorboard/0/ckpt-7\nEpoch 800: ELBO (train) 26.009422912807352, saved at /tmp/tensorboard/0/ckpt-8\nEpoch 900: ELBO (train) 33.02582505540399, saved at /tmp/tensorboard/0/ckpt-9\nEpoch 1000: ELBO (train) 39.49885808024434, saved at /tmp/tensorboard/0/ckpt-10\n"
    }
   ],
   "source": [
    "step_var = tf.Variable(1, dtype=tf.int32, trainable=False)\n",
    "epoch_var = tf.Variable(1, dtype=tf.int32, trainable=False)\n",
    "ckpt = tf.train.Checkpoint(model=model, step=step_var, epoch=epoch_var)\n",
    "manager = tf.train.CheckpointManager(ckpt, output_logdir, max_to_keep=5)\n",
    "\n",
    "print(f\"Checkpoint folder path at: {output_logdir}\")\n",
    "\n",
    "checkpointing_training_loop(model, batch_size=batch_size, epochs=1000, manager=manager, epoch_var=epoch_var, step_var=step_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the models have been saved, we can resore them using ```tf.train.Checkpoint.restore``` and assert their performance corresponds to the logs during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0 restored model from epoch 600 [step:1800] : ELBO training set 11.350933761903836\n1 restored model from epoch 700 [step:2100] : ELBO training set 18.6985702372843\n2 restored model from epoch 800 [step:2400] : ELBO training set 26.009422912807352\n3 restored model from epoch 900 [step:2700] : ELBO training set 33.02582505540399\n4 restored model from epoch 1000 [step:3000] : ELBO training set 39.49885808024434\n"
    }
   ],
   "source": [
    "for i, recorded_checkpoint in enumerate(manager.checkpoints):\n",
    "    ckpt.restore(recorded_checkpoint)\n",
    "    print(f\"{i} restored model from epoch {int(epoch_var)} [step:{int(step_var)}] : ELBO training set {model.elbo(X, Y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}