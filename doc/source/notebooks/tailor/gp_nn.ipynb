{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing TensorFlow models with GPflow\n",
    "\n",
    "This notebook explores two ways to combine TensorFlow neural networks with GPflow models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T10:53:12.620472Z",
     "start_time": "2018-06-20T10:53:11.541346Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpflow.test_util'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-f0c93d025262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgpflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgpflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotebook_niter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_continuous_integration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkmeans2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpflow.test_util'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import gpflow\n",
    "from gpflow.test_util import notebook_niter, is_continuous_integration\n",
    "from scipy.cluster.vq import kmeans2\n",
    "\n",
    "float_type = gpflow.settings.float_type \n",
    "\n",
    "ITERATIONS = notebook_niter(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: A convolutional network inside a GPflow model\n",
    "Here we'll use the GPflow functionality, but put a non-GPflow model inside the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T10:53:16.316761Z",
     "start_time": "2018-06-20T10:53:12.621686Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Tuple\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import gpflow\n",
    "from gpflow.config import default_float\n",
    "\n",
    "def map_fn(input_slice: Dict[str, tf.Tensor]):\n",
    "    updated = input_slice\n",
    "    updated[\"image\"] = tf.cast(updated[\"image\"], tf.float32) / 255.\n",
    "    updated[\"label\"] = tf.cast(updated[\"label\"], default_float())\n",
    "    return updated\n",
    "\n",
    "autotune = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "original_dataset = tfds.load(name=\"mnist\", split=tfds.Split.TRAIN)\n",
    "dataset = original_dataset.shuffle(1024)\\\n",
    "    .batch(32, drop_remainder=True)\\\n",
    "    .map(map_fn, num_parallel_calls=autotune)\\\n",
    "    .prefetch(autotune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T10:53:16.335949Z",
     "start_time": "2018-06-20T10:53:16.317967Z"
    }
   },
   "outputs": [],
   "source": [
    "# A vanilla ConvNet\n",
    "# This gets 97.3% accuracy on MNIST when used on its own (+ final linear layer) after 20K iterations\n",
    "\n",
    "class KernelWithConvNN(gpflow.kernels.Kernel):\n",
    "    def __init__(self, input_shape: Tuple, output_dim: int, base_kernel: gpflow.kernels.Kernel):\n",
    "        super().__init__()\n",
    "        with self.name_scope:\n",
    "            self.base_kernel = base_kernel\n",
    "            self.cnn = tf.keras.Sequential([\n",
    "                tf.keras.layers.Conv2D(filters=32, kernel_size=(28, 28), padding=\"same\", activation=\"relu\"),\n",
    "                tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "                tf.keras.layers.Conv2D(filters=64, kernel_size=(5, 5), padding=\"same\", activation=\"relu\"),\n",
    "                tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(output_dim, activation=\"relu\"),\n",
    "                tf.keras.layers.Lambda(lambda x: tf.cast(x, default_float()))\n",
    "            ])\n",
    "            self.cnn.build(input_shape)\n",
    "    \n",
    "    def K(self, a_input: tf.Tensor, b_input: Optional[tf.Tensor] = None, presliced: bool = False) -> tf.Tensor:\n",
    "        transformed_a = self.cnn(a_input)\n",
    "        transformed_b = self.cnn(b_input) if b_input is not None else b_input\n",
    "        return self.base_kernel.K(transformed_a, transformed_b, presliced)\n",
    "    \n",
    "    def K_diag(self, a_input: tf.Tensor, presliced: bool = False) -> tf.Tensor:\n",
    "        return self.base_kernel.K_diag(a_input, presliced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Builds the model based on input shapes received.\n",
       "\n",
       "This is to be used for subclassed models, which do not know at instantiation\n",
       "time what their inputs look like.\n",
       "\n",
       "This method only exists for users who want to call `model.build()` in a\n",
       "standalone way (as a substitute for calling the model on real data to\n",
       "build it). It will never be called by the framework (and thus it will\n",
       "never throw unexpected errors in an unrelated workflow).\n",
       "\n",
       "Args:\n",
       " input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
       "     are tuples, integers, or TensorShapes.\n",
       "\n",
       "Raises:\n",
       "  ValueError:\n",
       "    1. In case of invalid user-provided data (not of type tuple,\n",
       "       list, or TensorShape).\n",
       "    2. If the model requires call arguments that are agnostic\n",
       "       to the input shapes (positional or kwarg in call signature).\n",
       "    3. If not all layers were properly built.\n",
       "    4. If float type inputs are not supported within the layers.\n",
       "\n",
       "  In each of these cases, the user should build their model by calling it\n",
       "  on real tensor data.\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelSpaceInducingPoints(gpflow.inducing_variables.InducingPoints):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = kcnn(tf.random.normal((3, 28, 28, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T10:53:16.475537Z",
     "start_time": "2018-06-20T10:53:16.337305Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'gpflow' has no attribute 'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-c7ded1aa2472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Kuf is in NN output space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mgpflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernelSpaceInducingPoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKernelWithNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mKuf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgpflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams_as_tensors_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'gpflow' has no attribute 'features'"
     ]
    }
   ],
   "source": [
    "# Kuf is in NN output space\n",
    "@gpflow.features.dispatch(KernelSpaceInducingPoints, KernelWithNN, object)\n",
    "def Kuf(inducing_variable, kernel, a_input):\n",
    "    return kernel.base_kernel(inducing_variable, kernel.cnn(Xnew))\n",
    "\n",
    "\n",
    "class NNComposedKernel(KernelWithNN):\n",
    "    \"\"\"\n",
    "    This kernel class applies f() to X before calculating K\n",
    "    \"\"\"\n",
    "    \n",
    "    def K(self, X, X2=None):\n",
    "        return super().K(self.f(X), self.f(X2))\n",
    "    \n",
    "    def Kdiag(self, X):\n",
    "        return super().Kdiag(self.f(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T11:10:46.858524Z",
     "start_time": "2018-06-20T10:53:16.477021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 98.6800%\n"
     ]
    }
   ],
   "source": [
    "def ex1():\n",
    "    fX_dim = 5  \n",
    "    M = 100\n",
    "\n",
    "    # Unfortunately, only float32 and lower are supported by the Conv layers \n",
    "    f = lambda x: tf.cast(cnn_fn(tf.cast(x, tf.float32), fX_dim), float_type)\n",
    "    kern = NNComposedKernel(gpflow.kernels.Matern32(fX_dim), f)\n",
    "\n",
    "    # Build the model \n",
    "\n",
    "    lik = gpflow.likelihoods.MultiClass(Mnist.Nclasses)\n",
    "\n",
    "    Z = kmeans2(Mnist.X, M, minit='points')[0]\n",
    "\n",
    "    model = NN_SVGP(Mnist.X, Mnist.Y, kern, lik, Z=Z, num_latent=Mnist.Nclasses, minibatch_size=1000)\n",
    "\n",
    "    # Use GPflow wrappers to train. Note all session handling is done for us\n",
    "    gpflow.training.AdamOptimizer(0.001).minimize(model, maxiter=ITERATIONS)\n",
    "\n",
    "    # Predictions\n",
    "    m, v = model.predict_y(Mnist.Xtest)\n",
    "    preds = np.argmax(m, 1).reshape(Mnist.Ytest.shape)\n",
    "    correct = preds == Mnist.Ytest.astype(int)\n",
    "    acc = np.average(correct.astype(float)) * 100.\n",
    "\n",
    "    print('Accuracy is {:.4f}%'.format(acc))\n",
    "\n",
    "gpflow.reset_default_graph_and_session()\n",
    "ex1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T11:25:46.165332Z",
     "start_time": "2018-06-20T11:10:46.860361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 97.5600%\n"
     ]
    }
   ],
   "source": [
    "def ex2b():\n",
    "    fX_dim = 5  \n",
    "    minibatch_size = notebook_niter(1000, test_n=10)\n",
    "    M = notebook_niter(100, test_n=5)\n",
    "\n",
    "    # Unfortunately, only float32 and lower are supported by the Conv layers \n",
    "    f = lambda x: tf.cast(cnn_fn(tf.cast(x, tf.float32), fX_dim), float_type)\n",
    "    kern = KernelWithNN(gpflow.kernels.Matern32(fX_dim), f)\n",
    "    \n",
    "    # Reset inducing (these live in a different space to X, so we need to be careful here)\n",
    "    ind = np.random.choice(Mnist.X.shape[0], minibatch_size, replace=False)\n",
    "    \n",
    "    # Currently a hack is needed due to model initialisation\n",
    "    feat = KernelSpaceInducingPoints(np.empty((M, fX_dim)))\n",
    "    #feat = FFeature(Z_0)  # Ideally, we could move the calculation of Z_0\n",
    "    \n",
    "    # Build the model \n",
    "\n",
    "    lik = gpflow.likelihoods.MultiClass(Mnist.Nclasses)\n",
    "\n",
    "    #Z = kmeans2(Mnist.X, M, minit='points')[0]\n",
    "\n",
    "    model = NN_SVGP(Mnist.X, Mnist.Y, kern, lik, feat=feat, num_latent=Mnist.Nclasses, minibatch_size=minibatch_size)\n",
    "\n",
    "    fZ = model.kern.compute_f(Mnist.X[ind])\n",
    "    # Z_0 = kmeans2(fZ, M)[0] might fail\n",
    "    Z_0 = fZ[np.random.choice(len(fZ), M, replace=False)]\n",
    "    model.feature.Z = Z_0\n",
    "\n",
    "    # Use GPflow wrappers to train. Note all session handling is done for us\n",
    "    gpflow.training.AdamOptimizer(0.001).minimize(model, maxiter=ITERATIONS)\n",
    "\n",
    "    # Predictions\n",
    "    m, v = model.predict_y(Mnist.Xtest)\n",
    "    preds = np.argmax(m, 1).reshape(Mnist.Ytest.shape)\n",
    "    correct = preds == Mnist.Ytest.astype(int)\n",
    "    acc = np.average(correct.astype(float)) * 100.\n",
    "\n",
    "    print('Accuracy is {:.4f}%'.format(acc))\n",
    "\n",
    "gpflow.reset_default_graph_and_session()\n",
    "ex2b()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: A GPflow model on top of a TensorFlow model\n",
    "Now we'll do things the other way; take a model implemented in TensorFlow and explain how to put a GPflow model on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-20T11:40:21.347439Z",
     "start_time": "2018-06-20T11:25:46.167693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc is 98.5900\n"
     ]
    }
   ],
   "source": [
    "def ex2():\n",
    "    minibatch_size = notebook_niter(1000, test_n=10)\n",
    "    gp_dim = 5\n",
    "    M = notebook_niter(100, test_n=5)\n",
    "\n",
    "    # Placeholders\n",
    "    X = tf.placeholder(tf.float32, [minibatch_size, Mnist.input_dim])  # Fixed shape so num_data works in SVGP\n",
    "    Y = tf.placeholder(tf.float32, [minibatch_size, 1])\n",
    "    Xtest = tf.placeholder(tf.float32, [None, Mnist.input_dim])\n",
    "\n",
    "    # Build graph\n",
    "\n",
    "    with tf.variable_scope('cnn'):\n",
    "        f_X = tf.cast(cnn_fn(X, gp_dim), dtype=float_type)\n",
    "\n",
    "    with tf.variable_scope('cnn', reuse=True):\n",
    "        f_Xtest = tf.cast(cnn_fn(Xtest, gp_dim), dtype=float_type)\n",
    "\n",
    "    gp_model = gpflow.models.SVGP(f_X, tf.cast(Y, dtype=float_type), \n",
    "                                  gpflow.kernels.RBF(gp_dim), gpflow.likelihoods.MultiClass(Mnist.Nclasses), \n",
    "                                  Z=np.zeros((M, gp_dim)), # we'll set this later\n",
    "                                  num_latent=Mnist.Nclasses)\n",
    "\n",
    "    loss = -gp_model.likelihood_tensor\n",
    "\n",
    "    m, v = gp_model._build_predict(f_Xtest)\n",
    "    my, yv = gp_model.likelihood.predict_mean_and_var(m, v)\n",
    "\n",
    "    with tf.variable_scope('adam'):\n",
    "        opt_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "    tf_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='adam')\n",
    "    tf_vars += tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='cnn')\n",
    "\n",
    "    # Initialise\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.variables_initializer(var_list=tf_vars))\n",
    "    gp_model.initialize(session=sess)\n",
    "    \n",
    "    # Reset inducing (these live in a different space to X, so we need to be careful here)\n",
    "    ind = np.random.choice(Mnist.X.shape[0], minibatch_size, replace=False)\n",
    "\n",
    "    fZ = sess.run(f_X, feed_dict={X:Mnist.X[ind]})\n",
    "    # Z_0 = kmeans2(fZ, M)[0] might fail\n",
    "    Z_0 = fZ[np.random.choice(len(fZ), M, replace=False)]\n",
    "\n",
    "    def set_gp_param(param, value):\n",
    "        sess.run(tf.assign(param.unconstrained_tensor, param.transform.backward(value)))\n",
    "\n",
    "    set_gp_param(gp_model.feature.Z, Z_0)\n",
    "\n",
    "    # Train\n",
    "    for i in range(ITERATIONS):\n",
    "        ind = np.random.choice(Mnist.X.shape[0], minibatch_size, replace=False)\n",
    "        sess.run(opt_step, feed_dict={X:Mnist.X[ind], Y:Mnist.Y[ind]})\n",
    "\n",
    "    # Predict\n",
    "    preds = np.argmax(sess.run(my, feed_dict={Xtest:Mnist.Xtest}), 1).reshape(Mnist.Ytest.shape)\n",
    "    correct = preds == Mnist.Ytest.astype(int)\n",
    "    acc = np.average(correct.astype(float)) * 100.\n",
    "    print('acc is {:.4f}'.format(acc))\n",
    "\n",
    "gpflow.reset_default_graph_and_session()\n",
    "ex2()\n",
    "\n",
    "gpflow.reset_default_graph_and_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
