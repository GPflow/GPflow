{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import itertools\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"\"\n",
    "import numpy as np\n",
    "import gpflow\n",
    "import gpflow.training.monitor as mon\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: `gpflow.training.monitor`\n",
    "In this notebook we'll demo how to use `gpflow.training.monitor` for logging the optimisation of a GPflow model.\n",
    "\n",
    "## Creating the GPflow model\n",
    "We first generate some random data and create a GPflow model.\n",
    "\n",
    "Under the hood, GPflow gives a unique name to each model which is used to name the Variables it creates in the TensorFlow graph containing a random identifier. This is useful in interactive sessions, where people may create a few models, to prevent variables with the same name conflicting. However, when loading the model, we need to make sure that the names of all the variables are exactly the same as in the checkpoint. This is why we pass name=\"SVGP\" to the model constructor, and why we use gpflow.defer_build()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = np.random.rand(10000, 1) * 10\n",
    "Y = np.sin(X) + np.random.randn(*X.shape)\n",
    "Xt = np.random.rand(10000, 1) * 10\n",
    "Yt = np.sin(Xt) + np.random.randn(*Xt.shape)\n",
    "\n",
    "with gpflow.defer_build():\n",
    "    m = gpflow.models.SVGP(X, Y, gpflow.kernels.RBF(1), gpflow.likelihoods.Gaussian(),\n",
    "                           Z=np.linspace(0, 10, 5)[:, None],\n",
    "                           minibatch_size=100, name=\"SVGP\")\n",
    "    m.likelihood.variance = 0.01\n",
    "m.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute log likelihood before the optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML before the optimisation: -1271605.621944\n"
     ]
    }
   ],
   "source": [
    "print('LML before the optimisation: %f' % m.compute_log_likelihood())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a TensorFlow optimiser. All TensorFlow optimisers have a support for `global_step` variable. Its purpose is to track how many optimisation steps have occurred. It is useful to keep this in a TensorFlow variable as this allows it to be restored together with all the parameters of the model.\n",
    "\n",
    "The code below creates this variable using a monitor's helper function. It is important to create it before building the monitor in case the monitor includes a checkpoint task. This is because the checkpoint internally uses the TensorFlow Saver which creates a list of variables to save. Therefore all variables expected to be saved by the checkpoint task should exist by the time the task is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = m.enquire_session()\n",
    "global_step = mon.create_global_step(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the monitor\n",
    "\n",
    "Next we need to construct the monitor. `gpflow.training.monitor` provides classes that are building blocks for the monitor. Essengially, a monitor is a function that is provided as a callback to an optimiser. It consists of a number of tasks that may be executed at each step, subject to their running condition.\n",
    "\n",
    "In this example, we want to:\n",
    "- log certain scalar parameters in TensorBoard,\n",
    "- log the full optimisation objective (log marginal likelihood bound) periodically, even though we optimise with minibatches,\n",
    "- store a backup of the optimisation process periodically,\n",
    "- log performance for a test set periodically.\n",
    "\n",
    "We will define these tasks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_task = mon.PrintTimingsTask().with_name('print')\\\n",
    "    .with_condition(mon.PeriodicIterationCondition(10))\\\n",
    "    .with_exit_condition(True)\n",
    "\n",
    "sleep_task = mon.SleepTask(0.01).with_name('sleep').with_name('sleep')\n",
    "\n",
    "saver_task = mon.CheckpointTask('./monitor-saves').with_name('saver')\\\n",
    "    .with_condition(mon.PeriodicIterationCondition(10))\\\n",
    "    .with_exit_condition(True)\n",
    "\n",
    "file_writer = mon.LogdirWriter('./model-tensorboard')\n",
    "\n",
    "model_tboard_task = mon.ModelToTensorBoardTask(file_writer, m).with_name('model_tboard')\\\n",
    "    .with_condition(mon.PeriodicIterationCondition(10))\\\n",
    "    .with_exit_condition(True)\n",
    "\n",
    "lml_tboard_task = mon.LmlToTensorBoardTask(file_writer, m).with_name('lml_tboard')\\\n",
    "    .with_condition(mon.PeriodicIterationCondition(100))\\\n",
    "    .with_exit_condition(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the above code shows, each task can be assigned a name and running conditions. The name will be shown in the task timing summary.\n",
    "\n",
    "There are two different types of running conditions: `with_condition` controls execution of the task at each iteration in the optimisation loop. `with_exit_condition` is a simple boolean flag indicating that the task should also run at the end of optimisation.\n",
    "In this example we want to run our tasks periodically, at every iteration or every 10th or 100th iteration.\n",
    "\n",
    "Notice that the two TensorBoard tasks will write events into the same file. It is possible to share a file writer between multiple tasks. However it is not possible to share the same event location between multiple file writers. An attempt to open two writers with the same location will result in error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom tasks\n",
    "We may also want to perfom certain tasks that do not have pre-defined `Task` classes. For example, we may want to compute the performance on a test set. Here we create such a class by extending `BaseTensorBoardTask` to log the testing benchmarks in addition to all the scalar parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorBoardTask(mon.BaseTensorBoardTask):\n",
    "    def __init__(self, file_writer, model, Xt, Yt):\n",
    "        super().__init__(file_writer, model)\n",
    "        self.Xt = Xt\n",
    "        self.Yt = Yt\n",
    "        self._full_test_err = tf.placeholder(gpflow.settings.tf_float, shape=())\n",
    "        self._full_test_nlpp = tf.placeholder(gpflow.settings.tf_float, shape=())\n",
    "        self._summary = tf.summary.merge([tf.summary.scalar(\"test_rmse\", self._full_test_err),\n",
    "                                         tf.summary.scalar(\"test_nlpp\", self._full_test_nlpp)])\n",
    "    \n",
    "    def run(self, context: mon.MonitorContext, *args, **kwargs) -> None:\n",
    "        minibatch_size = 100\n",
    "        preds = np.vstack([self.model.predict_y(Xt[mb * minibatch_size:(mb + 1) * minibatch_size, :])[0]\n",
    "                            for mb in range(-(-len(Xt) // minibatch_size))])\n",
    "        test_err = np.mean((Yt - preds) ** 2.0)**0.5\n",
    "        self._eval_summary(context, {self._full_test_err: test_err, self._full_test_nlpp: 0.0})\n",
    "\n",
    "        \n",
    "custom_tboard_task = CustomTensorBoardTask(file_writer, m, Xt, Yt).with_name('custom_tboard')\\\n",
    "    .with_condition(mon.PeriodicIterationCondition(100))\\\n",
    "    .with_exit_condition(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can put all these tasks into a monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_tasks = [print_task, model_tboard_task, lml_tboard_task, custom_tboard_task, saver_task, sleep_task]\n",
    "monitor = mon.Monitor(monitor_tasks, session, global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the optimisation\n",
    "We finally get to running the optimisation.\n",
    "\n",
    "We may want to continue a previously run optimisation by resotring the TensorFlow graph from the latest checkpoint. Otherwise skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./monitor-saves/cp-1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./monitor-saves/cp-1450\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('./monitor-saves'):\n",
    "    mon.restore_session(session, './monitor-saves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10\ttotal itr.rate 12.91/s\trecent itr.rate 12.91/s\topt.step 1460\ttotal opt.rate 14.63/s\trecent opt.rate 14.63/s\n",
      "Iteration 20\ttotal itr.rate 19.65/s\trecent itr.rate 41.10/s\topt.step 1470\ttotal opt.rate 28.87/s\trecent opt.rate 1097.44/s\n",
      "Iteration 30\ttotal itr.rate 25.08/s\trecent itr.rate 56.14/s\topt.step 1480\ttotal opt.rate 42.40/s\trecent opt.rate 678.17/s\n",
      "Iteration 40\ttotal itr.rate 27.05/s\trecent itr.rate 35.34/s\topt.step 1490\ttotal opt.rate 54.93/s\trecent opt.rate 486.15/s\n",
      "Iteration 50\ttotal itr.rate 29.49/s\trecent itr.rate 46.20/s\topt.step 1500\ttotal opt.rate 67.04/s\trecent opt.rate 566.47/s\n",
      "Iteration 60\ttotal itr.rate 31.67/s\trecent itr.rate 50.18/s\topt.step 1510\ttotal opt.rate 78.57/s\trecent opt.rate 559.69/s\n",
      "Iteration 70\ttotal itr.rate 33.26/s\trecent itr.rate 47.68/s\topt.step 1520\ttotal opt.rate 89.64/s\trecent opt.rate 581.50/s\n",
      "Iteration 80\ttotal itr.rate 34.48/s\trecent itr.rate 46.29/s\topt.step 1530\ttotal opt.rate 100.18/s\trecent opt.rate 563.99/s\n",
      "Iteration 90\ttotal itr.rate 35.61/s\trecent itr.rate 48.38/s\topt.step 1540\ttotal opt.rate 110.16/s\trecent opt.rate 543.23/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:00<00:00, 287.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100\ttotal itr.rate 36.34/s\trecent itr.rate 44.46/s\topt.step 1550\ttotal opt.rate 118.50/s\trecent opt.rate 372.35/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 390.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 110\ttotal itr.rate 31.04/s\trecent itr.rate 12.62/s\topt.step 1560\ttotal opt.rate 128.22/s\trecent opt.rate 712.40/s\n",
      "Iteration 120\ttotal itr.rate 31.84/s\trecent itr.rate 44.55/s\topt.step 1570\ttotal opt.rate 136.33/s\trecent opt.rate 448.66/s\n",
      "Iteration 130\ttotal itr.rate 32.67/s\trecent itr.rate 47.53/s\topt.step 1580\ttotal opt.rate 145.42/s\trecent opt.rate 727.10/s\n",
      "Iteration 140\ttotal itr.rate 33.40/s\trecent itr.rate 47.03/s\topt.step 1590\ttotal opt.rate 154.09/s\trecent opt.rate 685.03/s\n",
      "Iteration 150\ttotal itr.rate 34.09/s\trecent itr.rate 47.91/s\topt.step 1600\ttotal opt.rate 162.80/s\trecent opt.rate 779.37/s\n",
      "Iteration 160\ttotal itr.rate 34.69/s\trecent itr.rate 47.25/s\topt.step 1610\ttotal opt.rate 171.12/s\trecent opt.rate 733.41/s\n",
      "Iteration 170\ttotal itr.rate 35.23/s\trecent itr.rate 46.96/s\topt.step 1620\ttotal opt.rate 179.37/s\trecent opt.rate 782.62/s\n",
      "Iteration 180\ttotal itr.rate 35.76/s\trecent itr.rate 47.96/s\topt.step 1630\ttotal opt.rate 187.10/s\trecent opt.rate 699.88/s\n",
      "Iteration 190\ttotal itr.rate 36.15/s\trecent itr.rate 44.95/s\topt.step 1640\ttotal opt.rate 193.17/s\trecent opt.rate 464.79/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:00<00:00, 329.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 200\ttotal itr.rate 36.59/s\trecent itr.rate 47.71/s\topt.step 1650\ttotal opt.rate 200.10/s\trecent opt.rate 627.85/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 395.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 210\ttotal itr.rate 34.28/s\trecent itr.rate 15.13/s\topt.step 1660\ttotal opt.rate 205.21/s\trecent opt.rate 419.75/s\n",
      "Iteration 220\ttotal itr.rate 34.66/s\trecent itr.rate 45.44/s\topt.step 1670\ttotal opt.rate 211.99/s\trecent opt.rate 691.54/s\n",
      "Iteration 230\ttotal itr.rate 35.13/s\trecent itr.rate 49.68/s\topt.step 1680\ttotal opt.rate 218.40/s\trecent opt.rate 653.23/s\n",
      "Iteration 240\ttotal itr.rate 35.50/s\trecent itr.rate 46.87/s\topt.step 1690\ttotal opt.rate 224.96/s\trecent opt.rate 728.49/s\n",
      "Iteration 250\ttotal itr.rate 35.84/s\trecent itr.rate 46.81/s\topt.step 1700\ttotal opt.rate 229.70/s\trecent opt.rate 464.01/s\n",
      "Iteration 260\ttotal itr.rate 36.19/s\trecent itr.rate 47.55/s\topt.step 1710\ttotal opt.rate 235.37/s\trecent opt.rate 615.25/s\n",
      "Iteration 270\ttotal itr.rate 36.51/s\trecent itr.rate 47.72/s\topt.step 1720\ttotal opt.rate 241.28/s\trecent opt.rate 694.04/s\n",
      "Iteration 280\ttotal itr.rate 36.80/s\trecent itr.rate 46.62/s\topt.step 1730\ttotal opt.rate 246.85/s\trecent opt.rate 655.21/s\n",
      "Iteration 290\ttotal itr.rate 37.03/s\trecent itr.rate 45.19/s\topt.step 1740\ttotal opt.rate 250.79/s\trecent opt.rate 453.70/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [00:00<00:00, 367.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 300\ttotal itr.rate 37.31/s\trecent itr.rate 47.79/s\topt.step 1750\ttotal opt.rate 254.27/s\trecent opt.rate 425.70/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 404.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 310\ttotal itr.rate 35.67/s\trecent itr.rate 15.36/s\topt.step 1760\ttotal opt.rate 258.97/s\trecent opt.rate 580.63/s\n",
      "Iteration 320\ttotal itr.rate 35.95/s\trecent itr.rate 47.28/s\topt.step 1770\ttotal opt.rate 264.17/s\trecent opt.rate 700.33/s\n",
      "Iteration 330\ttotal itr.rate 36.20/s\trecent itr.rate 46.85/s\topt.step 1780\ttotal opt.rate 267.58/s\trecent opt.rate 455.98/s\n",
      "Iteration 340\ttotal itr.rate 36.43/s\trecent itr.rate 46.14/s\topt.step 1790\ttotal opt.rate 270.99/s\trecent opt.rate 467.57/s\n",
      "Iteration 350\ttotal itr.rate 36.70/s\trecent itr.rate 49.06/s\topt.step 1800\ttotal opt.rate 275.69/s\trecent opt.rate 671.86/s\n",
      "Iteration 360\ttotal itr.rate 36.92/s\trecent itr.rate 46.37/s\topt.step 1810\ttotal opt.rate 280.32/s\trecent opt.rate 679.23/s\n",
      "Iteration 370\ttotal itr.rate 37.15/s\trecent itr.rate 47.82/s\topt.step 1820\ttotal opt.rate 284.95/s\trecent opt.rate 703.19/s\n",
      "Iteration 380\ttotal itr.rate 37.35/s\trecent itr.rate 46.64/s\topt.step 1830\ttotal opt.rate 289.52/s\trecent opt.rate 712.69/s\n",
      "Iteration 390\ttotal itr.rate 37.65/s\trecent itr.rate 54.68/s\topt.step 1840\ttotal opt.rate 293.82/s\trecent opt.rate 673.76/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:00<00:00, 188.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 400\ttotal itr.rate 37.83/s\trecent itr.rate 46.23/s\topt.step 1850\ttotal opt.rate 298.33/s\trecent opt.rate 745.14/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 316.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 410\ttotal itr.rate 36.31/s\trecent itr.rate 13.97/s\topt.step 1860\ttotal opt.rate 302.36/s\trecent opt.rate 657.96/s\n",
      "Iteration 420\ttotal itr.rate 36.50/s\trecent itr.rate 46.19/s\topt.step 1870\ttotal opt.rate 306.22/s\trecent opt.rate 642.23/s\n",
      "Iteration 430\ttotal itr.rate 36.72/s\trecent itr.rate 49.02/s\topt.step 1880\ttotal opt.rate 310.29/s\trecent opt.rate 700.88/s\n",
      "Iteration 440\ttotal itr.rate 36.90/s\trecent itr.rate 46.96/s\topt.step 1890\ttotal opt.rate 314.27/s\trecent opt.rate 701.37/s\n",
      "Iteration 450\ttotal itr.rate 37.09/s\trecent itr.rate 47.94/s\topt.step 1900\ttotal opt.rate 318.08/s\trecent opt.rate 683.02/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [00:00<00:00, 464.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 450\ttotal itr.rate 36.30/s\trecent itr.rate 0.00/s\topt.step 1900\ttotal opt.rate 286.53/s\trecent opt.rate 0.00/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 461.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks execution time summary:\n",
      "print:\t0.0413 (sec)\n",
      "model_tboard:\t0.1643 (sec)\n",
      "lml_tboard:\t1.3124 (sec)\n",
      "custom_tboard:\t1.2160 (sec)\n",
      "saver:\t4.0467 (sec)\n",
      "sleep:\t4.5388 (sec)\n"
     ]
    }
   ],
   "source": [
    "optimiser = gpflow.train.AdamOptimizer(0.01)\n",
    "\n",
    "with mon.Monitor(monitor_tasks, session, global_step, print_summary=True) as monitor:\n",
    "    optimiser.minimize(m, step_callback=monitor, maxiter=450, global_step=global_step)\n",
    "\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets compute the log likelihood again. Hopefully we will see an increase in its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LML after the optimisation: -13792.241274\n"
     ]
    }
   ],
   "source": [
    "print('LML after the optimisation: %f' % m.compute_log_likelihood())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we have used the TensorFlow `AdamOptimizer`. Using `ScipyOptimizer` requires a couple of special tricks. Firstly, this optimiser works with its own copy of trained variables and updates the original ones only when the optimisation is completed. Secondly, it doesn't use the `global_step` variable. This can present a problem when doing optimisation in several stages. Monitor has to use an iteration count instead of the `global_step`, which will be reset to zero at each stage.\n",
    "\n",
    "To adress the first problem we will provide the optimiser as one of the parameters to the monitor. The monitor will make sure the orginal variables are updated whenever we access them from a monitoring task. The second problem is addressed by creating an instance of `MonitorContext` and providing it explicitely to the `Monitor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 14991.851823\n",
      "  Number of iterations: 4\n",
      "  Number of functions evaluations: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: 14991.851823\n",
      "  Number of iterations: 4\n",
      "  Number of functions evaluations: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4\ttotal itr.rate 5.05/s\trecent itr.rate nan/s\topt.step 4\ttotal opt.rate 5.05/s\trecent opt.rate nan/s\n",
      "Tasks execution time summary:\n",
      "print:\t0.0414 (sec)\n"
     ]
    }
   ],
   "source": [
    "optimiser = gpflow.train.ScipyOptimizer()\n",
    "context = mon.MonitorContext()\n",
    "\n",
    "with mon.Monitor([print_task], session, print_summary=True, optimiser=optimiser, context=context) as monitor:\n",
    "    optimiser.minimize(m, step_callback=monitor, maxiter=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python GPFlow-venv",
   "language": "python",
   "name": "gpflow_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
