{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import gpflow\n",
    "import gpflow.training.monitor as mon\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "X = np.random.rand(10000, 1) * 10\n",
    "Y = np.sin(X) + np.random.randn(*X.shape)\n",
    "Xt = np.random.rand(10000, 1) * 10\n",
    "Yt = np.sin(X) + np.random.randn(*X.shape)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: `gpflow.training.monitor`\n",
    "In this notebook we'll demo how to use `gpflow.training.monitor` for logging the optimisation of a GPflow model. The example should cover pretty much all use cases.\n",
    "\n",
    "## Creating the GPflow model\n",
    "We first create the GPflow model. Under the hood, GPflow gives a unique name to each model which is used to name the Variables it creates in the TensorFlow graph containing a random identifier. This is useful in interactive sessions, where people may create a few models, to prevent variables with the same name conflicting. However, when loading the model, we need to make sure that the names of all the variables are exactly the same as in the checkpoint. This is why we pass `name=\"SVGP\"` to the model constructor, and why we use `gpflow.defer_build()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with gpflow.defer_build():\n",
    "    m = gpflow.models.SVGP(X, Y, gpflow.kernels.RBF(1), gpflow.likelihoods.Gaussian(),\n",
    "                           Z=np.linspace(0, 10, 5)[:, None],\n",
    "                           minibatch_size=100, name=\"SVGP\")\n",
    "    m.likelihood.variance = 0.01\n",
    "m.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1088595.1395058229"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.compute_log_likelihood()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the optimisation\n",
    "Next we need to set up the optimisation process. `gpflow.training.monitor` provides classes that manage the optimsation, and perform certain logging tasks. In this example, we want to:\n",
    "- log certain scalar parameters in TensorBoard\n",
    "- log the full optimisation objective (log marginal likelihood bound) periodically, even though we optimise with minibatches\n",
    "- store a backup of the optimisation process periodically\n",
    "- log performance for a test set periodically\n",
    "\n",
    "Because of the integration with TensorFlow ways of storing and logging, we will need to perform a few TensorFlow manipulations outside of GPflow as well.\n",
    "\n",
    "We start by creating the `global_step` variable. This is not strictly required by TensorFlow optimisers, but they do all have support for it. Its purpose is to track how many optimisation steps have occurred. It is useful to keep this in a TensorFlow variable as this allows it to be restored together with all the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "m.enquire_session().run(global_step.initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the optimiser action. `make_optimize_action` also creates the optimisation tensor, which is added to the computational graph. Later, the saver will store the whole graph, and so can also restore the exact optimiser state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = gpflow.train.AdamOptimizer(0.01).make_optimize_action(m, global_step=global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating actions for keeping track of the optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.kern.lengthscales.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cb():\n",
    "    m.anchor(m.enquire_session())\n",
    "    print('lengthscales: {}'.format(m.kern.lengthscales.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring session from `./monitor-saves/checkpoint-472`.\n",
      "INFO:tensorflow:Restoring parameters from ./monitor-saves/checkpoint-472\n"
     ]
    }
   ],
   "source": [
    "print_lml = mon.PrintAction(itertools.count(), mon.Trigger.ITER, m, \"lml\", single_line=False)\n",
    "callback = mon.CallbackAction(itertools.count(step=10), mon.Trigger.ITER,\n",
    "#                               cb)\n",
    "                              lambda : print('lengthscales: {}'.format(m.kern.lengthscales.value)))\n",
    "sleep = mon.SleepAction(itertools.count(), mon.Trigger.ITER, 0.01)\n",
    "saver = mon.StoreSession(itertools.count(step=10), mon.Trigger.ITER, m.enquire_session(),\n",
    "                         hist_path=\"./monitor-saves/checkpoint\", global_step=global_step)\n",
    "actions = [adam, print_lml, callback, sleep, saver]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lml: iteration 1 likelihood -67081.8343\n",
      "lengthscales: 1.0\n",
      "lml: iteration 2 likelihood -53473.8822\n",
      "lml: iteration 3 likelihood -58519.8139\n",
      "lml: iteration 4 likelihood -66894.6986\n",
      "lml: iteration 5 likelihood -79654.5435\n",
      "lml: iteration 6 likelihood -85969.7993\n",
      "lml: iteration 7 likelihood -71594.3317\n",
      "lml: iteration 8 likelihood -66891.0894\n",
      "lml: iteration 9 likelihood -48644.3054\n",
      "lml: iteration 10 likelihood -74417.3452\n",
      "lml: iteration 11 likelihood -79721.6210\n",
      "lengthscales: 1.0\n",
      "lml: iteration 12 likelihood -43877.1873\n",
      "lml: iteration 13 likelihood -71479.6665\n",
      "lml: iteration 14 likelihood -53425.0124\n",
      "lml: iteration 15 likelihood -84990.4086\n",
      "lml: iteration 16 likelihood -61294.9662\n",
      "lml: iteration 17 likelihood -53121.8563\n",
      "lml: iteration 18 likelihood -53664.7576\n",
      "lml: iteration 19 likelihood -70662.5137\n",
      "lml: iteration 20 likelihood -74941.6222\n",
      "lml: iteration 21 likelihood -53200.7872\n",
      "lengthscales: 1.0\n",
      "lml: iteration 22 likelihood -67710.9326\n",
      "lml: iteration 23 likelihood -62780.5405\n",
      "lml: iteration 24 likelihood -62122.1915\n",
      "lml: iteration 25 likelihood -45342.9245\n",
      "lml: iteration 26 likelihood -61686.8152\n",
      "lml: iteration 27 likelihood -52174.0357\n",
      "lml: iteration 28 likelihood -80926.5241\n",
      "lml: iteration 29 likelihood -66681.7068\n",
      "lml: iteration 30 likelihood -74394.2931\n",
      "lml: iteration 31 likelihood -69316.0827\n",
      "lengthscales: 1.0\n",
      "lml: iteration 32 likelihood -62577.5909\n",
      "lml: iteration 33 likelihood -77324.5162\n",
      "lml: iteration 34 likelihood -71303.4209\n",
      "lml: iteration 35 likelihood -79767.9073\n",
      "lml: iteration 36 likelihood -68161.6121\n",
      "lml: iteration 37 likelihood -73552.4186\n",
      "lml: iteration 38 likelihood -67072.9186\n",
      "lml: iteration 39 likelihood -72807.1314\n",
      "lml: iteration 40 likelihood -59656.9729\n",
      "lml: iteration 41 likelihood -60497.2353\n",
      "lengthscales: 1.0\n",
      "lml: iteration 42 likelihood -55072.9276\n",
      "lml: iteration 43 likelihood -63289.6849\n",
      "lml: iteration 44 likelihood -62642.2374\n",
      "lml: iteration 45 likelihood -77561.4683\n",
      "lml: iteration 46 likelihood -67797.3287\n",
      "lml: iteration 47 likelihood -56150.8905\n",
      "lml: iteration 48 likelihood -66499.2052\n",
      "lml: iteration 49 likelihood -54372.5415\n",
      "lml: iteration 50 likelihood -76808.5416\n",
      "lml: iteration 51 likelihood -62440.6589\n",
      "lengthscales: 1.0\n",
      "lml: iteration 52 likelihood -80506.7145\n",
      "lml: iteration 53 likelihood -67034.7088\n",
      "lml: iteration 54 likelihood -60185.6783\n",
      "lml: iteration 55 likelihood -60190.2949\n",
      "lml: iteration 56 likelihood -59571.4488\n",
      "lml: iteration 57 likelihood -78169.6370\n",
      "lml: iteration 58 likelihood -56862.3594\n",
      "lml: iteration 59 likelihood -66893.3410\n",
      "lml: iteration 60 likelihood -56125.9138\n",
      "lml: iteration 61 likelihood -61866.2629\n",
      "lengthscales: 1.0\n",
      "lml: iteration 62 likelihood -78427.2568\n",
      "lml: iteration 63 likelihood -57933.8120\n",
      "lml: iteration 64 likelihood -59822.4271\n",
      "lml: iteration 65 likelihood -65849.6058\n",
      "lml: iteration 66 likelihood -66435.4240\n",
      "lml: iteration 67 likelihood -61615.6072\n",
      "lml: iteration 68 likelihood -46896.9356\n",
      "lml: iteration 69 likelihood -52537.1530\n",
      "lml: iteration 70 likelihood -69379.9349\n",
      "lml: iteration 71 likelihood -67449.0450\n",
      "lengthscales: 1.0\n",
      "lml: iteration 72 likelihood -53446.8288\n",
      "lml: iteration 73 likelihood -59774.7814\n",
      "lml: iteration 74 likelihood -75224.0934\n",
      "lml: iteration 75 likelihood -55820.9885\n",
      "lml: iteration 76 likelihood -60745.2831\n",
      "lml: iteration 77 likelihood -68677.3946\n",
      "lml: iteration 78 likelihood -55849.0760\n",
      "lml: iteration 79 likelihood -44835.6044\n",
      "lml: iteration 80 likelihood -74057.7021\n",
      "lml: iteration 81 likelihood -64836.4686\n",
      "lengthscales: 1.0\n",
      "lml: iteration 82 likelihood -61298.2475\n",
      "lml: iteration 83 likelihood -53722.8585\n",
      "lml: iteration 84 likelihood -64247.4504\n",
      "lml: iteration 85 likelihood -56546.5483\n",
      "lml: iteration 86 likelihood -56073.4472\n",
      "lml: iteration 87 likelihood -66395.0641\n",
      "lml: iteration 88 likelihood -48690.5685\n",
      "lml: iteration 89 likelihood -50086.8696\n",
      "lml: iteration 90 likelihood -76763.5437\n",
      "lml: iteration 91 likelihood -46947.9483\n",
      "lengthscales: 1.0\n",
      "lml: iteration 92 likelihood -51722.9638\n",
      "lml: iteration 93 likelihood -66457.2949\n",
      "lml: iteration 94 likelihood -61579.4441\n",
      "lml: iteration 95 likelihood -69704.6214\n",
      "lml: iteration 96 likelihood -71043.0307\n",
      "lml: iteration 97 likelihood -57470.8640\n",
      "lml: iteration 98 likelihood -56824.0337\n",
      "lml: iteration 99 likelihood -52701.1029\n"
     ]
    }
   ],
   "source": [
    "gpflow.actions.Loop(actions, stop=100)()\n",
    "# m.anchor(m.enquire_session())  # <-- Why is this needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StoreSession' object has no attribute 'r'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b84054f0dc77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'StoreSession' object has no attribute 'r'"
     ]
    }
   ],
   "source": [
    "saver.r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an instance of `FileWriter`, which will save the TensorBoard logs to a file. This object needs to be shared between all `gpflow_monitor.TensorBoard` objects, if they are to write to the same path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fw = tf.summary.FileWriter(os.path.join(\"./results/test/tensorboard/\"), m.enquire_session().graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the TensorFlow side is set up, we can focus on the `gpflow_monitor` part. The optimsation is taken care of by the `ManagedOptimisation` class. This will run the training loop. The `ManagedOptimisation` object will also take care of running `Task`s.\n",
    "\n",
    "Each `Task` is something that needs to be run periodically during the optimisation. The first and second parameters of all tasks are a generator returning times (either in iterations or time) of when the `Task` needs to be run. The second determines whether a number of iterations (`Trigger.ITER`), an amount of time spent optimising (`Trigger.OPTIMISATION_TIME`), or the wall-clock time (`Trigger.TOTAL_TIME`) triggers the `Task` to be run. The following `Task`s are run once in every 100 or 1000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name full lml is illegal; using full_lml instead.\n"
     ]
    }
   ],
   "source": [
    "opt_method = ManagedOptimisation(m, gpflow.train.AdamOptimizer(0.01), global_step)\n",
    "opt_method.tasks += [\n",
    "    PrintTimings((x * 100 for x in itertools.count()), Trigger.ITER),\n",
    "    ModelTensorBoard((x * 100 for x in itertools.count()), Trigger.ITER, m, fw),\n",
    "    LmlTensorBoard((x * 1000 for x in itertools.count()), Trigger.ITER, m, fw, verbose=False),\n",
    "    StoreSession((x * 1000 for x in itertools.count()), Trigger.ITER, m.enquire_session(), \"./results/test/checkpoint\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also want to perfom certain tasks that do not have pre-defined `Task` classes. For example, computing the performance on a test set. Here we create such a class by extending `ModelTensorBoard` to log the testing benchmarks in addition to all the scalar parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestTensorBoard(ModelTensorBoard):\n",
    "    def __init__(self, sequence, trigger: Trigger, model, file_writer, Xt, Yt):\n",
    "        super().__init__(sequence, trigger, model, file_writer)\n",
    "        self.Xt = Xt\n",
    "        self.Yt = Yt\n",
    "        self._full_test_err = tf.placeholder(gpflow.settings.tf_float, shape=())\n",
    "        self._full_test_nlpp = tf.placeholder(gpflow.settings.tf_float, shape=())\n",
    "\n",
    "        self.summary = tf.summary.merge([tf.summary.scalar(\"test_rmse\", self._full_test_err),\n",
    "                                         tf.summary.scalar(\"test_nlpp\", self._full_test_nlpp)])\n",
    "\n",
    "    def _event_handler(self, manager):\n",
    "        minibatch_size = 100\n",
    "        preds = np.vstack([m.predict_y(Xt[mb * minibatch_size:(mb + 1) * minibatch_size, :])[0]\n",
    "                            for mb in range(-(-len(Xt) // minibatch_size))])\n",
    "        test_err = np.mean((Yt - preds) ** 2.0)**0.5\n",
    "        summary, step = m.enquire_session().run([self.summary, global_step],\n",
    "                                      feed_dict={self._full_test_err: test_err,\n",
    "                                                 self._full_test_nlpp: 0.0})\n",
    "        self.file_writer.add_summary(summary, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then add it to the task list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "opt_method.tasks.append(TestTensorBoard((x * 1000 for x in itertools.count()), Trigger.ITER, m, fw, Xt, Yt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the optimisation\n",
    "We finally get to running the optimisation. The second time this is run, the session should be restored from a checkpoint created by `StoreSession`. To confirm this, we print out the first value in all TensorFlow tensors. This includes any values used by the optimiser. This is important to ensure that the optimiser starts off from _exactly_ the same state as that it left. If this is not done correctly, models may start diverging after loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.54132327263575086,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.54132327263575086,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -4.6002665251585171,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.89999998,\n",
       " 0.99900001,\n",
       " 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = m.enquire_session()\n",
    "[u[1] if isinstance(u[1], numbers.Number) else u[1].flatten()[0]  for u in sorted([(v.name, sess.run(v)) for v in tf.global_variables()], key=lambda x: x[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 1:\t2.16 optimisation iter/s\t2.16 total iter/s\t0.00 last iter/sFull lml: -1198200.924550 (-1.20e+06)\n",
      "1000, 1000:\t454.39 optimisation iter/s\t325.05 total iter/s\t576.21 last iter/sFull lml: -30515.580038 (-3.05e+04)\n",
      "2000, 2000:\t506.20 optimisation iter/s\t367.32 total iter/s\t570.79 last iter/sFull lml: -17402.941729 (-1.74e+04)\n",
      "3000, 3000:\t527.07 optimisation iter/s\t384.49 total iter/s\t573.41 last iter/sFull lml: -15024.233225 (-1.50e+04)\n"
     ]
    }
   ],
   "source": [
    "opt_method.minimize(maxiter=8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we print the optimised variables for comparison on the next run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[u[1] if isinstance(u[1], numbers.Number) else u[1].flatten()[0]  for u in sorted([(v.name, sess.run(v)) for v in tf.global_variables()], key=lambda x: x[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
