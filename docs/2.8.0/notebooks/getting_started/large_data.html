<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Large Data with SGPR &#8212; GPflow 2.8.0 documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/pydata-custom.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Classification, other data distributions, VGP and SVGP" href="classification_and_other_data_distributions.html" />
    <link rel="prev" title="Parameters and Their Optimisation" href="parameters_and_their_optimisation.html" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">GPflow 2.8.0 documentation</p>
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../getting_started.html">
  Getting Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../user_guide.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/gpflow/index.html">
  API reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../benchmarks.html">
  Benchmarks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../bibliography.html">
  Bibliography
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        2.8.0  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables notebooks/getting_started/large_data and {'json_url': 'https://gpflow.github.io/GPflow/versions.json', 'version_match': '2.8.0'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "notebooks/getting_started/large_data.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://gpflow.github.io/GPflow/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "notebooks/getting_started/large_data.html";
        let btn = document.getElementById("version_switcher_button");
        // Set empty strings by default so that these attributes exist and can be used in CSS selectors
        btn.dataset["activeVersionName"] = "";
        btn.dataset["activeVersion"] = "";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's  variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "2.8.0") {
                node.classList.add("active");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../installation.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="basic_usage.html">
   Basic Usage with GPR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="kernels.html">
   Kernels
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="mean_functions.html">
   Mean Functions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="parameters_and_their_optimisation.html">
   Parameters and Their Optimisation
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Large Data with SGPR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="classification_and_other_data_distributions.html">
   Classification, other data distributions, VGP and SVGP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="monitoring.html">
   Monitoring
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="saving_and_loading.html">
   Saving and Loading Models
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Picking-initial-inducing-points">
   Picking initial inducing points
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Random-data-samples">
     Random data samples
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#k-means">
     k-means
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Uncorrelated-samples">
     Uncorrelated samples
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Advanced-initialisation">
     Advanced initialisation
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="Large-Data-with-SGPR">
<h1>Large Data with SGPR<a class="headerlink" href="#Large-Data-with-SGPR" title="Permalink to this heading">#</a></h1>
<p>Making predictions with Gaussian Processes is <span class="math notranslate nohighlight">\(O(N^3)\)</span>, which can be prohibitive for large <span class="math notranslate nohighlight">\(N\)</span>. In this chapter we introduce the Sparse Gaussian Process Regression (SGPR), which tries to solve this problem. The SGPR tries to approximate the <span class="math notranslate nohighlight">\(N\)</span> actual data points with <span class="math notranslate nohighlight">\(M\)</span> “inducing variables”. With inducing variables the SGPR can make predicitions in <span class="math notranslate nohighlight">\(O(NM^2)\)</span>, which can make a big difference if <span class="math notranslate nohighlight">\(M &lt;&lt; N\)</span>.</p>
<p>Note: For large datasets the “SVGP” model may also be relevant. See our section on <a class="reference internal" href="classification_and_other_data_distributions.html"><span class="doc">Classification and other data distributions</span></a>.</p>
<p>As usual we will start with our imports:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>

<span class="kn">import</span> <span class="nn">gpflow</span>
</pre></div>
</div>
</div>
<p>Although the sparse models are meant for large datasets, smaller datasets can be easier to understand, so we will reuse the same data we used in our <a class="reference internal" href="basic_usage.html"><span class="doc">Basic Usage</span></a> chapter:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mf">0.865</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.666</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.804</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.771</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.147</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.866</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.007</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.026</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.171</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.889</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.243</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.028</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mf">1.57</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.48</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.12</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.91</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.07</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.35</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.80</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.82</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.49</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">1.30</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.00</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.82</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;kx&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_getting_started_large_data_4_0.png" src="../../_images/notebooks_getting_started_large_data_4_0.png" />
</div>
</div>
<p>And a helper function for training and plotting our models:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPModel</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">data</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
    <span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">print_summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;notebook&quot;</span><span class="p">)</span>

    <span class="n">Xplot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">200</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>

    <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_var</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_y</span><span class="p">(</span><span class="n">Xplot</span><span class="p">,</span> <span class="n">full_cov</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">y_lower</span> <span class="o">=</span> <span class="n">y_mean</span> <span class="o">-</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_var</span><span class="p">)</span>
    <span class="n">y_upper</span> <span class="o">=</span> <span class="n">y_mean</span> <span class="o">+</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_var</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;kx&quot;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="p">(</span><span class="n">mean_line</span><span class="p">,)</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xplot</span><span class="p">,</span> <span class="n">y_mean</span><span class="p">,</span> <span class="s2">&quot;-&quot;</span><span class="p">)</span>
    <span class="n">color</span> <span class="o">=</span> <span class="n">mean_line</span><span class="o">.</span><span class="n">get_color</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xplot</span><span class="p">,</span> <span class="n">y_lower</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xplot</span><span class="p">,</span> <span class="n">y_upper</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">Xplot</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_lower</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">y_upper</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span>
    <span class="p">)</span>

    <span class="c1"># Also plot the inducing variables if possible:</span>
    <span class="n">iv</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;inducing_variable&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">iv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">iv</span><span class="o">.</span><span class="n">Z</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">iv</span><span class="o">.</span><span class="n">Z</span><span class="p">),</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;^&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>As a reference, let us try fitting our usual GPR. Notice that this works because our dataset here still is of a quite managable size. In practice you should only use an SGPR when your dataset is too large for a GPR:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPR</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">),</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(),</span>
<span class="p">)</span>
<span class="n">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                   </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">   value</th></tr>
</thead>
<tbody>
<tr><td>GPR.kernel.variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">11.6466 </td></tr>
<tr><td>GPR.kernel.lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;"> 0.37333</td></tr>
<tr><td>GPR.likelihood.variance</td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;"> 0.24001</td></tr>
</tbody>
</table></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_getting_started_large_data_8_1.png" src="../../_images/notebooks_getting_started_large_data_8_1.png" />
</div>
</div>
<p>Let us try fitting an SGPR. As mentioned above the SGPR is based on “inducing points” / “inducing variables”. The SGPR gains a speed-up by only capturing the shape of <span class="math notranslate nohighlight">\(f\)</span> at a small(ish) number of inducing points. We need tell the model where to put these. In this example we will use four inducing points, initially spaced evenly:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inducing_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.125</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.375</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.625</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.875</span><span class="p">]])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SGPR</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">),</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(),</span>
    <span class="n">inducing_variable</span><span class="o">=</span><span class="n">inducing_points</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                    </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th>value       </th></tr>
</thead>
<tbody>
<tr><td>SGPR.kernel.variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>11.79179    </td></tr>
<tr><td>SGPR.kernel.lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>0.38665     </td></tr>
<tr><td>SGPR.likelihood.variance</td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>0.24753     </td></tr>
<tr><td>SGPR.inducing_variable.Z</td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(4, 1) </td><td>float64</td><td>[[0.21006...</td></tr>
</tbody>
</table></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_getting_started_large_data_10_1.png" src="../../_images/notebooks_getting_started_large_data_10_1.png" />
</div>
</div>
<p>Here we get an excellent fit, even though the original data has 12 points, and we are approximating it with only four inducing points.</p>
<p>The blue triangles represent the positions of the inducing points.</p>
<p>You may notice that even though we initialised our inducing variables to be evenly spaced, they are spaced irregularly when plotting the model. The inducing variables are represent by a GPflow Parameter, and is optimised during model training, along with the other parameters.</p>
<p>For illustrative purposes, let us see what happens if we don’t use enough inducing points:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inducing_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.25</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">]])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SGPR</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">),</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(),</span>
    <span class="n">inducing_variable</span><span class="o">=</span><span class="n">inducing_points</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plot_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                    </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th>value  </th></tr>
</thead>
<tbody>
<tr><td>SGPR.kernel.variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>6.99571</td></tr>
<tr><td>SGPR.kernel.lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>1.09965</td></tr>
<tr><td>SGPR.likelihood.variance</td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td>0.57999</td></tr>
<tr><td>SGPR.inducing_variable.Z</td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(2, 1) </td><td>float64</td><td>[[0.12846]
 [0.82829]]        </td></tr>
</tbody>
</table></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_getting_started_large_data_13_1.png" src="../../_images/notebooks_getting_started_large_data_13_1.png" />
</div>
</div>
<p>The two inducing points above are not enough to capture the data well, so we get an overly simplistic <span class="math notranslate nohighlight">\(f\)</span>, and the model compensates with an overly high variance.</p>
<section id="Picking-initial-inducing-points">
<h2>Picking initial inducing points<a class="headerlink" href="#Picking-initial-inducing-points" title="Permalink to this heading">#</a></h2>
<p>When you use a sparse model you will need to pick initial inducing points, and choosing these correctly can have a large impact on performance. Above we used a simple grid. This often works well when your data is 1D, but we do not recommend using a grid for higher-dimensional data. In this section we discuss some alternatives.</p>
<p>First, let us declare some 2D data:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mf">0.70</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.53</span><span class="p">,</span> <span class="mf">0.81</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.78</span><span class="p">,</span> <span class="mf">0.36</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.83</span><span class="p">,</span> <span class="mf">0.09</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.71</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.66</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.87</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.63</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.37</span><span class="p">,</span> <span class="mf">0.90</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">,</span> <span class="mf">0.11</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.58</span><span class="p">,</span> <span class="mf">0.61</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.93</span><span class="p">,</span> <span class="mf">0.21</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.98</span><span class="p">,</span> <span class="mf">0.18</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.27</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.64</span><span class="p">,</span> <span class="mf">0.77</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.49</span><span class="p">,</span> <span class="mf">0.73</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.13</span><span class="p">,</span> <span class="mf">0.82</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.93</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.71</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.54</span><span class="p">,</span> <span class="mf">0.83</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.20</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.90</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.84</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.64</span><span class="p">,</span> <span class="mf">0.81</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.62</span><span class="p">,</span> <span class="mf">0.70</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">[</span><span class="mf">0.83</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.82</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.60</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.31</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.73</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.85</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.70</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.77</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.77</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.34</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.73</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.45</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.39</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.51</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.85</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.76</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.46</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.27</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.82</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.85</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.44</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.26</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.28</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.87</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.81</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>
<br/></pre></div>
</div>
</div>
<p>And write a helper-function to plot a model:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_2d_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPModel</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">n_grid</span> <span class="o">=</span> <span class="mi">50</span>
    <span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">ax_mean</span><span class="p">,</span> <span class="n">ax_std</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
    <span class="n">Xplots</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">n_grid</span><span class="p">)</span>
    <span class="n">Xplot1</span><span class="p">,</span> <span class="n">Xplot2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">Xplots</span><span class="p">,</span> <span class="n">Xplots</span><span class="p">)</span>
    <span class="n">Xplot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">Xplot1</span><span class="p">,</span> <span class="n">Xplot2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">Xplot</span> <span class="o">=</span> <span class="n">Xplot</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">n_grid</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

    <span class="n">iv</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;inducing_variable&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="c1"># Do not optimize inducing variables, so that we can better see the impact their choice has. When solving</span>
    <span class="c1"># a real problem you should generally optimise your inducing points.</span>
    <span class="k">if</span> <span class="n">iv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">gpflow</span><span class="o">.</span><span class="n">set_trainable</span><span class="p">(</span><span class="n">iv</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">opt</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>

    <span class="n">y_mean</span><span class="p">,</span> <span class="n">y_var</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_y</span><span class="p">(</span><span class="n">Xplot</span><span class="p">)</span>
    <span class="n">y_mean</span> <span class="o">=</span> <span class="n">y_mean</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">y_std</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">y_var</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="n">ax_mean</span><span class="o">.</span><span class="n">pcolor</span><span class="p">(</span><span class="n">Xplot1</span><span class="p">,</span> <span class="n">Xplot2</span><span class="p">,</span> <span class="n">y_mean</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Xplot1</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">ax_std</span><span class="o">.</span><span class="n">pcolor</span><span class="p">(</span><span class="n">Xplot1</span><span class="p">,</span> <span class="n">Xplot2</span><span class="p">,</span> <span class="n">y_std</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Xplot1</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">ax_mean</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
    <span class="n">ax_std</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>

    <span class="c1"># Also plot the inducing variables if possible:</span>
    <span class="k">if</span> <span class="n">iv</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax_mean</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">iv</span><span class="o">.</span><span class="n">Z</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">iv</span><span class="o">.</span><span class="n">Z</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let us first make a plot of a dense model, for comparison:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPR</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">),</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBF</span><span class="p">(),</span>
<span class="p">)</span>
<span class="n">plot_2d_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_getting_started_large_data_20_0.png" src="../../_images/notebooks_getting_started_large_data_20_0.png" />
</div>
</div>
<section id="Random-data-samples">
<h3>Random data samples<a class="headerlink" href="#Random-data-samples" title="Permalink to this heading">#</a></h3>
<p>A simple approach to selecting inducing points, is to randomly select a subset of your data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">n_inducing</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">inducing_variable</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_inducing</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SGPR</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">),</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBF</span><span class="p">(),</span>
    <span class="n">inducing_variable</span><span class="o">=</span><span class="n">inducing_variable</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plot_2d_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_getting_started_large_data_22_0.png" src="../../_images/notebooks_getting_started_large_data_22_0.png" />
</div>
</div>
</section>
<section id="k-means">
<h3>k-means<a class="headerlink" href="#k-means" title="Permalink to this heading">#</a></h3>
<p>Another good approach is to use the <a class="reference external" href="https://en.wikipedia.org/wiki/K-means_clustering">k-means algoritm</a>, which tries to find <span class="math notranslate nohighlight">\(k\)</span> centers of your data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.cluster.vq</span> <span class="kn">import</span> <span class="n">kmeans</span>

<span class="n">n_inducing</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">inducing_variable</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">kmeans</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_inducing</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SGPR</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">),</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBF</span><span class="p">(),</span>
    <span class="n">inducing_variable</span><span class="o">=</span><span class="n">inducing_variable</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plot_2d_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_getting_started_large_data_24_0.png" src="../../_images/notebooks_getting_started_large_data_24_0.png" />
</div>
</div>
</section>
<section id="Uncorrelated-samples">
<h3>Uncorrelated samples<a class="headerlink" href="#Uncorrelated-samples" title="Permalink to this heading">#</a></h3>
<p>It is a good idea to pick inducing points that are close to your data, which the above two algoritms does well. However they can struggle with some corner cases, such as if you do not (yet) have access to your data, or if you need to pick more inducing points than you have data. An approach that does not select points close to your data, but that can be more robust in some circumstances, is to use a <a class="reference external" href="https://en.wikipedia.org/wiki/Low-discrepancy_sequence">low-discrepancy sequence</a>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_dim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">n_inducing</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">inducing_variable</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">sample_halton_sequence</span><span class="p">(</span>
    <span class="n">n_dim</span><span class="p">,</span> <span class="n">n_inducing</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">1234</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SGPR</span><span class="p">(</span>
    <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">),</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">RBF</span><span class="p">(),</span>
    <span class="n">inducing_variable</span><span class="o">=</span><span class="n">inducing_variable</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plot_2d_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_getting_started_large_data_26_0.png" src="../../_images/notebooks_getting_started_large_data_26_0.png" />
</div>
</div>
</section>
<section id="Advanced-initialisation">
<h3>Advanced initialisation<a class="headerlink" href="#Advanced-initialisation" title="Permalink to this heading">#</a></h3>
<p>If none of the above approaches work well for you, we recommend that advanced users to look at the <a class="reference external" href="https://github.com/markvdw/RobustGP">RobustGP repository</a>.</p>
</section>
</section>
</section>


              </article>
              

              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2023, The GPflow Contributors.<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 7.0.0.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>