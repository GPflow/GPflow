<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Multi-output Gaussian processes in GPflow &#8212; GPflow 2.8.0 documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/pydata-custom.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="A simple demonstration of coregionalization" href="coregionalisation.html" />
    <link rel="prev" title="Convolutional Gaussian Processes" href="convolutional.html" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">GPflow 2.8.0 documentation</p>
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../getting_started.html">
  Getting Started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../user_guide.html">
  User Guide
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/gpflow/index.html">
  API reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../benchmarks.html">
  Benchmarks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../bibliography.html">
  Bibliography
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        2.8.0  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables notebooks/advanced/multioutput and {'json_url': 'https://gpflow.github.io/GPflow/versions.json', 'version_match': '2.8.0'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "notebooks/advanced/multioutput.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://gpflow.github.io/GPflow/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "notebooks/advanced/multioutput.html";
        let btn = document.getElementById("version_switcher_button");
        // Set empty strings by default so that these attributes exist and can be used in CSS selectors
        btn.dataset["activeVersionName"] = "";
        btn.dataset["activeVersion"] = "";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's  variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "2.8.0") {
                node.classList.add("active");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/vgp_notes.html">
   Derivation of VGP equations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/SGPR_notes.html">
   Derivation of SGPR equations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/cglb.html">
   Conjugate Gradient Lower Bound
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/upper_bound.html">
   Discussion of the GP marginal likelihood upper bound
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/FITCvsVFE.html">
   Comparing FITC approximation to VFE approximation
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/Sanity_check.html">
   Sanity checking when model behaviours should overlap
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/kernel_design.html">
   Kernel Design
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/gp_nn.html">
   Mixing TensorFlow models with GPflow
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/external-mean-function.html">
   Custom mean functions: metalearning with GPs
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/mixture_density_network.html">
   Mixture Density Networks in GPflow
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="mcmc.html">
   MCMC (Markov Chain Monte Carlo)
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ordinal_regression.html">
   Ordinal regression
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="gps_for_big_data.html">
   Stochastic Variational Inference for scalability with SVGP
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="multiclass_classification.html">
   Multiclass classification
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="varying_noise.html">
   Gaussian process regression with varying output noise
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="heteroskedastic.html">
   Heteroskedastic Likelihood and Multi-Latent GP
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="changepoints.html">
   Change points
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="convolutional.html">
   Convolutional Gaussian Processes
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Multi-output Gaussian processes in GPflow
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="coregionalisation.html">
   A simple demonstration of coregionalization
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="fast_predictions.html">
   Faster predictions by caching
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="GPLVM.html">
   Bayesian Gaussian process latent variable model (Bayesian GPLVM)
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="variational_fourier_features.html">
   Variational Fourier Features in the GPflow framework
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="natural_gradients.html">
   Natural gradients
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Task">
   Task
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Generate-synthetic-data">
   Generate synthetic data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Model-the-outputs-of-f(x)-directly">
   Model the outputs of
   <span class="math notranslate nohighlight">
    \(f(x)\)
   </span>
   directly
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#1.-Shared-independent-multi-output-kernel-(MOK)-and-shared-independent-inducing-variables">
     1. Shared independent multi-output kernel (MOK) and shared independent inducing variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#2.-Separate-independent-MOK-and-shared-independent-inducing-variables">
     2. Separate independent MOK and shared independent inducing variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#3.-Separate-independent-kernel-and-separate-independent-inducing-variables">
     3. Separate independent kernel and separate independent inducing variables
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Model-f(x)-by-doing-inference-in-the-g-space">
   Model
   <span class="math notranslate nohighlight">
    \(f(x)\)
   </span>
   by doing inference in the
   <span class="math notranslate nohighlight">
    \(g\)
   </span>
   space
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Mixed-kernel-and-uncorrelated-inducing-variables">
     Mixed kernel and uncorrelated inducing variables
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Illustration-of-GPflow's-multi-output-capabilities">
   Illustration of GPflow’s multi-output capabilities
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Multi-output-kernels-(MOK)-class-diagram">
     Multi-output kernels (MOK) class diagram
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Multi-output-inducing-variables-class-diagram">
     Multi-output inducing variables class diagram
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#Inducing-points">
       Inducing points
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#Fallback-shared/separate-independent-inducing-variables">
       Fallback shared/separate independent inducing variables
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#Shared/separate-independent-inducing-variables">
       Shared/separate independent inducing variables
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Implemented-combinations">
     Implemented combinations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Debugging:-introspect">
   Debugging: introspect
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Further-Reading:">
   Further Reading:
  </a>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="Multi-output-Gaussian-processes-in-GPflow">
<h1>Multi-output Gaussian processes in GPflow<a class="headerlink" href="#Multi-output-Gaussian-processes-in-GPflow" title="Permalink to this heading">#</a></h1>
<p>This notebook shows how to construct a multi-output GP model using GPflow, together with different interdomain inducing variables which lead to different approximation properties. GPflow provides a framework for specifying multioutput GP priors, and interdomain approximations which is - modular, by providing a consistent interface for the user of the resulting <code class="docutils literal notranslate"><span class="pre">SVGP</span></code> model, - extensible, by allowing new interdomain variables and kernels to be specified while reusing exising code where
possible, - efficient, by allowing the most efficient custom code path to be specified where desired.</p>
<p>Getting to grips with the maths and code can be a bit daunting, so to accompany the documentation there is an <a class="reference external" href="https://arxiv.org/abs/2003.01115">in-depth review on arXiv</a>, which provides a unified mathematical framework, together with a high-level description of software design choices in GPflow.</p>
<p>This notebook shows the various design choices that can be made, to show the reader the flexibility of the framework. This is done in the hope that an example is provided that can be easily adapted to the special case that the reader wants to implement.</p>
<p>A reader who just wants to use a multioutput kernel should simply choose the most efficient set of inducing variables.</p>
<p>To cite this framework, please reference our <a class="reference external" href="https://arxiv.org/abs/2003.01115">arXiv paper</a>.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>@article{GPflow2020multioutput,
  author = {{van der Wilk}, Mark and Dutordoir, Vincent and John, ST and
            Artemev, Artem and Adam, Vincent and Hensman, James},
  title = {A Framework for Interdomain and Multioutput {G}aussian Processes},
  year = {2020},
  journal = {arXiv:2003.01115},
  url = {https://arxiv.org/abs/2003.01115}
}
</pre></div>
</div>
<p><span class="math">\begin{equation}
\newcommand{\GP}{\mathcal{GP}}
\newcommand{\NN}{\mathcal{N}}
\newcommand{\LL}{\mathcal{L}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\valpha}{\boldsymbol\alpha}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vW}{\mathbf{W}}
\newcommand{\vI}{\mathbf{I}}
\newcommand{\vZ}{\mathbf{Z}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vU}{\mathbf{U}}
\newcommand{\vX}{\mathbf{X}}
\newcommand{\vY}{\mathbf{Y}}
\newcommand{\identity}{\mathbb{I}}
\end{equation}</span></p>
<section id="Task">
<h2>Task<a class="headerlink" href="#Task" title="Permalink to this heading">#</a></h2>
<p>We will consider a regression problem for functions <span class="math notranslate nohighlight">\(f: \mathbb{R}^D \rightarrow \mathbb{R}^P\)</span>. We assume that the dataset is of the form <span class="math notranslate nohighlight">\((X, f_1), \dots, (X, f_P)\)</span>, that is, we observe all the outputs for a particular input location (for cases where there are <strong>not</strong> fully observed outputs for each input, see <a class="reference internal" href="coregionalisation.html"><span class="doc">A simple demonstration of coregionalization</span></a>).</p>
<p>Here we assume a model of the form: <span class="math">\begin{equation}
f(x) = W g(x),
\end{equation}</span> where <span class="math notranslate nohighlight">\(g(x) \in \mathbb{R}^L\)</span>, <span class="math notranslate nohighlight">\(f(x) \in \mathbb{R}^P\)</span> and <span class="math notranslate nohighlight">\(W \in \mathbb{R}^{P \times L}\)</span>. We assume that the outputs of <span class="math notranslate nohighlight">\(g\)</span> are uncorrelated, and that by <em>mixing</em> them with <span class="math notranslate nohighlight">\(W\)</span> they become correlated. In this notebook, we show how to build this model using Sparse Variational Gaussian Process (SVGP) for <span class="math notranslate nohighlight">\(g\)</span>, which scales well with the numbers of data points and outputs.</p>
<p>Here we have two options for <span class="math notranslate nohighlight">\(g\)</span>: 1. The output dimensions of <span class="math notranslate nohighlight">\(g\)</span> share the same kernel. 2. Each output of <span class="math notranslate nohighlight">\(g\)</span> has a separate kernel.</p>
<p>In addition, we have two further suboptions for the inducing inputs of <span class="math notranslate nohighlight">\(g\)</span>: 1. The instances of <span class="math notranslate nohighlight">\(g\)</span> share the same inducing inputs. 2. Each output of <span class="math notranslate nohighlight">\(g\)</span> has its own set of inducing inputs.</p>
<p>The notation is as follows: - <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{N \times D}\)</span> denotes the input - <span class="math notranslate nohighlight">\(Y \in \RR^{N \times P}\)</span> denotes the output - <span class="math notranslate nohighlight">\(k_{1..L}\)</span>, <span class="math notranslate nohighlight">\(L\)</span> are kernels on <span class="math notranslate nohighlight">\(\RR^{N \times D}\)</span> - <span class="math notranslate nohighlight">\(g_{1..L}\)</span>, <span class="math notranslate nohighlight">\(L\)</span> are independent <span class="math notranslate nohighlight">\(\GP\)</span>s with <span class="math notranslate nohighlight">\(g_l \sim \GP(0,k_l)\)</span> - <span class="math notranslate nohighlight">\(f_{1..P}\)</span>, <span class="math notranslate nohighlight">\(P\)</span> are correlated <span class="math notranslate nohighlight">\(\GP\)</span>s with <span class="math notranslate nohighlight">\(\vf = \vW \vg\)</span></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">gpflow</span> <span class="k">as</span> <span class="nn">gpf</span>
<span class="kn">from</span> <span class="nn">gpflow.ci_utils</span> <span class="kn">import</span> <span class="n">reduce_in_tests</span>
<span class="kn">from</span> <span class="nn">gpflow.utilities</span> <span class="kn">import</span> <span class="n">print_summary</span>

<span class="n">gpf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">gpf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_summary_fmt</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">MAXITER</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2023-05-03 23:15:04.331498: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-05-03 23:15:04.462766: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2023-05-03 23:15:04.462784: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2023-05-03 23:15:04.503390: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2023-05-03 23:15:05.290499: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer.so.7&#39;; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2023-05-03 23:15:05.290590: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer_plugin.so.7&#39;; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2023-05-03 23:15:05.290601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
</pre></div></div>
</div>
</section>
<section id="Generate-synthetic-data">
<h2>Generate synthetic data<a class="headerlink" href="#Generate-synthetic-data" title="Permalink to this heading">#</a></h2>
<p>We create a utility function to generate synthetic data. We assume that:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># number of points</span>
<span class="n">D</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># number of input dimensions</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># number of inducing points</span>
<span class="n">L</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># number of latent GPs</span>
<span class="n">P</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of observations = output dimensions</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">-</span> <span class="mi">5</span>  <span class="c1"># Inputs = N x D</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span> <span class="mf">3.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">-</span> <span class="n">X</span><span class="p">))</span>  <span class="c1"># G = N x L</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]])</span>  <span class="c1"># L x P</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>  <span class="c1"># N x P</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">F</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">data</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">Zinit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">M</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>We create a utility function for plotting:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_model</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">8.0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">8.0</span><span class="p">):</span>
    <span class="n">pX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="mi">100</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">pY</span><span class="p">,</span> <span class="n">pYv</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_y</span><span class="p">(</span><span class="n">pX</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pY</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">pY</span> <span class="o">=</span> <span class="n">pY</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pX</span><span class="p">,</span> <span class="n">pY</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">top</span> <span class="o">=</span> <span class="n">pY</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">pYv</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span>
        <span class="n">bot</span> <span class="o">=</span> <span class="n">pY</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">pYv</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">pX</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">top</span><span class="p">,</span> <span class="n">bot</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;f&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ELBO: </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">:</span><span class="s2">.3</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">Z</span> <span class="o">*</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;o&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Model-the-outputs-of-f(x)-directly">
<h2>Model the outputs of <span class="math notranslate nohighlight">\(f(x)\)</span> directly<a class="headerlink" href="#Model-the-outputs-of-f(x)-directly" title="Permalink to this heading">#</a></h2>
<p>The three following examples show how to model the outputs of the model <span class="math notranslate nohighlight">\(f(x)\)</span> directly. Mathematically, this case is equivalent to having: <span class="math">\begin{equation}
f(x) = I g(x),
\end{equation}</span> i.e. <span class="math notranslate nohighlight">\(W = I\)</span> and <span class="math notranslate nohighlight">\(P = L\)</span>.</p>
<section id="1.-Shared-independent-multi-output-kernel-(MOK)-and-shared-independent-inducing-variables">
<h3>1. Shared independent multi-output kernel (MOK) and shared independent inducing variables<a class="headerlink" href="#1.-Shared-independent-multi-output-kernel-(MOK)-and-shared-independent-inducing-variables" title="Permalink to this heading">#</a></h3>
<p>Here the priors on all outputs are constrained to have the same kernel hyperparameters. We also share the inducing inputs between all outputs. The different GPs are independent both in the prior and the approximate posterior.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create multi-output kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SharedIndependent</span><span class="p">(</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">()</span> <span class="o">+</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Linear</span><span class="p">(),</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">P</span>
<span class="p">)</span>
<span class="c1"># initialization of inducing input locations (M random points from the training inputs)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Zinit</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># create multi-output inducing variables from Z</span>
<span class="n">iv</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">SharedIndependentInducingVariables</span><span class="p">(</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">InducingPoints</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2023-05-03 23:15:08.466066: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2023-05-03 23:15:08.466087: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2023-05-03 23:15:08.466106: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (d64c43fc0b71): /proc/driver/nvidia/version does not exist
2023-05-03 23:15:08.466371: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create SVGP model as usual and optimize</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">(</span>
    <span class="n">kernel</span><span class="p">,</span> <span class="n">gpf</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(),</span> <span class="n">inducing_variable</span><span class="o">=</span><span class="n">iv</span><span class="p">,</span> <span class="n">num_latent_gps</span><span class="o">=</span><span class="n">P</span>
<span class="p">)</span>
<span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                                      </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value           </th></tr>
</thead>
<tbody>
<tr><td>SVGP.kernel.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0             </td></tr>
<tr><td>SVGP.kernel.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0             </td></tr>
<tr><td>SVGP.kernel.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0             </td></tr>
<tr><td>SVGP.likelihood.variance                  </td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0             </td></tr>
<tr><td>SVGP.inducing_variable.inducing_variable.Z</td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(15, 1)    </td><td>float64</td><td>[[-5....        </td></tr>
<tr><td>SVGP.q_mu                                 </td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(15, 3)    </td><td>float64</td><td>[[0., 0., 0.... </td></tr>
<tr><td>SVGP.q_sqrt                               </td><td>Parameter</td><td>FillTriangular  </td><td>       </td><td>True       </td><td>(3, 15, 15)</td><td>float64</td><td>[[[1., 0., 0....</td></tr>
</tbody>
</table></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">optimize_model_with_scipy</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">training_loss_closure</span><span class="p">(</span><span class="n">data</span><span class="p">),</span>
        <span class="n">variables</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;l-bfgs-b&quot;</span><span class="p">,</span>
        <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;disp&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span> <span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="n">MAXITER</span><span class="p">},</span>
    <span class="p">)</span>


<span class="n">optimize_model_with_scipy</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =          424     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  3.26251D+03    |proj g|=  1.79322D+03

At iterate   50    f=  1.60046D+02    |proj g|=  2.23880D+01

At iterate  100    f=  6.24335D+01    |proj g|=  2.64482D+01
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 This problem is unconstrained.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

At iterate  150    f=  5.47594D+01    |proj g|=  2.30324D+01

At iterate  200    f=  5.09409D+01    |proj g|=  1.79887D+01

At iterate  250    f=  4.85812D+01    |proj g|=  1.69594D+01

At iterate  300    f=  4.68431D+01    |proj g|=  1.00237D+01

At iterate  350    f=  4.56696D+01    |proj g|=  6.56927D+00

At iterate  400    f=  4.46591D+01    |proj g|=  7.61969D+00

At iterate  450    f=  4.37202D+01    |proj g|=  9.01165D+00

At iterate  500    f=  4.30875D+01    |proj g|=  8.36795D+00

At iterate  550    f=  4.27808D+01    |proj g|=  1.06301D+01

At iterate  600    f=  4.26544D+01    |proj g|=  2.51395D+00

At iterate  650    f=  4.25500D+01    |proj g|=  2.33529D+00

At iterate  700    f=  4.24944D+01    |proj g|=  2.56079D+00

At iterate  750    f=  4.24630D+01    |proj g|=  8.78334D-01

At iterate  800    f=  4.24463D+01    |proj g|=  4.26999D-01

At iterate  850    f=  4.24381D+01    |proj g|=  4.16215D-01

At iterate  900    f=  4.24335D+01    |proj g|=  4.11149D-01

At iterate  950    f=  4.24295D+01    |proj g|=  8.49405D-01

At iterate 1000    f=  4.24265D+01    |proj g|=  1.33535D+00

At iterate 1050    f=  4.24249D+01    |proj g|=  1.05105D-01

At iterate 1100    f=  4.24240D+01    |proj g|=  3.28053D-01

At iterate 1150    f=  4.24235D+01    |proj g|=  1.67576D-01

At iterate 1200    f=  4.24230D+01    |proj g|=  1.49874D-01

At iterate 1250    f=  4.24225D+01    |proj g|=  5.82735D-02

At iterate 1300    f=  4.24221D+01    |proj g|=  1.34652D-01

At iterate 1350    f=  4.24218D+01    |proj g|=  2.27220D-01

At iterate 1400    f=  4.24214D+01    |proj g|=  1.21356D-01

At iterate 1450    f=  4.24211D+01    |proj g|=  2.22174D-01

At iterate 1500    f=  4.24208D+01    |proj g|=  2.25751D-01

At iterate 1550    f=  4.24205D+01    |proj g|=  1.64768D-01

At iterate 1600    f=  4.24205D+01    |proj g|=  3.55818D-02

At iterate 1650    f=  4.24204D+01    |proj g|=  2.40386D-02

At iterate 1700    f=  4.24204D+01    |proj g|=  1.07473D-01

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
  424   1700   1813      1     0     0   1.075D-01   4.242D+01
  F =   42.420424440816490

CONVERGENCE: REL_REDUCTION_OF_F_&lt;=_FACTR*EPSMCH
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                                      </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value                                   </th></tr>
</thead>
<tbody>
<tr><td>SVGP.kernel.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.92725                                 </td></tr>
<tr><td>SVGP.kernel.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.79819                                 </td></tr>
<tr><td>SVGP.kernel.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.2139                                  </td></tr>
<tr><td>SVGP.likelihood.variance                  </td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.03966                                 </td></tr>
<tr><td>SVGP.inducing_variable.inducing_variable.Z</td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(15, 1)    </td><td>float64</td><td>[[-4.83959...                           </td></tr>
<tr><td>SVGP.q_mu                                 </td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(15, 3)    </td><td>float64</td><td>[[-0.90097, 0.69851, -1.4739...         </td></tr>
<tr><td>SVGP.q_sqrt                               </td><td>Parameter</td><td>FillTriangular  </td><td>       </td><td>True       </td><td>(3, 15, 15)</td><td>float64</td><td>[[[1.7120e-02, 0.0000e+00, 0.0000e+00...</td></tr>
</tbody>
</table></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot predictions and observations</span>
<span class="n">plot_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_multioutput_15_0.png" src="../../_images/notebooks_advanced_multioutput_15_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lengthscales</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                                            </th><th>class    </th><th>transform  </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>SharedIndependent.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.92725</td></tr>
<tr><td>SharedIndependent.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.79819</td></tr>
<tr><td>SharedIndependent.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">1.2139 </td></tr>
</tbody>
</table></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=0.7981918482945918&gt;
</pre></div></div>
</div>
</section>
<section id="2.-Separate-independent-MOK-and-shared-independent-inducing-variables">
<h3>2. Separate independent MOK and shared independent inducing variables<a class="headerlink" href="#2.-Separate-independent-MOK-and-shared-independent-inducing-variables" title="Permalink to this heading">#</a></h3>
<p>Here we allow different hyperparameters for the priors of each output. We still share the inducing inputs between all outputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create list of kernels for each output</span>
<span class="n">kern_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">()</span> <span class="o">+</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Linear</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="p">]</span>
<span class="c1"># Create multi-output kernel from kernel list</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SeparateIndependent</span><span class="p">(</span><span class="n">kern_list</span><span class="p">)</span>
<span class="c1"># initialization of inducing input locations (M random points from the training inputs)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Zinit</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># create multi-output inducing variables from Z</span>
<span class="n">iv</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">SharedIndependentInducingVariables</span><span class="p">(</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">InducingPoints</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create SVGP model as usual and optimize</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">(</span>
    <span class="n">kernel</span><span class="p">,</span> <span class="n">gpf</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(),</span> <span class="n">inducing_variable</span><span class="o">=</span><span class="n">iv</span><span class="p">,</span> <span class="n">num_latent_gps</span><span class="o">=</span><span class="n">P</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimize_model_with_scipy</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /tmp/max_venv/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =          430     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  3.26251D+03    |proj g|=  1.79322D+03
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 This problem is unconstrained.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

At iterate   50    f=  1.94337D+02    |proj g|=  7.19142D+00

At iterate  100    f=  1.66814D+02    |proj g|=  3.26283D+01

At iterate  150    f=  6.00999D+01    |proj g|=  2.15028D+01

At iterate  200    f=  4.97328D+01    |proj g|=  1.95679D+01

At iterate  250    f=  4.64796D+01    |proj g|=  8.71966D+00

At iterate  300    f=  4.44078D+01    |proj g|=  5.29028D+00

At iterate  350    f=  4.30525D+01    |proj g|=  9.00944D+00

At iterate  400    f=  4.15516D+01    |proj g|=  1.03807D+01

At iterate  450    f=  4.04783D+01    |proj g|=  9.62300D+00

At iterate  500    f=  3.97566D+01    |proj g|=  6.23925D+00

At iterate  550    f=  3.89135D+01    |proj g|=  2.19500D+01

At iterate  600    f=  3.82752D+01    |proj g|=  9.02205D+00

At iterate  650    f=  3.79721D+01    |proj g|=  3.18852D+00

At iterate  700    f=  3.77513D+01    |proj g|=  2.32701D+00

At iterate  750    f=  3.75961D+01    |proj g|=  8.92977D+00

At iterate  800    f=  3.74777D+01    |proj g|=  2.63936D+00

At iterate  850    f=  3.73929D+01    |proj g|=  2.87805D+00

At iterate  900    f=  3.73332D+01    |proj g|=  1.00035D+00

At iterate  950    f=  3.72974D+01    |proj g|=  1.60231D+00

At iterate 1000    f=  3.72751D+01    |proj g|=  1.69327D+00

At iterate 1050    f=  3.72575D+01    |proj g|=  5.20291D-01

At iterate 1100    f=  3.72450D+01    |proj g|=  1.99396D+00

At iterate 1150    f=  3.72328D+01    |proj g|=  1.45785D+00

At iterate 1200    f=  3.72250D+01    |proj g|=  5.66249D-01

At iterate 1250    f=  3.72197D+01    |proj g|=  2.88656D+00

At iterate 1300    f=  3.72131D+01    |proj g|=  3.59536D-01

At iterate 1350    f=  3.72047D+01    |proj g|=  8.53286D-01

At iterate 1400    f=  3.71976D+01    |proj g|=  1.43617D+00

At iterate 1450    f=  3.71928D+01    |proj g|=  2.20744D-01

At iterate 1500    f=  3.71874D+01    |proj g|=  1.19581D+00

At iterate 1550    f=  3.71839D+01    |proj g|=  4.57358D-01

At iterate 1600    f=  3.71815D+01    |proj g|=  2.80283D-01

At iterate 1650    f=  3.71800D+01    |proj g|=  1.86547D-01

At iterate 1700    f=  3.71792D+01    |proj g|=  1.92775D-01

At iterate 1750    f=  3.71787D+01    |proj g|=  1.79399D-01

At iterate 1800    f=  3.71785D+01    |proj g|=  2.37693D-01

At iterate 1850    f=  3.71783D+01    |proj g|=  1.12377D-01

At iterate 1900    f=  3.71782D+01    |proj g|=  1.58807D-01

At iterate 1950    f=  3.71781D+01    |proj g|=  9.27521D-02

At iterate 2000    f=  3.71780D+01    |proj g|=  1.01838D-01

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
  430   2000   2140      1     0     0   1.018D-01   3.718D+01
  F =   37.178028020708659

STOP: TOTAL NO. of ITERATIONS REACHED LIMIT
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                                                  </th><th>class    </th><th>transform  </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>SeparateIndependent.kernels[0].kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.86408</td></tr>
<tr><td>SeparateIndependent.kernels[0].kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.93467</td></tr>
<tr><td>SeparateIndependent.kernels[0].kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.86262</td></tr>
<tr><td>SeparateIndependent.kernels[1].kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.75081</td></tr>
<tr><td>SeparateIndependent.kernels[1].kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.96981</td></tr>
<tr><td>SeparateIndependent.kernels[1].kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.53054</td></tr>
<tr><td>SeparateIndependent.kernels[2].kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">1.11149</td></tr>
<tr><td>SeparateIndependent.kernels[2].kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.74912</td></tr>
<tr><td>SeparateIndependent.kernels[2].kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">2.21307</td></tr>
</tbody>
</table></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_multioutput_22_0.png" src="../../_images/notebooks_advanced_multioutput_22_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">k</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lengthscales</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=0.9346736406655387&gt;,
 &lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=0.9698064672110547&gt;,
 &lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=0.7491181736855458&gt;]
</pre></div></div>
</div>
</section>
<section id="3.-Separate-independent-kernel-and-separate-independent-inducing-variables">
<h3>3. Separate independent kernel and separate independent inducing variables<a class="headerlink" href="#3.-Separate-independent-kernel-and-separate-independent-inducing-variables" title="Permalink to this heading">#</a></h3>
<p>Here we allow different hyperparameters for the priors of each output. We now allow different inducing inputs for each output.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create list of kernels for each output</span>
<span class="n">kern_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">()</span> <span class="o">+</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Linear</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="p">]</span>
<span class="c1"># Create multi-output kernel from kernel list</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SeparateIndependent</span><span class="p">(</span><span class="n">kern_list</span><span class="p">)</span>
<span class="c1"># initialization of inducing input locations, one set of locations per output</span>
<span class="n">Zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Zinit</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">P</span><span class="p">)]</span>
<span class="c1"># initialize as list inducing inducing variables</span>
<span class="n">iv_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">InducingPoints</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="k">for</span> <span class="n">Z</span> <span class="ow">in</span> <span class="n">Zs</span><span class="p">]</span>
<span class="c1"># create multi-output inducing variables from iv_list</span>
<span class="n">iv</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">SeparateIndependentInducingVariables</span><span class="p">(</span><span class="n">iv_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><strong>NOTE:</strong> While the inducing points are independent, there needs to be the same number of inducing points per dimension.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create SVGP model as usual and optimize</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">(</span>
    <span class="n">kernel</span><span class="p">,</span> <span class="n">gpf</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(),</span> <span class="n">inducing_variable</span><span class="o">=</span><span class="n">iv</span><span class="p">,</span> <span class="n">num_latent_gps</span><span class="o">=</span><span class="n">P</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimize_model_with_scipy</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =          460     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  3.26251D+03    |proj g|=  1.79322D+03
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 This problem is unconstrained.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

At iterate   50    f=  1.91729D+02    |proj g|=  6.27078D+00

At iterate  100    f=  1.05481D+02    |proj g|=  4.93334D+01

At iterate  150    f=  5.20108D+01    |proj g|=  2.94272D+01

At iterate  200    f=  4.67145D+01    |proj g|=  2.18349D+01

At iterate  250    f=  4.42325D+01    |proj g|=  2.92998D+01

At iterate  300    f=  4.28052D+01    |proj g|=  6.52055D+00

At iterate  350    f=  4.12258D+01    |proj g|=  7.51169D+00

At iterate  400    f=  3.96203D+01    |proj g|=  9.03021D+00

At iterate  450    f=  3.86267D+01    |proj g|=  6.21595D+00

At iterate  500    f=  3.81482D+01    |proj g|=  4.72608D+00

At iterate  550    f=  3.79072D+01    |proj g|=  3.26377D+00

At iterate  600    f=  3.77769D+01    |proj g|=  3.26844D+00

At iterate  650    f=  3.76880D+01    |proj g|=  2.81014D+00

At iterate  700    f=  3.75912D+01    |proj g|=  2.54230D+00

At iterate  750    f=  3.74843D+01    |proj g|=  1.60409D+00

At iterate  800    f=  3.73878D+01    |proj g|=  3.66023D+00

At iterate  850    f=  3.72751D+01    |proj g|=  1.80375D+00

At iterate  900    f=  3.72000D+01    |proj g|=  5.29436D+00

At iterate  950    f=  3.71556D+01    |proj g|=  1.57365D+00

At iterate 1000    f=  3.71109D+01    |proj g|=  1.92874D+00

At iterate 1050    f=  3.70677D+01    |proj g|=  4.03134D+00

At iterate 1100    f=  3.70264D+01    |proj g|=  1.65964D+00

At iterate 1150    f=  3.70021D+01    |proj g|=  1.94705D+00

At iterate 1200    f=  3.69893D+01    |proj g|=  7.90922D-01

At iterate 1250    f=  3.69794D+01    |proj g|=  6.15579D-01

At iterate 1300    f=  3.69724D+01    |proj g|=  8.61087D-01

At iterate 1350    f=  3.69680D+01    |proj g|=  8.38448D-01

At iterate 1400    f=  3.69652D+01    |proj g|=  5.08162D-01

At iterate 1450    f=  3.69621D+01    |proj g|=  4.89696D-01

At iterate 1500    f=  3.69592D+01    |proj g|=  7.00189D-01

At iterate 1550    f=  3.69560D+01    |proj g|=  5.52089D-01

At iterate 1600    f=  3.69537D+01    |proj g|=  1.50911D-01

At iterate 1650    f=  3.69521D+01    |proj g|=  8.23773D-01

At iterate 1700    f=  3.69512D+01    |proj g|=  1.88230D-01

At iterate 1750    f=  3.69506D+01    |proj g|=  2.76983D-01

At iterate 1800    f=  3.69502D+01    |proj g|=  7.08849D-01

At iterate 1850    f=  3.69499D+01    |proj g|=  5.98787D-01

At iterate 1900    f=  3.69495D+01    |proj g|=  2.53047D-01

At iterate 1950    f=  3.69491D+01    |proj g|=  2.12177D-01

At iterate 2000    f=  3.69488D+01    |proj g|=  1.45673D-01

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
  460   2000   2141      1     0     0   1.457D-01   3.695D+01
  F =   36.948765982874498

STOP: TOTAL NO. of ITERATIONS REACHED LIMIT
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_multioutput_29_0.png" src="../../_images/notebooks_advanced_multioutput_29_0.png" />
</div>
</div>
<p>The following plot shows that we use different inducing <em>inputs</em> in each output dimension.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">inducing_variable</span><span class="o">.</span><span class="n">inducing_variable_list</span><span class="p">)):</span>
    <span class="n">q_mu_unwhitened</span><span class="p">,</span> <span class="n">q_var_unwhitened</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_f</span><span class="p">(</span>
        <span class="n">m</span><span class="o">.</span><span class="n">inducing_variable</span><span class="o">.</span><span class="n">inducing_variable_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">Z</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">m</span><span class="o">.</span><span class="n">inducing_variable</span><span class="o">.</span><span class="n">inducing_variable_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">Z</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
        <span class="n">q_mu_unwhitened</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
        <span class="s2">&quot;o&quot;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">minor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">minor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s2">&quot;minor&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_multioutput_31_0.png" src="../../_images/notebooks_advanced_multioutput_31_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">inducing_variable</span><span class="o">.</span><span class="n">inducing_variable_list</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ListWrapper([&lt;gpflow.inducing_variables.inducing_variables.InducingPoints object at 0x7f44683f6050&gt;, &lt;gpflow.inducing_variables.inducing_variables.InducingPoints object at 0x7f44683f7ac0&gt;, &lt;gpflow.inducing_variables.inducing_variables.InducingPoints object at 0x7f44683f6e90&gt;])
</pre></div></div>
</div>
</section>
</section>
<section id="Model-f(x)-by-doing-inference-in-the-g-space">
<h2>Model <span class="math notranslate nohighlight">\(f(x)\)</span> by doing inference in the <span class="math notranslate nohighlight">\(g\)</span> space<a class="headerlink" href="#Model-f(x)-by-doing-inference-in-the-g-space" title="Permalink to this heading">#</a></h2>
<section id="Mixed-kernel-and-uncorrelated-inducing-variables">
<h3>Mixed kernel and uncorrelated inducing variables<a class="headerlink" href="#Mixed-kernel-and-uncorrelated-inducing-variables" title="Permalink to this heading">#</a></h3>
<p>Remember the general case: <span class="math notranslate nohighlight">\(f(x) = W g(x)\)</span>, where <span class="math notranslate nohighlight">\(g(x) \in \mathbb{R}^L\)</span>, <span class="math notranslate nohighlight">\(f(x) \in \mathbb{R}^P\)</span> and <span class="math notranslate nohighlight">\(W \in \mathbb{R}^{P \times L}\)</span>, where <span class="math notranslate nohighlight">\(L \leq P\)</span>. We assume that the outputs of <span class="math notranslate nohighlight">\(g\)</span> are uncorrelated, and by <em>mixing</em> them with <span class="math notranslate nohighlight">\(W\)</span> they become correlated. With this setup we perform the optimal routine to calculate the conditional. Namely, calculate the conditional of the uncorrelated latent <span class="math notranslate nohighlight">\(g\)</span> and afterwards project the mean and variance using
the mixing matrix: <span class="math notranslate nohighlight">\(\mu_f = W \mu_g\)</span> and <span class="math notranslate nohighlight">\(\Sigma_f = W\Sigma_g W^\top\)</span></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(K_{uu} = L \times M \times M\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(K_{uf} = L \times M \times N\)</span></p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create list of kernels for each output</span>
<span class="n">kern_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">()</span> <span class="o">+</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Linear</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
<span class="p">]</span>
<span class="c1"># Create multi-output kernel from kernel list</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">LinearCoregionalization</span><span class="p">(</span>
    <span class="n">kern_list</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>
<span class="p">)</span>  <span class="c1"># Notice that we initialise the mixing matrix W</span>
<span class="c1"># initialisation of inducing input locations (M random points from the training inputs)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Zinit</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># create multi-output inducing variables from Z</span>
<span class="n">iv</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">SharedIndependentInducingVariables</span><span class="p">(</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">InducingPoints</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize mean of variational posterior to be of shape MxL</span>
<span class="n">q_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">L</span><span class="p">))</span>
<span class="c1"># initialize \sqrt(Σ) of variational posterior to be of shape LxMxM</span>
<span class="n">q_sqrt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">M</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">L</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span>

<span class="c1"># create SVGP model as usual and optimize</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">(</span>
    <span class="n">kernel</span><span class="p">,</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(),</span>
    <span class="n">inducing_variable</span><span class="o">=</span><span class="n">iv</span><span class="p">,</span>
    <span class="n">q_mu</span><span class="o">=</span><span class="n">q_mu</span><span class="p">,</span>
    <span class="n">q_sqrt</span><span class="o">=</span><span class="n">q_sqrt</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimize_model_with_scipy</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 This problem is unconstrained.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =          298     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  7.44521D+03    |proj g|=  6.62929D+03

At iterate   50    f=  3.17536D+02    |proj g|=  4.85678D+00

At iterate  100    f=  1.84264D+02    |proj g|=  1.74463D+02

At iterate  150    f=  1.18739D+02    |proj g|=  1.20540D+02

At iterate  200    f=  4.03397D+01    |proj g|=  7.37977D+01

At iterate  250    f=  2.35736D+01    |proj g|=  3.19784D+01

At iterate  300    f=  1.85507D+01    |proj g|=  1.90258D+01

At iterate  350    f=  1.38568D+01    |proj g|=  2.18620D+01

At iterate  400    f=  1.06028D+01    |proj g|=  3.83948D+01

At iterate  450    f=  8.44384D+00    |proj g|=  1.64975D+01

At iterate  500    f=  6.90463D+00    |proj g|=  7.77259D+00

At iterate  550    f=  5.55241D+00    |proj g|=  1.50941D+01

At iterate  600    f=  4.41403D+00    |proj g|=  1.54117D+01

At iterate  650    f=  3.67700D+00    |proj g|=  1.88611D+01

At iterate  700    f=  3.19464D+00    |proj g|=  3.68109D+00

At iterate  750    f=  2.86225D+00    |proj g|=  1.10662D+01

At iterate  800    f=  2.55773D+00    |proj g|=  3.86343D+00

At iterate  850    f=  2.02080D+00    |proj g|=  6.48201D+00

At iterate  900    f=  1.64970D+00    |proj g|=  2.93980D+00

At iterate  950    f=  1.47558D+00    |proj g|=  8.81754D+00

At iterate 1000    f=  1.34171D+00    |proj g|=  1.41515D+00

At iterate 1050    f=  1.26776D+00    |proj g|=  1.10931D+00

At iterate 1100    f=  1.21259D+00    |proj g|=  2.60048D+00

At iterate 1150    f=  1.13337D+00    |proj g|=  8.38712D-01

At iterate 1200    f=  1.02389D+00    |proj g|=  1.74448D+00

At iterate 1250    f=  9.45899D-01    |proj g|=  5.74669D+00

At iterate 1300    f=  8.89688D-01    |proj g|=  2.71870D+00

At iterate 1350    f=  8.30694D-01    |proj g|=  2.65540D+00

At iterate 1400    f=  7.87407D-01    |proj g|=  2.00173D+00

At iterate 1450    f=  7.49752D-01    |proj g|=  1.18554D+00

At iterate 1500    f=  7.27385D-01    |proj g|=  1.23276D+00

At iterate 1550    f=  7.09314D-01    |proj g|=  1.69974D+00

At iterate 1600    f=  6.97240D-01    |proj g|=  5.40155D-01

At iterate 1650    f=  6.87100D-01    |proj g|=  1.30062D+00

At iterate 1700    f=  6.77038D-01    |proj g|=  7.07311D-01

At iterate 1750    f=  6.67227D-01    |proj g|=  1.13528D+00

At iterate 1800    f=  6.59190D-01    |proj g|=  9.66881D-01

At iterate 1850    f=  6.50920D-01    |proj g|=  3.86379D+00

At iterate 1900    f=  6.43698D-01    |proj g|=  3.26855D-01

At iterate 1950    f=  6.37257D-01    |proj g|=  2.48417D-01

At iterate 2000    f=  6.32587D-01    |proj g|=  7.10780D-01

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
  298   2000   2193      1     0     0   7.108D-01   6.326D-01
  F =  0.63258728580373713

STOP: TOTAL NO. of ITERATIONS REACHED LIMIT
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_multioutput_37_0.png" src="../../_images/notebooks_advanced_multioutput_37_0.png" />
</div>
</div>
</section>
</section>
<section id="Illustration-of-GPflow's-multi-output-capabilities">
<h2>Illustration of GPflow’s multi-output capabilities<a class="headerlink" href="#Illustration-of-GPflow's-multi-output-capabilities" title="Permalink to this heading">#</a></h2>
<p>This section shows the inheritance structure in GPflow’s multi-output framework.</p>
<section id="Multi-output-kernels-(MOK)-class-diagram">
<h3>Multi-output kernels (MOK) class diagram<a class="headerlink" href="#Multi-output-kernels-(MOK)-class-diagram" title="Permalink to this heading">#</a></h3>
<p>We include three multi-output kernels: - <code class="docutils literal notranslate"><span class="pre">SharedIndependent</span></code>: This kernel is included mainly as an illustration of specifying a conditional using the multiple dispatch framework. The same functionality is provided by using a normal kernel and passing in multiple approximate posteriors by stacking <code class="docutils literal notranslate"><span class="pre">q_mu</span></code> and <code class="docutils literal notranslate"><span class="pre">q_sqrt</span></code>. - <code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code>: This kernel allows you to use different priors for each output GP. - <code class="docutils literal notranslate"><span class="pre">LinearCoregionalization</span></code>: This kernel describes the prior of the linear
model of coregionalization. As shown previously, this implementation supports various inducing point approximations. <img alt="Multi-output kernels" src="../../_images/multioutput_kernels.svg" /></p>
<p>We include several base classes. Two are noteworthy: - <code class="docutils literal notranslate"><span class="pre">MultioutputKernel</span></code> is included to be the base class for all multi-output kernels. - <code class="docutils literal notranslate"><span class="pre">IndepedentLatent</span></code> is the base class for all multi-output kernels which are constructed from independent latent processes. Including this kernel allows the specification of a default approximation method which, while not the most efficient, does take advantage of <em>some</em> structure. It can be applied to <em>any</em> kernel constructed from independent latent
processes.</p>
<p>There is a similarity in the meaning of <code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code> and <code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code>. Both kernels indicate that independent processes are used, and that <span class="math notranslate nohighlight">\(\mathbf{K}_{\bf uu}\)</span> can therefore be represented as a <code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code> tensor. It could therefore be suggested that <code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code> be the parent class of all “independent latent” kernels, instead of having a separate <code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code> class. We decided against this because: - this would increase the complexity in
specifying <code class="docutils literal notranslate"><span class="pre">conditionals()</span></code> for the otherwise simple multi-output kernels <code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code> and <code class="docutils literal notranslate"><span class="pre">SharedIndependent</span></code>. - we did not want to specify too much of an implementation in <code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code>, leaving implementation details to child classes. Using <code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code> as the base class would force all child classes to be a <code class="docutils literal notranslate"><span class="pre">Combination</span></code> kernel.</p>
</section>
<section id="Multi-output-inducing-variables-class-diagram">
<h3>Multi-output inducing variables class diagram<a class="headerlink" href="#Multi-output-inducing-variables-class-diagram" title="Permalink to this heading">#</a></h3>
<p><img alt="Multi-output features" src="../../_images/multioutput_features.svg" /></p>
<section id="Inducing-points">
<h4>Inducing points<a class="headerlink" href="#Inducing-points" title="Permalink to this heading">#</a></h4>
<p>The goal of this class is to provide inducing variables that can be used with <em>any</em> kernel, even if the method ends up being slow.</p>
<p>The multiouput framework extends <code class="docutils literal notranslate"><span class="pre">InducingPoints</span></code> to work with multi-output kernels. Just like for single-output kernels, we want <code class="docutils literal notranslate"><span class="pre">InducingPoints</span></code> to work for all <code class="docutils literal notranslate"><span class="pre">MultioutputKernel</span></code>s. We do this by defining <code class="docutils literal notranslate"><span class="pre">InducingPoints</span></code> to take <em>all</em> outputs for specific inducing inputs as inducing variables.</p>
</section>
<section id="Fallback-shared/separate-independent-inducing-variables">
<h4>Fallback shared/separate independent inducing variables<a class="headerlink" href="#Fallback-shared/separate-independent-inducing-variables" title="Permalink to this heading">#</a></h4>
<p>The goal of these classes is to provide a reasonably efficient implementation for kernels that give exploitable independence structure in the prior of inducing variables (that is, subclasses of <code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code>), while only needing to implement <code class="docutils literal notranslate"><span class="pre">Kuu()</span></code> and <code class="docutils literal notranslate"><span class="pre">Kuf()</span></code> methods.</p>
</section>
<section id="Shared/separate-independent-inducing-variables">
<h4>Shared/separate independent inducing variables<a class="headerlink" href="#Shared/separate-independent-inducing-variables" title="Permalink to this heading">#</a></h4>
<p>The goal of these classes is to provide the most efficient code path for kernels that allow exploiting independence structure in the prior of inducing variables.</p>
<p>For more specialized multi-output kernels (i.e. <code class="docutils literal notranslate"><span class="pre">{Shared|Separate}Independent</span></code> or <code class="docutils literal notranslate"><span class="pre">LinearCoregionalization</span></code>) we define <code class="docutils literal notranslate"><span class="pre">{Shared|Separate}IndependentInducingVariables</span></code>. These wrap (a list of) single-output inducing variables to define groups of a-priori independent inducing variables, which leads to a <span class="math notranslate nohighlight">\(\mathbf{K}_{\bf uu}\)</span> that can be represented as a <code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code> tensor. We saw the use of these previously.</p>
<p><code class="docutils literal notranslate"><span class="pre">{Shared|Separate}IndependentInducingVariables</span></code> inherit from <code class="docutils literal notranslate"><span class="pre">Fallback{Shared|Separate}IndependentInducingVariables</span></code>, so the multiple dispatch will fall back on the slower but general implementation.</p>
</section>
</section>
<section id="Implemented-combinations">
<h3>Implemented combinations<a class="headerlink" href="#Implemented-combinations" title="Permalink to this heading">#</a></h3>
<p>Multiple dispatch is applied to both <code class="docutils literal notranslate"><span class="pre">Kuu()</span></code>, <code class="docutils literal notranslate"><span class="pre">Kuf()</span></code>, and <code class="docutils literal notranslate"><span class="pre">conditional()</span></code>. The return values of the covariances can therefore be tailored to a specific implementation of <code class="docutils literal notranslate"><span class="pre">conditional()</span></code>. The following table lists combinations which are currently available in GPflow. Thanks to the multiple dispatch code, implementing your own outside of GPflow should require only a small amount of code!</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Inducing variable class</p></th>
<th class="head"><p>Kernel</p></th>
<th class="head"><p>Kuu</p></th>
<th class="head"><p>Kuf</p></th>
<th class="head"><p>conditional</p></th>
<th class="head"><p>note</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">InducingPoints</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">MultioutputKernel</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">P,</span> <span class="pre">M,</span> <span class="pre">P]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">P,</span> <span class="pre">N,</span> <span class="pre">P]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">inducing_point_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">fully_correlated_conditional()</span></code></p></td>
<td><p>Works for all kernels, but might be
very inefficient. In this case
<code class="docutils literal notranslate"><span class="pre">q_mu</span></code> and <code class="docutils literal notranslate"><span class="pre">q_sqrt</span></code> should have
shapes of <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">MP]</span></code> and
<code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">MP,</span> <span class="pre">MP]</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">SharedIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SharedIndependent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">shared_independent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
<td><p>The combination of these two classes
is in a sense redundant, because we
can achieve the same behavior by
using the single output Kernel and
InducingVariable classes. They are
added for illustrative purposes.
Thanks to the conditional dispatch,
the most efficient code path is
used.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">SeparateIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SharedIndependent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">separate_independent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code> P times</p></td>
<td><p>We loop P times over the
<code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">SeparateIndependentInducingVariable</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">separate_independent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code> P times</p></td>
<td><p>We loop P times over the
<code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">SharedIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">separate_independent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code> P times</p></td>
<td><p>We loop P times over the
<code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">FallbackSharedIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">L,</span> <span class="pre">N,</span> <span class="pre">P]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">fallback_independent_latent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">independent_interdomain_conditional()</span></code></p></td>
<td><p>Implementation which only requires
custom <code class="docutils literal notranslate"><span class="pre">Kuu()</span></code> and <code class="docutils literal notranslate"><span class="pre">Kuf()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">FallbackSeparateIndependentInducingVariable</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">L,</span> <span class="pre">N,</span> <span class="pre">P]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">fallback_independent_latent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">independent_interdomain_conditional()</span></code></p></td>
<td><p>Implementation which only requires
custom <code class="docutils literal notranslate"><span class="pre">Kuu()</span></code> and <code class="docutils literal notranslate"><span class="pre">Kuf()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">SharedIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">LinearCoregionalization</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">coregionalization_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
<td><p>This is the most efficient
implementation for linear
coregionalization. The inducing
outputs live in g-space. Here we use
the output of the base conditional
and project the mean and covariance
with the mixing matrix W.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">SeparateIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">LinearCoregionalization</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
<td><p>This is the most efficient
implementation for linear
coregionalization. The inducing
outputs live in g-space. Here we use
the output of the base conditional
and project the mean and covariance
with the mixing matrix W.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="Debugging:-introspect">
<h2>Debugging: introspect<a class="headerlink" href="#Debugging:-introspect" title="Permalink to this heading">#</a></h2>
<p>Given all these possibilities it can be hard to determine which conditional will be called for which set of kernel and inducing variable. The following method lets you proactively introspect which implementation will be executed. This can be useful when debugging new code.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">inspect_conditional</span><span class="p">(</span><span class="n">inducing_variable_type</span><span class="p">,</span> <span class="n">kernel_type</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function returning the exact implementation called</span>
<span class="sd">    by the multiple dispatch `conditional` given the type of</span>
<span class="sd">    kernel and inducing variable.</span>

<span class="sd">    :param inducing_variable_type:</span>
<span class="sd">        Type of the inducing variable</span>
<span class="sd">    :param kernel_type:</span>
<span class="sd">        Type of the kernel</span>

<span class="sd">    :return: String</span>
<span class="sd">        Contains the name, the file and the linenumber of the</span>
<span class="sd">        implementation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">inspect</span>

    <span class="kn">from</span> <span class="nn">gpflow.conditionals</span> <span class="kn">import</span> <span class="n">conditional</span>

    <span class="n">implementation</span> <span class="o">=</span> <span class="n">conditional</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
        <span class="nb">object</span><span class="p">,</span> <span class="n">inducing_variable_type</span><span class="p">,</span> <span class="n">kernel_type</span><span class="p">,</span> <span class="nb">object</span>
    <span class="p">)</span>
    <span class="n">info</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">getmembers</span><span class="p">(</span><span class="n">implementation</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">info</span><span class="p">[</span><span class="s2">&quot;__code__&quot;</span><span class="p">]</span>


<span class="c1"># Example:</span>
<span class="n">inspect_conditional</span><span class="p">(</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">SharedIndependentInducingVariables</span><span class="p">,</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SharedIndependent</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;code object wrapped_function at 0x7f44742296e0, file &#34;/tmp/max_venv/lib/python3.10/site-packages/check_shapes/decorator.py&#34;, line 118&gt;
</pre></div></div>
</div>
</section>
<section id="Further-Reading:">
<h2>Further Reading:<a class="headerlink" href="#Further-Reading:" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="coregionalisation.html"><span class="doc">A simple demonstration of coregionalization</span></a>, which details other GPflow features for multi-output prediction without fully observed outputs.</p></li>
</ul>
</section>
</section>


              </article>
              

              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2023, The GPflow Contributors.<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 7.0.0.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>