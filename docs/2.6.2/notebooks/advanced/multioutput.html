
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Multi-output Gaussian processes in GPflow &#8212; GPflow 2.6.2 documentation</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1e1de1a1873e13ef5536" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1e1de1a1873e13ef5536" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/pydata-custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1e1de1a1873e13ef5536">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/advanced/multioutput';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://gpflow.github.io/GPflow/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '2.6.2';
        </script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Natural gradients" href="natural_gradients.html" />
    <link rel="prev" title="Multiclass classification" href="multiclass_classification.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../index.html">

  
  
  
  
  
  
  

  
    <img src="../../_static/gpflow_logo.svg" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/gpflow_logo.svg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../../intro.html">
                        Introduction
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../manual.html">
                        GPflow manual
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../intro_to_gpflow2.html">
                        GPflow with TensorFlow 2
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="../../notebooks_file.html">
                        Notebooks
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../derivations.html">
                        Derivations
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../../api/gpflow/index.html">
                        API reference
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../bibliography.html">
                        Bibliography
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <div class="version-switcher__container dropdown">
    <button type="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-toggle="dropdown">
        2.6.2  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div class="version-switcher__menu dropdown-menu list-group-flush py-0">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>
      </div>
      
    </div>
  </div>


  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
  </div>

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../../intro.html">
                        Introduction
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../manual.html">
                        GPflow manual
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../intro_to_gpflow2.html">
                        GPflow with TensorFlow 2
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="../../notebooks_file.html">
                        Notebooks
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../derivations.html">
                        Derivations
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../../api/gpflow/index.html">
                        API reference
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../bibliography.html">
                        Bibliography
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <div class="version-switcher__container dropdown">
    <button type="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-toggle="dropdown">
        2.6.2  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div class="version-switcher__menu dropdown-menu list-group-flush py-0">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
    Section Navigation
  </p>
  <div class="bd-toc-item navbar-nav">
    <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../basics/GPLVM.html">Bayesian Gaussian process latent variable model (Bayesian GPLVM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/classification.html">Basic (binary) GP classification model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/monitoring.html">Monitoring Optimisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/regression.html">Basic (Gaussian likelihood) GP regression model</a></li>
</ul>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="changepoints.html">Change points</a></li>
<li class="toctree-l1"><a class="reference internal" href="convolutional.html">Convolutional Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="coregionalisation.html">A simple demonstration of coregionalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="fast_predictions.html">Faster predictions by caching</a></li>
<li class="toctree-l1"><a class="reference internal" href="gps_for_big_data.html">Stochastic Variational Inference for scalability with SVGP</a></li>
<li class="toctree-l1"><a class="reference internal" href="heteroskedastic.html">Heteroskedastic Likelihood and Multi-Latent GP</a></li>
<li class="toctree-l1"><a class="reference internal" href="kernels.html">Manipulating kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="mcmc.html">MCMC (Markov Chain Monte Carlo)</a></li>
<li class="toctree-l1"><a class="reference internal" href="multiclass_classification.html">Multiclass classification</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Multi-output Gaussian processes in GPflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="natural_gradients.html">Natural gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="ordinal_regression.html">Ordinal regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="variational_fourier_features.html">Variational Fourier Features in the GPflow framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="varying_noise.html">Gaussian process regression with varying output noise</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tailor/external-mean-function.html">Custom mean functions: metalearning with GPs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tailor/gp_nn.html">Mixing TensorFlow models with GPflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tailor/kernel_design.html">Kernel Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tailor/mixture_density_network.html">Mixture Density Networks in GPflow</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../theory/FITCvsVFE.html">Comparing FITC approximation to VFE approximation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/SGPR_notes.html">Derivation of SGPR equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/Sanity_check.html">Sanity checking when model behaviours should overlap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/cglb.html">Conjugate Gradient Lower Bound</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/upper_bound.html">Discussion of the GP marginal likelihood upper bound</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/vgp_notes.html">Derivation of VGP equations</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../understanding/models.html">Manipulating GPflow models</a></li>
</ul>

  </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

      </div>
      <main class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="Multi-output-Gaussian-processes-in-GPflow">
<h1>Multi-output Gaussian processes in GPflow<a class="headerlink" href="#Multi-output-Gaussian-processes-in-GPflow" title="Permalink to this heading">#</a></h1>
<p>This notebook shows how to construct a multi-output GP model using GPflow, together with different interdomain inducing variables which lead to different approximation properties. GPflow provides a framework for specifying multioutput GP priors, and interdomain approximations which is - modular, by providing a consistent interface for the user of the resulting <code class="docutils literal notranslate"><span class="pre">SVGP</span></code> model, - extensible, by allowing new interdomain variables and kernels to be specified while reusing exising code where
possible, - efficient, by allowing the most efficient custom code path to be specified where desired.</p>
<p>Getting to grips with the maths and code can be a bit daunting, so to accompany the documentation there is an <a class="reference external" href="https://arxiv.org/abs/2003.01115">in-depth review on arXiv</a>, which provides a unified mathematical framework, together with a high-level description of software design choices in GPflow.</p>
<p>This notebook shows the various design choices that can be made, to show the reader the flexibility of the framework. This is done in the hope that an example is provided that can be easily adapted to the special case that the reader wants to implement.</p>
<p>A reader who just wants to use a multioutput kernel should simply choose the most efficient set of inducing variables.</p>
<p>To cite this framework, please reference our <a class="reference external" href="https://arxiv.org/abs/2003.01115">arXiv paper</a>.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>@article{GPflow2020multioutput,
  author = {{van der Wilk}, Mark and Dutordoir, Vincent and John, ST and
            Artemev, Artem and Adam, Vincent and Hensman, James},
  title = {A Framework for Interdomain and Multioutput {G}aussian Processes},
  year = {2020},
  journal = {arXiv:2003.01115},
  url = {https://arxiv.org/abs/2003.01115}
}
</pre></div>
</div>
<p><span class="math">\begin{equation}
\newcommand{\GP}{\mathcal{GP}}
\newcommand{\NN}{\mathcal{N}}
\newcommand{\LL}{\mathcal{L}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\valpha}{\boldsymbol\alpha}
\newcommand{\vf}{\mathbf{f}}
\newcommand{\vF}{\mathbf{F}}
\newcommand{\vg}{\mathbf{g}}
\newcommand{\vW}{\mathbf{W}}
\newcommand{\vI}{\mathbf{I}}
\newcommand{\vZ}{\mathbf{Z}}
\newcommand{\vu}{\mathbf{u}}
\newcommand{\vU}{\mathbf{U}}
\newcommand{\vX}{\mathbf{X}}
\newcommand{\vY}{\mathbf{Y}}
\newcommand{\identity}{\mathbb{I}}
\end{equation}</span></p>
<section id="Task">
<h2>Task<a class="headerlink" href="#Task" title="Permalink to this heading">#</a></h2>
<p>We will consider a regression problem for functions <span class="math notranslate nohighlight">\(f: \mathbb{R}^D \rightarrow \mathbb{R}^P\)</span>. We assume that the dataset is of the form <span class="math notranslate nohighlight">\((X, f_1), \dots, (X, f_P)\)</span>, that is, we observe all the outputs for a particular input location (for cases where there are <strong>not</strong> fully observed outputs for each input, see <a class="reference internal" href="coregionalisation.html"><span class="doc">A simple demonstration of coregionalization</span></a>).</p>
<p>Here we assume a model of the form: <span class="math">\begin{equation}
f(x) = W g(x),
\end{equation}</span> where <span class="math notranslate nohighlight">\(g(x) \in \mathbb{R}^L\)</span>, <span class="math notranslate nohighlight">\(f(x) \in \mathbb{R}^P\)</span> and <span class="math notranslate nohighlight">\(W \in \mathbb{R}^{P \times L}\)</span>. We assume that the outputs of <span class="math notranslate nohighlight">\(g\)</span> are uncorrelated, and that by <em>mixing</em> them with <span class="math notranslate nohighlight">\(W\)</span> they become correlated. In this notebook, we show how to build this model using Sparse Variational Gaussian Process (SVGP) for <span class="math notranslate nohighlight">\(g\)</span>, which scales well with the numbers of data points and outputs.</p>
<p>Here we have two options for <span class="math notranslate nohighlight">\(g\)</span>: 1. The output dimensions of <span class="math notranslate nohighlight">\(g\)</span> share the same kernel. 1. Each output of <span class="math notranslate nohighlight">\(g\)</span> has a separate kernel.</p>
<p>In addition, we have two further suboptions for the inducing inputs of <span class="math notranslate nohighlight">\(g\)</span>: 1. The instances of <span class="math notranslate nohighlight">\(g\)</span> share the same inducing inputs. 1. Each output of <span class="math notranslate nohighlight">\(g\)</span> has its own set of inducing inputs.</p>
<p>The notation is as follows: - <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{N \times D}\)</span> denotes the input - <span class="math notranslate nohighlight">\(Y \in \RR^{N \times P}\)</span> denotes the output - <span class="math notranslate nohighlight">\(k_{1..L}\)</span>, <span class="math notranslate nohighlight">\(L\)</span> are kernels on <span class="math notranslate nohighlight">\(\RR^{N \times D}\)</span> - <span class="math notranslate nohighlight">\(g_{1..L}\)</span>, <span class="math notranslate nohighlight">\(L\)</span> are independent <span class="math notranslate nohighlight">\(\GP\)</span>s with <span class="math notranslate nohighlight">\(g_l \sim \GP(0,k_l)\)</span> - <span class="math notranslate nohighlight">\(f_{1..P}\)</span>, <span class="math notranslate nohighlight">\(P\)</span> are correlated <span class="math notranslate nohighlight">\(\GP\)</span>s with <span class="math notranslate nohighlight">\(\vf = \vW \vg\)</span></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">gpflow</span> <span class="k">as</span> <span class="nn">gpf</span>
<span class="kn">from</span> <span class="nn">gpflow.ci_utils</span> <span class="kn">import</span> <span class="n">reduce_in_tests</span>
<span class="kn">from</span> <span class="nn">gpflow.utilities</span> <span class="kn">import</span> <span class="n">print_summary</span>

<span class="n">gpf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">gpf</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_summary_fmt</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">MAXITER</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">2000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-10-10 13:39:04.590036: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-10 13:39:04.733510: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-10-10 13:39:04.733532: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-10-10 13:39:04.763774: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-10-10 13:39:05.464329: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer.so.7&#39;; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-10-10 13:39:05.464402: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer_plugin.so.7&#39;; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-10-10 13:39:05.464415: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You&#39;re calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.
  warn(
/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You&#39;re calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.
  warn(
</pre></div></div>
</div>
</section>
<section id="Generate-synthetic-data">
<h2>Generate synthetic data<a class="headerlink" href="#Generate-synthetic-data" title="Permalink to this heading">#</a></h2>
<p>We create a utility function to generate synthetic data. We assume that:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># number of points</span>
<span class="n">D</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># number of input dimensions</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">15</span>  <span class="c1"># number of inducing points</span>
<span class="n">L</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># number of latent GPs</span>
<span class="n">P</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># number of observations = output dimensions</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_data</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">-</span> <span class="mi">5</span>  <span class="c1"># Inputs = N x D</span>
    <span class="n">G</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">3</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">X</span><span class="p">,</span> <span class="mf">3.0</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">-</span> <span class="n">X</span><span class="p">))</span>  <span class="c1"># G = N x L</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.43</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]])</span>  <span class="c1"># L x P</span>
    <span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>  <span class="c1"># N x P</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">F</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">F</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">data</span> <span class="o">=</span> <span class="n">generate_data</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">Zinit</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">M</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>We create a utility function for plotting:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_model</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">lower</span><span class="o">=-</span><span class="mf">8.0</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="mf">8.0</span><span class="p">):</span>
    <span class="n">pX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">,</span> <span class="mi">100</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">pY</span><span class="p">,</span> <span class="n">pYv</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_y</span><span class="p">(</span><span class="n">pX</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pY</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="n">pY</span> <span class="o">=</span> <span class="n">pY</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">pX</span><span class="p">,</span> <span class="n">pY</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">pY</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">top</span> <span class="o">=</span> <span class="n">pY</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">pYv</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span>
        <span class="n">bot</span> <span class="o">=</span> <span class="n">pY</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">pYv</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">**</span> <span class="mf">0.5</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">pX</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">top</span><span class="p">,</span> <span class="n">bot</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;f&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ELBO: </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">:</span><span class="s2">.3</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">Z</span> <span class="o">*</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;o&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Model-the-outputs-of-f(x)-directly">
<h2>Model the outputs of <span class="math notranslate nohighlight">\(f(x)\)</span> directly<a class="headerlink" href="#Model-the-outputs-of-f(x)-directly" title="Permalink to this heading">#</a></h2>
<p>The three following examples show how to model the outputs of the model <span class="math notranslate nohighlight">\(f(x)\)</span> directly. Mathematically, this case is equivalent to having: <span class="math">\begin{equation}
f(x) = I g(x),
\end{equation}</span> i.e.Â <span class="math notranslate nohighlight">\(W = I\)</span> and <span class="math notranslate nohighlight">\(P = L\)</span>.</p>
<section id="1.-Shared-independent-multi-output-kernel-(MOK)-and-shared-independent-inducing-variables">
<h3>1. Shared independent multi-output kernel (MOK) and shared independent inducing variables<a class="headerlink" href="#1.-Shared-independent-multi-output-kernel-(MOK)-and-shared-independent-inducing-variables" title="Permalink to this heading">#</a></h3>
<p>Here the priors on all outputs are constrained to have the same kernel hyperparameters. We also share the inducing inputs between all outputs. The different GPs are independent both in the prior and the approximate posterior.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create multi-output kernel</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SharedIndependent</span><span class="p">(</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">()</span> <span class="o">+</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Linear</span><span class="p">(),</span> <span class="n">output_dim</span><span class="o">=</span><span class="n">P</span>
<span class="p">)</span>
<span class="c1"># initialization of inducing input locations (M random points from the training inputs)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Zinit</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># create multi-output inducing variables from Z</span>
<span class="n">iv</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">SharedIndependentInducingVariables</span><span class="p">(</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">InducingPoints</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You&#39;re calling gpflow.experimental.check_shapes.checker.ShapeChecker.__init__ which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.
  warn(
2022-10-10 13:39:08.219157: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-10-10 13:39:08.219389: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2022-10-10 13:39:08.219415: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bf92644da0ec): /proc/driver/nvidia/version does not exist
2022-10-10 13:39:08.220022: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create SVGP model as usual and optimize</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">(</span>
    <span class="n">kernel</span><span class="p">,</span> <span class="n">gpf</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(),</span> <span class="n">inducing_variable</span><span class="o">=</span><span class="n">iv</span><span class="p">,</span> <span class="n">num_latent_gps</span><span class="o">=</span><span class="n">P</span>
<span class="p">)</span>
<span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                                      </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value           </th></tr>
</thead>
<tbody>
<tr><td>SVGP.kernel.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0             </td></tr>
<tr><td>SVGP.kernel.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0             </td></tr>
<tr><td>SVGP.kernel.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0             </td></tr>
<tr><td>SVGP.likelihood.variance                  </td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0             </td></tr>
<tr><td>SVGP.inducing_variable.inducing_variable.Z</td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(15, 1)    </td><td>float64</td><td>[[-5....        </td></tr>
<tr><td>SVGP.q_mu                                 </td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(15, 3)    </td><td>float64</td><td>[[0., 0., 0.... </td></tr>
<tr><td>SVGP.q_sqrt                               </td><td>Parameter</td><td>FillTriangular  </td><td>       </td><td>True       </td><td>(3, 15, 15)</td><td>float64</td><td>[[[1., 0., 0....</td></tr>
</tbody>
</table></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">optimize_model_with_scipy</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
        <span class="n">model</span><span class="o">.</span><span class="n">training_loss_closure</span><span class="p">(</span><span class="n">data</span><span class="p">),</span>
        <span class="n">variables</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span>
        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;l-bfgs-b&quot;</span><span class="p">,</span>
        <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;disp&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span> <span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="n">MAXITER</span><span class="p">},</span>
    <span class="p">)</span>


<span class="n">optimize_model_with_scipy</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 This problem is unconstrained.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =          424     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  3.26251D+03    |proj g|=  1.79322D+03

At iterate   50    f=  1.60046D+02    |proj g|=  2.23880D+01

At iterate  100    f=  6.25482D+01    |proj g|=  2.71201D+01

At iterate  150    f=  5.46511D+01    |proj g|=  1.08489D+01

At iterate  200    f=  5.04147D+01    |proj g|=  9.69613D+00

At iterate  250    f=  4.81768D+01    |proj g|=  6.17771D+00

At iterate  300    f=  4.64853D+01    |proj g|=  1.63270D+01

At iterate  350    f=  4.53993D+01    |proj g|=  2.58286D+00

At iterate  400    f=  4.45053D+01    |proj g|=  1.75085D+00

At iterate  450    f=  4.37208D+01    |proj g|=  9.96513D+00

At iterate  500    f=  4.30009D+01    |proj g|=  7.76101D+00

At iterate  550    f=  4.27248D+01    |proj g|=  1.73770D+00

At iterate  600    f=  4.26050D+01    |proj g|=  1.99376D+00

At iterate  650    f=  4.25214D+01    |proj g|=  2.13490D+00

At iterate  700    f=  4.24760D+01    |proj g|=  1.29972D+00

At iterate  750    f=  4.24513D+01    |proj g|=  1.92102D+00

At iterate  800    f=  4.24395D+01    |proj g|=  3.95727D-01

At iterate  850    f=  4.24342D+01    |proj g|=  1.09160D+00

At iterate  900    f=  4.24302D+01    |proj g|=  2.21299D-01

At iterate  950    f=  4.24268D+01    |proj g|=  3.62403D-01

At iterate 1000    f=  4.24250D+01    |proj g|=  3.53533D-01

At iterate 1050    f=  4.24241D+01    |proj g|=  8.04352D-02

At iterate 1100    f=  4.24236D+01    |proj g|=  1.52831D-01

At iterate 1150    f=  4.24231D+01    |proj g|=  3.58038D-01

At iterate 1200    f=  4.24223D+01    |proj g|=  4.90681D-01

At iterate 1250    f=  4.24220D+01    |proj g|=  1.03745D-01

At iterate 1300    f=  4.24218D+01    |proj g|=  8.42608D-02

At iterate 1350    f=  4.24216D+01    |proj g|=  5.29683D-02

At iterate 1400    f=  4.24213D+01    |proj g|=  1.53513D-01

At iterate 1450    f=  4.24211D+01    |proj g|=  2.80217D-01

At iterate 1500    f=  4.24209D+01    |proj g|=  4.67469D-02

At iterate 1550    f=  4.24207D+01    |proj g|=  6.32664D-02

At iterate 1600    f=  4.24207D+01    |proj g|=  1.13515D-01

At iterate 1650    f=  4.24206D+01    |proj g|=  6.66171D-02

At iterate 1700    f=  4.24206D+01    |proj g|=  3.85838D-02

At iterate 1750    f=  4.24205D+01    |proj g|=  4.35149D-02

At iterate 1800    f=  4.24205D+01    |proj g|=  3.67244D-02

At iterate 1850    f=  4.24204D+01    |proj g|=  1.49520D-02

At iterate 1900    f=  4.24204D+01    |proj g|=  8.04920D-02

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
  424   1900   2026      1     0     0   8.049D-02   4.242D+01
  F =   42.420419749804282

CONVERGENCE: REL_REDUCTION_OF_F_&lt;=_FACTR*EPSMCH
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                                      </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value                                   </th></tr>
</thead>
<tbody>
<tr><td>SVGP.kernel.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.92881                                 </td></tr>
<tr><td>SVGP.kernel.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.79845                                 </td></tr>
<tr><td>SVGP.kernel.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.21136                                 </td></tr>
<tr><td>SVGP.likelihood.variance                  </td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.03966                                 </td></tr>
<tr><td>SVGP.inducing_variable.inducing_variable.Z</td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(15, 1)    </td><td>float64</td><td>[[-4.83987...                           </td></tr>
<tr><td>SVGP.q_mu                                 </td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(15, 3)    </td><td>float64</td><td>[[-0.90194, 0.69922, -1.47534...        </td></tr>
<tr><td>SVGP.q_sqrt                               </td><td>Parameter</td><td>FillTriangular  </td><td>       </td><td>True       </td><td>(3, 15, 15)</td><td>float64</td><td>[[[1.7140e-02, 0.0000e+00, 0.0000e+00...</td></tr>
</tbody>
</table></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot predictions and observations</span>
<span class="n">plot_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_multioutput_15_0.png" src="../../_images/notebooks_advanced_multioutput_15_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lengthscales</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                                            </th><th>class    </th><th>transform  </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>SharedIndependent.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.92881</td></tr>
<tr><td>SharedIndependent.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.79845</td></tr>
<tr><td>SharedIndependent.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">1.21136</td></tr>
</tbody>
</table></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=0.7984468434302114&gt;
</pre></div></div>
</div>
</section>
<section id="2.-Separate-independent-MOK-and-shared-independent-inducing-variables">
<h3>2. Separate independent MOK and shared independent inducing variables<a class="headerlink" href="#2.-Separate-independent-MOK-and-shared-independent-inducing-variables" title="Permalink to this heading">#</a></h3>
<p>Here we allow different hyperparameters for the priors of each output. We still share the inducing inputs between all outputs.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create list of kernels for each output</span>
<span class="n">kern_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">()</span> <span class="o">+</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Linear</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="p">]</span>
<span class="c1"># Create multi-output kernel from kernel list</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SeparateIndependent</span><span class="p">(</span><span class="n">kern_list</span><span class="p">)</span>
<span class="c1"># initialization of inducing input locations (M random points from the training inputs)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Zinit</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># create multi-output inducing variables from Z</span>
<span class="n">iv</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">SharedIndependentInducingVariables</span><span class="p">(</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">InducingPoints</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create SVGP model as usual and optimize</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">(</span>
    <span class="n">kernel</span><span class="p">,</span> <span class="n">gpf</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(),</span> <span class="n">inducing_variable</span><span class="o">=</span><span class="n">iv</span><span class="p">,</span> <span class="n">num_latent_gps</span><span class="o">=</span><span class="n">P</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimize_model_with_scipy</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /tmp/max_venv/lib/python3.10/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 This problem is unconstrained.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =          430     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  3.26251D+03    |proj g|=  1.79322D+03

At iterate   50    f=  1.94337D+02    |proj g|=  7.19126D+00

At iterate  100    f=  1.67801D+02    |proj g|=  2.54936D+01

At iterate  150    f=  5.95688D+01    |proj g|=  1.30478D+01

At iterate  200    f=  4.96488D+01    |proj g|=  1.91983D+01

At iterate  250    f=  4.66541D+01    |proj g|=  9.62574D+00

At iterate  300    f=  4.46522D+01    |proj g|=  1.25628D+01

At iterate  350    f=  4.33838D+01    |proj g|=  1.27690D+01

At iterate  400    f=  4.17217D+01    |proj g|=  2.23241D+01

At iterate  450    f=  4.03379D+01    |proj g|=  1.06276D+01

At iterate  500    f=  3.94733D+01    |proj g|=  1.26023D+01

At iterate  550    f=  3.86382D+01    |proj g|=  6.46691D+00

At iterate  600    f=  3.82440D+01    |proj g|=  8.13901D+00

At iterate  650    f=  3.79726D+01    |proj g|=  1.78131D+01

At iterate  700    f=  3.77627D+01    |proj g|=  4.74212D+00

At iterate  750    f=  3.75797D+01    |proj g|=  4.30812D+00

At iterate  800    f=  3.74646D+01    |proj g|=  2.35469D+00

At iterate  850    f=  3.73922D+01    |proj g|=  2.49940D+00

At iterate  900    f=  3.73327D+01    |proj g|=  3.86056D+00

At iterate  950    f=  3.72995D+01    |proj g|=  4.21572D+00

At iterate 1000    f=  3.72792D+01    |proj g|=  1.44563D+00

At iterate 1050    f=  3.72648D+01    |proj g|=  6.49190D-01

At iterate 1100    f=  3.72528D+01    |proj g|=  2.51480D-01

At iterate 1150    f=  3.72404D+01    |proj g|=  5.61992D-01

At iterate 1200    f=  3.72295D+01    |proj g|=  8.27107D-01

At iterate 1250    f=  3.72184D+01    |proj g|=  8.95014D-01

At iterate 1300    f=  3.72112D+01    |proj g|=  7.43351D-01

At iterate 1350    f=  3.72035D+01    |proj g|=  4.59073D-01

At iterate 1400    f=  3.71966D+01    |proj g|=  1.51816D+00

At iterate 1450    f=  3.71901D+01    |proj g|=  7.04316D-01

At iterate 1500    f=  3.71865D+01    |proj g|=  6.89060D-01

At iterate 1550    f=  3.71839D+01    |proj g|=  5.07504D-01

At iterate 1600    f=  3.71816D+01    |proj g|=  8.58259D-01

At iterate 1650    f=  3.71800D+01    |proj g|=  2.92423D-01

At iterate 1700    f=  3.71790D+01    |proj g|=  1.39011D-01

At iterate 1750    f=  3.71784D+01    |proj g|=  1.47100D-01

At iterate 1800    f=  3.71781D+01    |proj g|=  1.46424D-01

At iterate 1850    f=  3.71779D+01    |proj g|=  4.22140D-02

At iterate 1900    f=  3.71777D+01    |proj g|=  9.24390D-02

At iterate 1950    f=  3.71777D+01    |proj g|=  5.53324D-02

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
  430   1983   2103      1     0     0   1.796D-01   3.718D+01
  F =   37.177665022320539

CONVERGENCE: REL_REDUCTION_OF_F_&lt;=_FACTR*EPSMCH
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                                                  </th><th>class    </th><th>transform  </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>SeparateIndependent.kernels[0].kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.86258</td></tr>
<tr><td>SeparateIndependent.kernels[0].kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.93443</td></tr>
<tr><td>SeparateIndependent.kernels[0].kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.86384</td></tr>
<tr><td>SeparateIndependent.kernels[1].kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.75038</td></tr>
<tr><td>SeparateIndependent.kernels[1].kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.96988</td></tr>
<tr><td>SeparateIndependent.kernels[1].kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.53124</td></tr>
<tr><td>SeparateIndependent.kernels[2].kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">1.11067</td></tr>
<tr><td>SeparateIndependent.kernels[2].kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">0.74903</td></tr>
<tr><td>SeparateIndependent.kernels[2].kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">2.23295</td></tr>
</tbody>
</table></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_multioutput_22_0.png" src="../../_images/notebooks_advanced_multioutput_22_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">k</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lengthscales</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
[&lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=0.9344271026474873&gt;,
 &lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=0.9698768175450306&gt;,
 &lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=0.7490276029858081&gt;]
</pre></div></div>
</div>
</section>
<section id="3.-Separate-independent-kernel-and-separate-independent-inducing-variables">
<h3>3. Separate independent kernel and separate independent inducing variables<a class="headerlink" href="#3.-Separate-independent-kernel-and-separate-independent-inducing-variables" title="Permalink to this heading">#</a></h3>
<p>Here we allow different hyperparameters for the priors of each output. We now allow different inducing inputs for each output.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create list of kernels for each output</span>
<span class="n">kern_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">()</span> <span class="o">+</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Linear</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
<span class="p">]</span>
<span class="c1"># Create multi-output kernel from kernel list</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SeparateIndependent</span><span class="p">(</span><span class="n">kern_list</span><span class="p">)</span>
<span class="c1"># initialization of inducing input locations, one set of locations per output</span>
<span class="n">Zs</span> <span class="o">=</span> <span class="p">[</span><span class="n">Zinit</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">P</span><span class="p">)]</span>
<span class="c1"># initialize as list inducing inducing variables</span>
<span class="n">iv_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">InducingPoints</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span> <span class="k">for</span> <span class="n">Z</span> <span class="ow">in</span> <span class="n">Zs</span><span class="p">]</span>
<span class="c1"># create multi-output inducing variables from iv_list</span>
<span class="n">iv</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">SeparateIndependentInducingVariables</span><span class="p">(</span><span class="n">iv_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><strong>NOTE:</strong> While the inducing points are independent, there needs to be the same number of inducing points per dimension.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create SVGP model as usual and optimize</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">(</span>
    <span class="n">kernel</span><span class="p">,</span> <span class="n">gpf</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(),</span> <span class="n">inducing_variable</span><span class="o">=</span><span class="n">iv</span><span class="p">,</span> <span class="n">num_latent_gps</span><span class="o">=</span><span class="n">P</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimize_model_with_scipy</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 This problem is unconstrained.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =          460     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  3.26251D+03    |proj g|=  1.79322D+03

At iterate   50    f=  1.91729D+02    |proj g|=  6.27078D+00

At iterate  100    f=  1.11226D+02    |proj g|=  1.01543D+02

At iterate  150    f=  5.20161D+01    |proj g|=  1.30689D+01

At iterate  200    f=  4.69361D+01    |proj g|=  4.69177D+01

At iterate  250    f=  4.41766D+01    |proj g|=  7.17047D+00

At iterate  300    f=  4.27943D+01    |proj g|=  9.90431D+00

At iterate  350    f=  4.12960D+01    |proj g|=  7.53606D+00

At iterate  400    f=  3.95955D+01    |proj g|=  1.22008D+01

At iterate  450    f=  3.86108D+01    |proj g|=  1.92450D+01

At iterate  500    f=  3.81436D+01    |proj g|=  1.11775D+01

At iterate  550    f=  3.79090D+01    |proj g|=  2.47366D+00

At iterate  600    f=  3.77848D+01    |proj g|=  2.24553D+00

At iterate  650    f=  3.76905D+01    |proj g|=  2.38986D+00

At iterate  700    f=  3.75869D+01    |proj g|=  4.36481D+00

At iterate  750    f=  3.74777D+01    |proj g|=  5.00007D+00

At iterate  800    f=  3.73676D+01    |proj g|=  2.15240D+00

At iterate  850    f=  3.72695D+01    |proj g|=  2.68041D+00

At iterate  900    f=  3.71963D+01    |proj g|=  1.70180D+00

At iterate  950    f=  3.71482D+01    |proj g|=  1.29328D+00

At iterate 1000    f=  3.71074D+01    |proj g|=  3.89082D+00

At iterate 1050    f=  3.70615D+01    |proj g|=  1.19608D+00

At iterate 1100    f=  3.70273D+01    |proj g|=  2.00785D+00

At iterate 1150    f=  3.69988D+01    |proj g|=  1.69787D+00

At iterate 1200    f=  3.69847D+01    |proj g|=  6.74138D-01

At iterate 1250    f=  3.69750D+01    |proj g|=  5.19511D-01

At iterate 1300    f=  3.69698D+01    |proj g|=  5.78420D-01

At iterate 1350    f=  3.69662D+01    |proj g|=  6.25408D-01

At iterate 1400    f=  3.69632D+01    |proj g|=  5.50439D-01

At iterate 1450    f=  3.69610D+01    |proj g|=  3.13294D-01

At iterate 1500    f=  3.69587D+01    |proj g|=  5.10488D-01

At iterate 1550    f=  3.69564D+01    |proj g|=  1.81866D-01

At iterate 1600    f=  3.69542D+01    |proj g|=  3.27195D-01

At iterate 1650    f=  3.69527D+01    |proj g|=  1.99318D-01

At iterate 1700    f=  3.69517D+01    |proj g|=  4.44632D-01

At iterate 1750    f=  3.69509D+01    |proj g|=  2.32143D-01

At iterate 1800    f=  3.69503D+01    |proj g|=  1.32929D-01

At iterate 1850    f=  3.69497D+01    |proj g|=  2.12914D-01

At iterate 1900    f=  3.69492D+01    |proj g|=  1.48367D-01

At iterate 1950    f=  3.69488D+01    |proj g|=  1.89027D-01

At iterate 2000    f=  3.69484D+01    |proj g|=  1.24718D-01

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
  460   2000   2140      1     0     0   1.247D-01   3.695D+01
  F =   36.948410222551317

STOP: TOTAL NO. of ITERATIONS REACHED LIMIT
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_multioutput_29_0.png" src="../../_images/notebooks_advanced_multioutput_29_0.png" />
</div>
</div>
<p>The following plot shows that we use different inducing <em>inputs</em> in each output dimension.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">inducing_variable</span><span class="o">.</span><span class="n">inducing_variable_list</span><span class="p">)):</span>
    <span class="n">q_mu_unwhitened</span><span class="p">,</span> <span class="n">q_var_unwhitened</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">predict_f</span><span class="p">(</span>
        <span class="n">m</span><span class="o">.</span><span class="n">inducing_variable</span><span class="o">.</span><span class="n">inducing_variable_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">Z</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">m</span><span class="o">.</span><span class="n">inducing_variable</span><span class="o">.</span><span class="n">inducing_variable_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">Z</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
        <span class="n">q_mu_unwhitened</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
        <span class="s2">&quot;o&quot;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">minor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">minor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="s2">&quot;minor&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_multioutput_31_0.png" src="../../_images/notebooks_advanced_multioutput_31_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">inducing_variable</span><span class="o">.</span><span class="n">inducing_variable_list</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
ListWrapper([&lt;gpflow.inducing_variables.inducing_variables.InducingPoints object at 0x7faa7c283430&gt;, &lt;gpflow.inducing_variables.inducing_variables.InducingPoints object at 0x7faa7c282a70&gt;, &lt;gpflow.inducing_variables.inducing_variables.InducingPoints object at 0x7faa7c43a260&gt;])
</pre></div></div>
</div>
</section>
</section>
<section id="Model-f(x)-by-doing-inference-in-the-g-space">
<h2>Model <span class="math notranslate nohighlight">\(f(x)\)</span> by doing inference in the <span class="math notranslate nohighlight">\(g\)</span> space<a class="headerlink" href="#Model-f(x)-by-doing-inference-in-the-g-space" title="Permalink to this heading">#</a></h2>
<section id="Mixed-kernel-and-uncorrelated-inducing-variables">
<h3>Mixed kernel and uncorrelated inducing variables<a class="headerlink" href="#Mixed-kernel-and-uncorrelated-inducing-variables" title="Permalink to this heading">#</a></h3>
<p>Remember the general case: <span class="math notranslate nohighlight">\(f(x) = W g(x)\)</span>, where <span class="math notranslate nohighlight">\(g(x) \in \mathbb{R}^L\)</span>, <span class="math notranslate nohighlight">\(f(x) \in \mathbb{R}^P\)</span> and <span class="math notranslate nohighlight">\(W \in \mathbb{R}^{P \times L}\)</span>, where <span class="math notranslate nohighlight">\(L \leq P\)</span>. We assume that the outputs of <span class="math notranslate nohighlight">\(g\)</span> are uncorrelated, and by <em>mixing</em> them with <span class="math notranslate nohighlight">\(W\)</span> they become correlated. With this setup we perform the optimal routine to calculate the conditional. Namely, calculate the conditional of the uncorrelated latent <span class="math notranslate nohighlight">\(g\)</span> and afterwards project the mean and variance using
the mixing matrix: <span class="math notranslate nohighlight">\(\mu_f = W \mu_g\)</span> and <span class="math notranslate nohighlight">\(\Sigma_f = W\Sigma_g W^\top\)</span></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(K_{uu} = L \times M \times M\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(K_{uf} = L \times M \times N\)</span></p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create list of kernels for each output</span>
<span class="n">kern_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">()</span> <span class="o">+</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Linear</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
<span class="p">]</span>
<span class="c1"># Create multi-output kernel from kernel list</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">LinearCoregionalization</span><span class="p">(</span>
    <span class="n">kern_list</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>
<span class="p">)</span>  <span class="c1"># Notice that we initialise the mixing matrix W</span>
<span class="c1"># initialisation of inducing input locations (M random points from the training inputs)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">Zinit</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># create multi-output inducing variables from Z</span>
<span class="n">iv</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">SharedIndependentInducingVariables</span><span class="p">(</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">InducingPoints</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># initialize mean of variational posterior to be of shape MxL</span>
<span class="n">q_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">M</span><span class="p">,</span> <span class="n">L</span><span class="p">))</span>
<span class="c1"># initialize \sqrt(Î£) of variational posterior to be of shape LxMxM</span>
<span class="n">q_sqrt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">M</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">L</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1.0</span>

<span class="c1"># create SVGP model as usual and optimize</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">gpf</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">(</span>
    <span class="n">kernel</span><span class="p">,</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">(),</span>
    <span class="n">inducing_variable</span><span class="o">=</span><span class="n">iv</span><span class="p">,</span>
    <span class="n">q_mu</span><span class="o">=</span><span class="n">q_mu</span><span class="p">,</span>
    <span class="n">q_sqrt</span><span class="o">=</span><span class="n">q_sqrt</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimize_model_with_scipy</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
 This problem is unconstrained.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
RUNNING THE L-BFGS-B CODE

           * * *

Machine precision = 2.220D-16
 N =          298     M =           10

At X0         0 variables are exactly at the bounds

At iterate    0    f=  7.44521D+03    |proj g|=  6.62929D+03

At iterate   50    f=  3.17536D+02    |proj g|=  4.85678D+00

At iterate  100    f=  1.72326D+02    |proj g|=  1.27892D+02

At iterate  150    f=  1.07479D+02    |proj g|=  3.56398D+01

At iterate  200    f=  3.42125D+01    |proj g|=  7.09685D+01

At iterate  250    f=  2.09585D+01    |proj g|=  4.48371D+01

At iterate  300    f=  1.61664D+01    |proj g|=  1.32557D+01

At iterate  350    f=  1.21720D+01    |proj g|=  2.63808D+01

At iterate  400    f=  9.68082D+00    |proj g|=  1.35825D+01

At iterate  450    f=  7.73028D+00    |proj g|=  1.88419D+01

At iterate  500    f=  6.44143D+00    |proj g|=  4.11613D+01

At iterate  550    f=  5.26354D+00    |proj g|=  1.03765D+01

At iterate  600    f=  4.25867D+00    |proj g|=  7.76566D+00

At iterate  650    f=  3.58394D+00    |proj g|=  6.88400D+00

At iterate  700    f=  3.09796D+00    |proj g|=  3.64345D+00

At iterate  750    f=  2.75839D+00    |proj g|=  1.02569D+01

At iterate  800    f=  2.35431D+00    |proj g|=  1.76240D+01

At iterate  850    f=  1.80070D+00    |proj g|=  1.04386D+01

At iterate  900    f=  1.53541D+00    |proj g|=  4.97609D+00

At iterate  950    f=  1.41219D+00    |proj g|=  7.41418D+00

At iterate 1000    f=  1.29912D+00    |proj g|=  2.71758D+00

At iterate 1050    f=  1.20319D+00    |proj g|=  1.46667D+00

At iterate 1100    f=  1.10128D+00    |proj g|=  2.81529D+00

At iterate 1150    f=  1.01153D+00    |proj g|=  3.73160D+00

At iterate 1200    f=  9.33403D-01    |proj g|=  7.81433D-01

At iterate 1250    f=  8.80741D-01    |proj g|=  7.99147D-01

At iterate 1300    f=  8.38234D-01    |proj g|=  1.53324D+00

At iterate 1350    f=  8.04007D-01    |proj g|=  3.44662D+00

At iterate 1400    f=  7.76123D-01    |proj g|=  5.83165D-01

At iterate 1450    f=  7.54255D-01    |proj g|=  1.17003D+00

At iterate 1500    f=  7.30881D-01    |proj g|=  1.79285D+00

At iterate 1550    f=  7.12292D-01    |proj g|=  1.84236D+00

At iterate 1600    f=  6.98546D-01    |proj g|=  5.50370D-01

At iterate 1650    f=  6.85617D-01    |proj g|=  1.00091D+00

At iterate 1700    f=  6.70749D-01    |proj g|=  1.18019D+00

At iterate 1750    f=  6.59199D-01    |proj g|=  5.47999D-01

At iterate 1800    f=  6.52206D-01    |proj g|=  4.49372D-01

At iterate 1850    f=  6.47309D-01    |proj g|=  5.48646D-01

At iterate 1900    f=  6.42606D-01    |proj g|=  6.70976D-01

At iterate 1950    f=  6.37862D-01    |proj g|=  2.57139D-01

At iterate 2000    f=  6.33217D-01    |proj g|=  3.67995D-01

           * * *

Tit   = total number of iterations
Tnf   = total number of function evaluations
Tnint = total number of segments explored during Cauchy searches
Skip  = number of BFGS updates skipped
Nact  = number of active bounds at final generalized Cauchy point
Projg = norm of the final projected gradient
F     = final function value

           * * *

   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F
  298   2000   2194      1     0     0   3.680D-01   6.332D-01
  F =  0.63321650488028780

STOP: TOTAL NO. of ITERATIONS REACHED LIMIT
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_model</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_multioutput_37_0.png" src="../../_images/notebooks_advanced_multioutput_37_0.png" />
</div>
</div>
</section>
</section>
<section id="Illustration-of-GPflowâs-multi-output-capabilities">
<h2>Illustration of GPflowâs multi-output capabilities<a class="headerlink" href="#Illustration-of-GPflowâs-multi-output-capabilities" title="Permalink to this heading">#</a></h2>
<p>This section shows the inheritance structure in GPflowâs multi-output framework.</p>
<section id="Multi-output-kernels-(MOK)-class-diagram">
<h3>Multi-output kernels (MOK) class diagram<a class="headerlink" href="#Multi-output-kernels-(MOK)-class-diagram" title="Permalink to this heading">#</a></h3>
<p>We include three multi-output kernels: - <code class="docutils literal notranslate"><span class="pre">SharedIndependent</span></code>: This kernel is included mainly as an illustration of specifying a conditional using the multiple dispatch framework. The same functionality is provided by using a normal kernel and passing in multiple approximate posteriors by stacking <code class="docutils literal notranslate"><span class="pre">q_mu</span></code> and <code class="docutils literal notranslate"><span class="pre">q_sqrt</span></code>. - <code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code>: This kernel allows you to use different priors for each output GP. - <code class="docutils literal notranslate"><span class="pre">LinearCoregionalization</span></code>: This kernel describes the prior of the linear
model of coregionalization. As shown previously, this implementation supports various inducing point approximations. <img alt="Multi-output kernels" src="../../_images/multioutput_kernels.svg" /></p>
<p>We include several base classes. Two are noteworthy: - <code class="docutils literal notranslate"><span class="pre">MultioutputKernel</span></code> is included to be the base class for all multi-output kernels. - <code class="docutils literal notranslate"><span class="pre">IndepedentLatent</span></code> is the base class for all multi-output kernels which are constructed from independent latent processes. Including this kernel allows the specification of a default approximation method which, while not the most efficient, does take advantage of <em>some</em> structure. It can be applied to <em>any</em> kernel constructed from independent latent
processes.</p>
<p>There is a similarity in the meaning of <code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code> and <code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code>. Both kernels indicate that independent processes are used, and that <span class="math notranslate nohighlight">\(\mathbf{K}_{\bf uu}\)</span> can therefore be represented as a <code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code> tensor. It could therefore be suggested that <code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code> be the parent class of all âindependent latentâ kernels, instead of having a separate <code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code> class. We decided against this because: - this would increase the complexity in
specifying <code class="docutils literal notranslate"><span class="pre">conditionals()</span></code> for the otherwise simple multi-output kernels <code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code> and <code class="docutils literal notranslate"><span class="pre">SharedIndependent</span></code>. - we did not want to specify too much of an implementation in <code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code>, leaving implementation details to child classes. Using <code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code> as the base class would force all child classes to be a <code class="docutils literal notranslate"><span class="pre">Combination</span></code> kernel.</p>
</section>
<section id="Multi-output-inducing-variables-class-diagram">
<h3>Multi-output inducing variables class diagram<a class="headerlink" href="#Multi-output-inducing-variables-class-diagram" title="Permalink to this heading">#</a></h3>
<p><img alt="Multi-output features" src="../../_images/multioutput_features.svg" /></p>
<section id="Inducing-points">
<h4>Inducing points<a class="headerlink" href="#Inducing-points" title="Permalink to this heading">#</a></h4>
<p>The goal of this class is to provide inducing variables that can be used with <em>any</em> kernel, even if the method ends up being slow.</p>
<p>The multiouput framework extends <code class="docutils literal notranslate"><span class="pre">InducingPoints</span></code> to work with multi-output kernels. Just like for single-output kernels, we want <code class="docutils literal notranslate"><span class="pre">InducingPoints</span></code> to work for all <code class="docutils literal notranslate"><span class="pre">MultioutputKernel</span></code>s. We do this by defining <code class="docutils literal notranslate"><span class="pre">InducingPoints</span></code> to take <em>all</em> outputs for specific inducing inputs as inducing variables.</p>
</section>
<section id="Fallback-shared/separate-independent-inducing-variables">
<h4>Fallback shared/separate independent inducing variables<a class="headerlink" href="#Fallback-shared/separate-independent-inducing-variables" title="Permalink to this heading">#</a></h4>
<p>The goal of these classes is to provide a reasonably efficient implementation for kernels that give exploitable independence structure in the prior of inducing variables (that is, subclasses of <code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code>), while only needing to implement <code class="docutils literal notranslate"><span class="pre">Kuu()</span></code> and <code class="docutils literal notranslate"><span class="pre">Kuf()</span></code> methods.</p>
</section>
<section id="Shared/separate-independent-inducing-variables">
<h4>Shared/separate independent inducing variables<a class="headerlink" href="#Shared/separate-independent-inducing-variables" title="Permalink to this heading">#</a></h4>
<p>The goal of these classes is to provide the most efficient code path for kernels that allow exploiting independence structure in the prior of inducing variables.</p>
<p>For more specialized multi-output kernels (i.e.Â <code class="docutils literal notranslate"><span class="pre">{Shared|Separate}Independent</span></code> or <code class="docutils literal notranslate"><span class="pre">LinearCoregionalization</span></code>) we define <code class="docutils literal notranslate"><span class="pre">{Shared|Separate}IndependentInducingVariables</span></code>. These wrap (a list of) single-output inducing variables to define groups of a-priori independent inducing variables, which leads to a <span class="math notranslate nohighlight">\(\mathbf{K}_{\bf uu}\)</span> that can be represented as a <code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code> tensor. We saw the use of these previously.</p>
<p><code class="docutils literal notranslate"><span class="pre">{Shared|Separate}IndependentInducingVariables</span></code> inherit from <code class="docutils literal notranslate"><span class="pre">Fallback{Shared|Separate}IndependentInducingVariables</span></code>, so the multiple dispatch will fall back on the slower but general implementation.</p>
</section>
</section>
<section id="Implemented-combinations">
<h3>Implemented combinations<a class="headerlink" href="#Implemented-combinations" title="Permalink to this heading">#</a></h3>
<p>Multiple dispatch is applied to both <code class="docutils literal notranslate"><span class="pre">Kuu()</span></code>, <code class="docutils literal notranslate"><span class="pre">Kuf()</span></code>, and <code class="docutils literal notranslate"><span class="pre">conditional()</span></code>. The return values of the covariances can therefore be tailored to a specific implementation of <code class="docutils literal notranslate"><span class="pre">conditional()</span></code>. The following table lists combinations which are currently available in GPflow. Thanks to the multiple dispatch code, implementing your own outside of GPflow should require only a small amount of code!</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Inducing variable class</p></th>
<th class="head"><p>Kernel</p></th>
<th class="head"><p>Kuu</p></th>
<th class="head"><p>Kuf</p></th>
<th class="head"><p>conditional</p></th>
<th class="head"><p>note</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">InducingPoints</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">MultioutputKernel</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">P,</span> <span class="pre">M,</span> <span class="pre">P]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">P,</span> <span class="pre">N,</span> <span class="pre">P]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">inducing_point_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">fully_correlated_conditional()</span></code></p></td>
<td><p>Works for all kernels, but might be
very inefficient. In this case
<code class="docutils literal notranslate"><span class="pre">q_mu</span></code> and <code class="docutils literal notranslate"><span class="pre">q_sqrt</span></code> should have
shapes of <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">MP]</span></code> and
<code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">MP,</span> <span class="pre">MP]</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">SharedIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SharedIndependent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">shared_independent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
<td><p>The combination of these two classes
is in a sense redundant, because we
can achieve the same behavior by
using the single output Kernel and
InducingVariable classes. They are
added for illustrative purposes.
Thanks to the conditional dispatch,
the most efficient code path is
used.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">SeparateIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SharedIndependent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">separate_independent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code> P times</p></td>
<td><p>We loop P times over the
<code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">SeparateIndependentInducingVariable</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">separate_independent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code> P times</p></td>
<td><p>We loop P times over the
<code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">SharedIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SeparateIndependent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[P,</span> <span class="pre">M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">separate_independent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code> P times</p></td>
<td><p>We loop P times over the
<code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">FallbackSharedIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">L,</span> <span class="pre">N,</span> <span class="pre">P]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">fallback_independent_latent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">independent_interdomain_conditional()</span></code></p></td>
<td><p>Implementation which only requires
custom <code class="docutils literal notranslate"><span class="pre">Kuu()</span></code> and <code class="docutils literal notranslate"><span class="pre">Kuf()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">FallbackSeparateIndependentInducingVariable</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">IndependentLatent</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[M,</span> <span class="pre">L,</span> <span class="pre">N,</span> <span class="pre">P]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">fallback_independent_latent_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">independent_interdomain_conditional()</span></code></p></td>
<td><p>Implementation which only requires
custom <code class="docutils literal notranslate"><span class="pre">Kuu()</span></code> and <code class="docutils literal notranslate"><span class="pre">Kuf()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">SharedIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">LinearCoregionalization</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">coregionalization_conditional()</span></code>, which calls <code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
<td><p>This is the most efficient
implementation for linear
coregionalization. The inducing
outputs live in g-space. Here we use
the output of the base conditional
and project the mean and covariance
with the mixing matrix W.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">SeparateIndependentInducingVariables</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">LinearCoregionalization</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">M]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">[L,</span> <span class="pre">M,</span> <span class="pre">N]</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">base_conditional()</span></code></p></td>
<td><p>This is the most efficient
implementation for linear
coregionalization. The inducing
outputs live in g-space. Here we use
the output of the base conditional
and project the mean and covariance
with the mixing matrix W.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="Debugging:-introspect">
<h2>Debugging: introspect<a class="headerlink" href="#Debugging:-introspect" title="Permalink to this heading">#</a></h2>
<p>Given all these possibilities it can be hard to determine which conditional will be called for which set of kernel and inducing variable. The following method lets you proactively introspect which implementation will be executed. This can be useful when debugging new code.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">inspect_conditional</span><span class="p">(</span><span class="n">inducing_variable_type</span><span class="p">,</span> <span class="n">kernel_type</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Helper function returning the exact implementation called</span>
<span class="sd">    by the multiple dispatch `conditional` given the type of</span>
<span class="sd">    kernel and inducing variable.</span>

<span class="sd">    :param inducing_variable_type:</span>
<span class="sd">        Type of the inducing variable</span>
<span class="sd">    :param kernel_type:</span>
<span class="sd">        Type of the kernel</span>

<span class="sd">    :return: String</span>
<span class="sd">        Contains the name, the file and the linenumber of the</span>
<span class="sd">        implementation.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">import</span> <span class="nn">inspect</span>

    <span class="kn">from</span> <span class="nn">gpflow.conditionals</span> <span class="kn">import</span> <span class="n">conditional</span>

    <span class="n">implementation</span> <span class="o">=</span> <span class="n">conditional</span><span class="o">.</span><span class="n">dispatch</span><span class="p">(</span>
        <span class="nb">object</span><span class="p">,</span> <span class="n">inducing_variable_type</span><span class="p">,</span> <span class="n">kernel_type</span><span class="p">,</span> <span class="nb">object</span>
    <span class="p">)</span>
    <span class="n">info</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">getmembers</span><span class="p">(</span><span class="n">implementation</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">info</span><span class="p">[</span><span class="s2">&quot;__code__&quot;</span><span class="p">]</span>


<span class="c1"># Example:</span>
<span class="n">inspect_conditional</span><span class="p">(</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">inducing_variables</span><span class="o">.</span><span class="n">SharedIndependentInducingVariables</span><span class="p">,</span>
    <span class="n">gpf</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SharedIndependent</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;code object wrapped_function at 0x7faab4593470, file &#34;/home/circleci/project/gpflow/experimental/check_shapes/decorator.py&#34;, line 86&gt;
</pre></div></div>
</div>
</section>
<section id="Further-Reading:">
<h2>Further Reading:<a class="headerlink" href="#Further-Reading:" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="coregionalisation.html"><span class="doc">A simple demonstration of coregionalization</span></a>, which details other GPflow features for multi-output prediction without fully observed outputs.</p></li>
</ul>
</section>
</section>


            </article>
            
            
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Task">
   Task
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Generate-synthetic-data">
   Generate synthetic data
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Model-the-outputs-of-f(x)-directly">
   Model the outputs of
   <span class="math notranslate nohighlight">
    \(f(x)\)
   </span>
   directly
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#1.-Shared-independent-multi-output-kernel-(MOK)-and-shared-independent-inducing-variables">
     1. Shared independent multi-output kernel (MOK) and shared independent inducing variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#2.-Separate-independent-MOK-and-shared-independent-inducing-variables">
     2. Separate independent MOK and shared independent inducing variables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#3.-Separate-independent-kernel-and-separate-independent-inducing-variables">
     3. Separate independent kernel and separate independent inducing variables
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Model-f(x)-by-doing-inference-in-the-g-space">
   Model
   <span class="math notranslate nohighlight">
    \(f(x)\)
   </span>
   by doing inference in the
   <span class="math notranslate nohighlight">
    \(g\)
   </span>
   space
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Mixed-kernel-and-uncorrelated-inducing-variables">
     Mixed kernel and uncorrelated inducing variables
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Illustration-of-GPflowâs-multi-output-capabilities">
   Illustration of GPflowâs multi-output capabilities
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Multi-output-kernels-(MOK)-class-diagram">
     Multi-output kernels (MOK) class diagram
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Multi-output-inducing-variables-class-diagram">
     Multi-output inducing variables class diagram
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#Inducing-points">
       Inducing points
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#Fallback-shared/separate-independent-inducing-variables">
       Fallback shared/separate independent inducing variables
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#Shared/separate-independent-inducing-variables">
       Shared/separate independent inducing variables
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Implemented-combinations">
     Implemented combinations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Debugging:-introspect">
   Debugging: introspect
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Further-Reading:">
   Further Reading:
  </a>
 </li>
</ul>

</nav>
</div>

<div class="toc-item">
  
<div id="searchbox"></div>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1e1de1a1873e13ef5536"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022, The GPflow Contributors.<br>

</p>

  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.2.3.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>