
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>MCMC (Markov Chain Monte Carlo) &#8212; GPflow 2.6.3 documentation</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1e1de1a1873e13ef5536" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1e1de1a1873e13ef5536" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/pydata-custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1e1de1a1873e13ef5536">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/advanced/mcmc';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://gpflow.github.io/GPflow/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = '2.6.3';
        </script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Multiclass classification" href="multiclass_classification.html" />
    <link rel="prev" title="Manipulating kernels" href="kernels.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../index.html">

  
  
  
  
  
  
  

  
    <img src="../../_static/gpflow_logo.svg" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/gpflow_logo.svg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../../intro.html">
                        Introduction
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../manual.html">
                        GPflow manual
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../intro_to_gpflow2.html">
                        GPflow with TensorFlow 2
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="../../notebooks_file.html">
                        Notebooks
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../derivations.html">
                        Derivations
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../../api/gpflow/index.html">
                        API reference
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../bibliography.html">
                        Bibliography
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <div class="version-switcher__container dropdown">
    <button type="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-toggle="dropdown">
        2.6.3  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div class="version-switcher__menu dropdown-menu list-group-flush py-0">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>
      </div>
      
    </div>
  </div>


  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
  </div>

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../../intro.html">
                        Introduction
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../manual.html">
                        GPflow manual
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../intro_to_gpflow2.html">
                        GPflow with TensorFlow 2
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="../../notebooks_file.html">
                        Notebooks
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../derivations.html">
                        Derivations
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../../api/gpflow/index.html">
                        API reference
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../../bibliography.html">
                        Bibliography
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <div class="version-switcher__container dropdown">
    <button type="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-toggle="dropdown">
        2.6.3  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div class="version-switcher__menu dropdown-menu list-group-flush py-0">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>
      </div>
      
    </div>
    
  </div>

  
  <div class="sidebar-start-items sidebar-primary__section">
    <div class="sidebar-start-items__item"><nav class="bd-links" id="bd-docs-nav" aria-label="Section navigation">
  <p class="bd-links__title" role="heading" aria-level="1">
    Section Navigation
  </p>
  <div class="bd-toc-item navbar-nav">
    <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../basics/GPLVM.html">Bayesian Gaussian process latent variable model (Bayesian GPLVM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/classification.html">Basic (binary) GP classification model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/monitoring.html">Monitoring Optimisation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../basics/regression.html">Basic (Gaussian likelihood) GP regression model</a></li>
</ul>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="changepoints.html">Change points</a></li>
<li class="toctree-l1"><a class="reference internal" href="convolutional.html">Convolutional Gaussian Processes</a></li>
<li class="toctree-l1"><a class="reference internal" href="coregionalisation.html">A simple demonstration of coregionalization</a></li>
<li class="toctree-l1"><a class="reference internal" href="fast_predictions.html">Faster predictions by caching</a></li>
<li class="toctree-l1"><a class="reference internal" href="gps_for_big_data.html">Stochastic Variational Inference for scalability with SVGP</a></li>
<li class="toctree-l1"><a class="reference internal" href="heteroskedastic.html">Heteroskedastic Likelihood and Multi-Latent GP</a></li>
<li class="toctree-l1"><a class="reference internal" href="kernels.html">Manipulating kernels</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">MCMC (Markov Chain Monte Carlo)</a></li>
<li class="toctree-l1"><a class="reference internal" href="multiclass_classification.html">Multiclass classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="multioutput.html">Multi-output Gaussian processes in GPflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="natural_gradients.html">Natural gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="ordinal_regression.html">Ordinal regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="variational_fourier_features.html">Variational Fourier Features in the GPflow framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="varying_noise.html">Gaussian process regression with varying output noise</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../tailor/external-mean-function.html">Custom mean functions: metalearning with GPs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tailor/gp_nn.html">Mixing TensorFlow models with GPflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tailor/kernel_design.html">Kernel Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tailor/mixture_density_network.html">Mixture Density Networks in GPflow</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../theory/FITCvsVFE.html">Comparing FITC approximation to VFE approximation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/SGPR_notes.html">Derivation of SGPR equations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/Sanity_check.html">Sanity checking when model behaviours should overlap</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/cglb.html">Conjugate Gradient Lower Bound</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/upper_bound.html">Discussion of the GP marginal likelihood upper bound</a></li>
<li class="toctree-l1"><a class="reference internal" href="../theory/vgp_notes.html">Derivation of VGP equations</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../understanding/models.html">Manipulating GPflow models</a></li>
</ul>

  </div>
</nav>
    </div>
  </div>
  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

      </div>
      <main class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="MCMC-(Markov-Chain-Monte-Carlo)">
<h1>MCMC (Markov Chain Monte Carlo)<a class="headerlink" href="#MCMC-(Markov-Chain-Monte-Carlo)" title="Permalink to this heading">#</a></h1>
<p>GPflow allows you to approximate the posterior over the latent functions of its models (and over the hyperparameters after setting a prior for those) using Hamiltonian Monte Carlo (HMC)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>
<span class="kn">from</span> <span class="nn">multiclass_classification</span> <span class="kn">import</span> <span class="n">colors</span><span class="p">,</span> <span class="n">plot_from_samples</span>
<span class="kn">from</span> <span class="nn">tensorflow_probability</span> <span class="kn">import</span> <span class="n">distributions</span> <span class="k">as</span> <span class="n">tfd</span>

<span class="kn">import</span> <span class="nn">gpflow</span>
<span class="kn">from</span> <span class="nn">gpflow</span> <span class="kn">import</span> <span class="n">set_trainable</span>
<span class="kn">from</span> <span class="nn">gpflow.ci_utils</span> <span class="kn">import</span> <span class="n">reduce_in_tests</span>

<span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_jitter</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">)</span>
<span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_summary_fmt</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
<span class="c1"># convert to float64 for tfp to play nicely with gpflow in 64</span>
<span class="n">f64</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">to_default_float</span>

<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>


<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-10-13 10:01:21.719342: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-13 10:01:21.842951: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-10-13 10:01:21.842972: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-10-13 10:01:21.871698: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-10-13 10:01:22.507159: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer.so.7&#39;; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-10-13 10:01:22.507226: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer_plugin.so.7&#39;; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-10-13 10:01:22.507234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You&#39;re calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.
  warn(
/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You&#39;re calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.
  warn(
</pre></div></div>
</div>
<p>In this notebook, we provide three examples:</p>
<ul class="simple">
<li><p><a class="reference external" href="#Example-1:-GP-regression">Example 1</a>: Sampling hyperparameters in Gaussian process regression</p></li>
<li><p><a class="reference external" href="#Example-2:-Sparse-MC-for-multiclass-classification">Example 2</a>: Sparse Variational MC applied to the multiclass classification problem</p></li>
<li><p><a class="reference external" href="#Example-3:-Fully-Bayesian-inference-for-generalized-GP-models-with-HMC">Example 3</a>: Full Bayesian inference for Gaussian process models</p></li>
</ul>
<section id="Example-1:-GP-regression">
<h2>Example 1: GP regression<a class="headerlink" href="#Example-1:-GP-regression" title="Permalink to this heading">#</a></h2>
<p>We first consider the GP regression (with Gaussian noise) for which the marginal likelihood <span class="math notranslate nohighlight">\(p(\mathbf y\,|\,\theta)\)</span> can be computed exactly.</p>
<p>The GPR model parameterized by <span class="math notranslate nohighlight">\(\theta = [\tau]\)</span> is given by <span class="math">\begin{equation}
Y_i = f(X_i) + \varepsilon_i
\end{equation}</span> where <span class="math notranslate nohighlight">\(f \sim \mathcal{GP}(\mu(.), k(., .))\)</span>, and <span class="math notranslate nohighlight">\(\varepsilon \sim \mathcal{N}(0, \tau^2 I)\)</span>.</p>
<p>See the <a class="reference internal" href="../basics/regression.html"><span class="doc">Basic (Gaussian likelihood) GP regression model</span></a> for more details on GPR and for a treatment of the direct likelihood maximization.</p>
<section id="Data-for-a-one-dimensional-regression-problem">
<h3>Data for a one-dimensional regression problem<a class="headerlink" href="#Data-for-a-one-dimensional-regression-problem" title="Permalink to this heading">#</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">15</span>


<span class="k">def</span> <span class="nf">synthetic_data</span><span class="p">(</span><span class="n">num</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">rng</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">):</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">12</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.66</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">25</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mi">3</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>


<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span> <span class="o">=</span> <span class="n">synthetic_data</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;kx&quot;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$X$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$Y$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;toy data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_7_0.png" src="../../_images/notebooks_advanced_mcmc_7_0.png" />
</div>
</div>
</section>
<section id="MCMC-for-hyperparameters-\theta">
<h3>MCMC for hyperparameters <span class="math notranslate nohighlight">\(\theta\)</span><a class="headerlink" href="#MCMC-for-hyperparameters-\theta" title="Permalink to this heading">#</a></h3>
<p>We now want to sample from the posterior over <span class="math notranslate nohighlight">\(\theta\)</span>: <span class="math">\begin{equation}
p(\theta|\mathbf{y}) \propto p(\mathbf{y}|\theta)p(\theta)
\end{equation}</span></p>
<p>Firstly, we build the GPR model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Matern52</span><span class="p">(</span><span class="n">lengthscales</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">mean_function</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">mean_functions</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPR</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">mean_function</span><span class="p">,</span> <span class="n">noise_variance</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You&#39;re calling gpflow.experimental.check_shapes.checker.ShapeChecker.__init__ which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.
  warn(
2022-10-13 10:01:25.269974: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-10-13 10:01:25.270002: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2022-10-13 10:01:25.270021: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (8ae7e9adaed8): /proc/driver/nvidia/version does not exist
2022-10-13 10:01:25.270273: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div></div>
</div>
<p>Secondly, we initialize the model to the maximum likelihood solution.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;log posterior density at optimum: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">log_posterior_density</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
log posterior density at optimum: -11.460240793868877
</pre></div></div>
</div>
<p>Thirdly, we add priors to the hyperparameters.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># tfp.distributions dtype is inferred from parameters - so convert to 64-bit</span>
<span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">lengthscales</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">mean_function</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">f64</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span> <span class="n">f64</span><span class="p">(</span><span class="mf">10.0</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">mean_function</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">f64</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span> <span class="n">f64</span><span class="p">(</span><span class="mf">10.0</span><span class="p">))</span>

<span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">print_summary</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                   </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th>value       </th></tr>
</thead>
<tbody>
<tr><td>GPR.mean_function.A    </td><td>Parameter</td><td>Identity        </td><td>Normal </td><td>True       </td><td>(1, 1) </td><td>float64</td><td>[[-0.79274]]</td></tr>
<tr><td>GPR.mean_function.b    </td><td>Parameter</td><td>Identity        </td><td>Normal </td><td>True       </td><td>()     </td><td>float64</td><td>3.37839     </td></tr>
<tr><td>GPR.kernel.variance    </td><td>Parameter</td><td>Softplus        </td><td>Gamma  </td><td>True       </td><td>()     </td><td>float64</td><td>0.85356     </td></tr>
<tr><td>GPR.kernel.lengthscales</td><td>Parameter</td><td>Softplus        </td><td>Gamma  </td><td>True       </td><td>()     </td><td>float64</td><td>0.07945     </td></tr>
<tr><td>GPR.likelihood.variance</td><td>Parameter</td><td>Softplus + Shift</td><td>Gamma  </td><td>True       </td><td>()     </td><td>float64</td><td>0.01652     </td></tr>
</tbody>
</table></div>
</div>
<p>We now sample from the posterior using HMC.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_burnin_steps</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Note that here we need model.trainable_parameters, not trainable_variables - only parameters can have priors!</span>
<span class="n">hmc_helper</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SamplingHelper</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">log_posterior_density</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span>
<span class="p">)</span>

<span class="n">hmc</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">HamiltonianMonteCarlo</span><span class="p">(</span>
    <span class="n">target_log_prob_fn</span><span class="o">=</span><span class="n">hmc_helper</span><span class="o">.</span><span class="n">target_log_prob_fn</span><span class="p">,</span>
    <span class="n">num_leapfrog_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">step_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">adaptive_hmc</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">SimpleStepSizeAdaptation</span><span class="p">(</span>
    <span class="n">hmc</span><span class="p">,</span>
    <span class="n">num_adaptation_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">target_accept_prob</span><span class="o">=</span><span class="n">f64</span><span class="p">(</span><span class="mf">0.75</span><span class="p">),</span>
    <span class="n">adaptation_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="p">)</span>


<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">run_chain_fn</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">sample_chain</span><span class="p">(</span>
        <span class="n">num_results</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">num_burnin_steps</span><span class="o">=</span><span class="n">num_burnin_steps</span><span class="p">,</span>
        <span class="n">current_state</span><span class="o">=</span><span class="n">hmc_helper</span><span class="o">.</span><span class="n">current_state</span><span class="p">,</span>
        <span class="n">kernel</span><span class="o">=</span><span class="n">adaptive_hmc</span><span class="p">,</span>
        <span class="n">trace_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">_</span><span class="p">,</span> <span class="n">pkr</span><span class="p">:</span> <span class="n">pkr</span><span class="o">.</span><span class="n">inner_results</span><span class="o">.</span><span class="n">is_accepted</span><span class="p">,</span>
    <span class="p">)</span>


<span class="n">samples</span><span class="p">,</span> <span class="n">traces</span> <span class="o">=</span> <span class="n">run_chain_fn</span><span class="p">()</span>
<span class="n">parameter_samples</span> <span class="o">=</span> <span class="n">hmc_helper</span><span class="o">.</span><span class="n">convert_to_constrained_values</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

<span class="n">param_to_name</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">param</span><span class="p">:</span> <span class="n">name</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">parameter_dict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<p><strong>NOTE:</strong> All the Hamiltonian MCMC sampling takes place in an unconstrained space (where constrained parameters have been mapped via a bijector to an unconstrained space). This makes the optimization, as required in the gradient step, much easier.</p>
<p>However, we often wish to sample the constrained parameter values, not the unconstrained one. The <code class="docutils literal notranslate"><span class="pre">SamplingHelper</span></code> helps us convert our unconstrained values to constrained parameter ones.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">y_axis_label</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">val</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">val</span><span class="p">),</span> <span class="n">label</span><span class="o">=</span><span class="n">param_to_name</span><span class="p">[</span><span class="n">param</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;HMC iteration&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">y_axis_label</span><span class="p">)</span>


<span class="n">plot_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">,</span> <span class="s2">&quot;unconstrained values&quot;</span><span class="p">)</span>
<span class="n">plot_samples</span><span class="p">(</span>
    <span class="n">parameter_samples</span><span class="p">,</span>
    <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">,</span>
    <span class="s2">&quot;constrained parameter values&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_17_0.png" src="../../_images/notebooks_advanced_mcmc_17_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_17_1.png" src="../../_images/notebooks_advanced_mcmc_17_1.png" />
</div>
</div>
<p>You can also inspect the marginal distribution of samples.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">marginal_samples</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">y_axis_label</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
        <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">param_to_name</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>
    <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">samples</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">val</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">param_to_name</span><span class="p">[</span><span class="n">param</span><span class="p">])</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">y_axis_label</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">marginal_samples</span><span class="p">(</span>
    <span class="n">samples</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">,</span> <span class="s2">&quot;unconstrained variable samples&quot;</span>
<span class="p">)</span>
<span class="n">marginal_samples</span><span class="p">(</span>
    <span class="n">parameter_samples</span><span class="p">,</span>
    <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">,</span>
    <span class="s2">&quot;constrained parameter samples&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_19_0.png" src="../../_images/notebooks_advanced_mcmc_19_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_19_1.png" src="../../_images/notebooks_advanced_mcmc_19_1.png" />
</div>
</div>
<p><strong>NOTE:</strong> The sampler runs in unconstrained space (so that positive parameters remain positive, and parameters that are not trainable are ignored).</p>
<p>For serious analysis you most certainly want to run the sampler longer, with multiple chains and convergence checks. This will do for illustration though!</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_joint_marginals</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">y_axis_label</span><span class="p">):</span>
    <span class="n">name_to_index</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">param_to_name</span><span class="p">[</span><span class="n">param</span><span class="p">]:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
    <span class="p">}</span>
    <span class="n">f</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">constrained_layout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">samples</span><span class="p">[</span><span class="n">name_to_index</span><span class="p">[</span><span class="s2">&quot;.likelihood.variance&quot;</span><span class="p">]],</span>
        <span class="n">samples</span><span class="p">[</span><span class="n">name_to_index</span><span class="p">[</span><span class="s2">&quot;.kernel.variance&quot;</span><span class="p">]],</span>
        <span class="s2">&quot;k.&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;noise_variance&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;signal_variance&quot;</span><span class="p">)</span>

    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">samples</span><span class="p">[</span><span class="n">name_to_index</span><span class="p">[</span><span class="s2">&quot;.likelihood.variance&quot;</span><span class="p">]],</span>
        <span class="n">samples</span><span class="p">[</span><span class="n">name_to_index</span><span class="p">[</span><span class="s2">&quot;.kernel.lengthscales&quot;</span><span class="p">]],</span>
        <span class="s2">&quot;k.&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;noise_variance&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;lengthscale&quot;</span><span class="p">)</span>

    <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="n">samples</span><span class="p">[</span><span class="n">name_to_index</span><span class="p">[</span><span class="s2">&quot;.kernel.lengthscales&quot;</span><span class="p">]],</span>
        <span class="n">samples</span><span class="p">[</span><span class="n">name_to_index</span><span class="p">[</span><span class="s2">&quot;.kernel.variance&quot;</span><span class="p">]],</span>
        <span class="s2">&quot;k.&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;lengthscale&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;signal_variance&quot;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">y_axis_label</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">plot_joint_marginals</span><span class="p">(</span>
    <span class="n">samples</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">,</span> <span class="s2">&quot;unconstrained variable samples&quot;</span>
<span class="p">)</span>
<span class="n">plot_joint_marginals</span><span class="p">(</span>
    <span class="n">parameter_samples</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">,</span> <span class="s2">&quot;parameter samples&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_21_0.png" src="../../_images/notebooks_advanced_mcmc_21_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_21_1.png" src="../../_images/notebooks_advanced_mcmc_21_1.png" />
</div>
</div>
<p>To plot the posterior of predictions, we’ll iterate through the samples and set the model state with each sample. Then, for that state (set of hyperparameters) we’ll draw some samples from the prediction function.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the function posterior</span>
<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="mi">20</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">var_samples</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">hmc_helper</span><span class="o">.</span><span class="n">current_state</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
        <span class="n">var</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">var_samples</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_f_samples</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">f</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span> <span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;kx&quot;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">xx</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$x$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$f|X,Y$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Posterior GP samples&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_23_0.png" src="../../_images/notebooks_advanced_mcmc_23_0.png" />
</div>
</div>
<p>This example demonstrates the multi-modality of the true posterior over hyperparameters: the data could be explained both by long lengthscale, small signal variance, and high noise variance, as well as by shorter lengthscale, higher signal variance, and low noise variance.</p>
</section>
</section>
<section id="Example-2:-Sparse-MC-for-multiclass-classification">
<h2>Example 2: Sparse MC for multiclass classification<a class="headerlink" href="#Example-2:-Sparse-MC-for-multiclass-classification" title="Permalink to this heading">#</a></h2>
<p>We now consider the multiclass classification problem (see the <a class="reference internal" href="multiclass_classification.html"><span class="doc">Multiclass classification</span></a> notebook). Here the marginal likelihood is not available in closed form. Instead we use a sparse variational approximation where we approximate the posterior for each GP as <span class="math notranslate nohighlight">\(q(f_c) \propto p(f_c|\mathbf{u}_c)q(\mathbf{u}_c)\)</span></p>
<p>In the standard Sparse Variational GP (SVGP) formulation, <span class="math notranslate nohighlight">\(q(\mathbf{u_c})\)</span> is parameterized as a multivariate Gaussian.</p>
<p>An alternative is to directly sample from the optimal <span class="math notranslate nohighlight">\(q(\mathbf{u}_c)\)</span>; this is what Sparse Variational GP using MCMC (SGPMC) does.</p>
<p>We first build a multiclass classification dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate data by sampling from SquaredExponential kernel, and classifying with the argmax</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">C</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="n">lengthscales</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">kernel</span><span class="o">.</span><span class="n">K</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="mf">1e-6</span>

<span class="n">f</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">cov</span><span class="o">=</span><span class="n">K</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">C</span><span class="p">))</span><span class="o">.</span><span class="n">T</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="c1"># One-hot encoding</span>
<span class="n">Y_hot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
<span class="n">Y_hot</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">Y</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>

<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">C</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">order</span><span class="p">],</span> <span class="n">f</span><span class="p">[</span><span class="n">order</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="s2">&quot;.&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">c</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">order</span><span class="p">],</span> <span class="n">Y_hot</span><span class="p">[</span><span class="n">order</span><span class="p">,</span> <span class="n">c</span><span class="p">],</span> <span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">c</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$X$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Latent (dots) and one-hot labels (lines)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Sample from the joint $p(Y, \mathbf</span><span class="si">{f}</span><span class="s2">)$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_29_0.png" src="../../_images/notebooks_advanced_mcmc_29_0.png" />
</div>
</div>
<p>We then build the SGPMC model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Matern32</span><span class="p">(</span><span class="n">lengthscales</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> <span class="o">+</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">White</span><span class="p">(</span>
    <span class="n">variance</span><span class="o">=</span><span class="mf">0.01</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SGPMC</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span>
    <span class="n">likelihood</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">MultiClass</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
    <span class="n">inducing_variable</span><span class="o">=</span><span class="n">X</span><span class="p">[::</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
    <span class="n">num_latent_gps</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lengthscales</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="n">f64</span><span class="p">(</span><span class="mf">2.0</span><span class="p">),</span> <span class="n">f64</span><span class="p">(</span><span class="mf">2.0</span><span class="p">))</span>
<span class="n">set_trainable</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">variance</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

<span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">print_summary</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                                </th><th>class    </th><th>transform  </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th>value          </th></tr>
</thead>
<tbody>
<tr><td>SGPMC.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>Gamma  </td><td>True       </td><td>()     </td><td>float64</td><td>1.0            </td></tr>
<tr><td>SGPMC.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>Gamma  </td><td>True       </td><td>()     </td><td>float64</td><td>0.1            </td></tr>
<tr><td>SGPMC.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>       </td><td>False      </td><td>()     </td><td>float64</td><td>0.01           </td></tr>
<tr><td>SGPMC.likelihood.invlink.epsilon    </td><td>Parameter</td><td>Sigmoid    </td><td>Beta   </td><td>False      </td><td>()     </td><td>float64</td><td>0.001          </td></tr>
<tr><td>SGPMC.inducing_variable.Z           </td><td>Parameter</td><td>Identity   </td><td>       </td><td>True       </td><td>(20, 1)</td><td>float64</td><td>[[0.37454...   </td></tr>
<tr><td>SGPMC.V                             </td><td>Parameter</td><td>Identity   </td><td>Normal </td><td>True       </td><td>(20, 3)</td><td>float64</td><td>[[0., 0., 0....</td></tr>
</tbody>
</table></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The inducing point locations Z should not be included in the MCMC (see [Hensman et al. (2015)](https://papers.nips.cc/paper/5875-mcmc-for-variationally-sparse-gaussian-processes), hence we set them to non-trainable.</span>
<span class="n">set_trainable</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">inducing_variable</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The chain of samples for <span class="math notranslate nohighlight">\(\mathbf{u}_c, \theta\)</span> is initialized at the value maximizing <span class="math notranslate nohighlight">\(p(Y|\mathbf{u}_c, \theta)\)</span>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="mi">20</span><span class="p">}</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;log posterior density at optimum: </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">log_posterior_density</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
log posterior density at optimum: -79.7654902747724
</pre></div></div>
</div>
<p>Sampling starts with a ‘burn in’ period.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_burnin_steps</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>

<span class="c1"># Note that here we need model.trainable_parameters, not trainable_variables - only parameters can have priors!</span>
<span class="n">hmc_helper</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SamplingHelper</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">log_posterior_density</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span>
<span class="p">)</span>

<span class="n">hmc</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">HamiltonianMonteCarlo</span><span class="p">(</span>
    <span class="n">target_log_prob_fn</span><span class="o">=</span><span class="n">hmc_helper</span><span class="o">.</span><span class="n">target_log_prob_fn</span><span class="p">,</span>
    <span class="n">num_leapfrog_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">step_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">adaptive_hmc</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">SimpleStepSizeAdaptation</span><span class="p">(</span>
    <span class="n">hmc</span><span class="p">,</span>
    <span class="n">num_adaptation_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">target_accept_prob</span><span class="o">=</span><span class="n">f64</span><span class="p">(</span><span class="mf">0.75</span><span class="p">),</span>
    <span class="n">adaptation_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="p">)</span>


<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">run_chain_fn</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">sample_chain</span><span class="p">(</span>
        <span class="n">num_results</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">num_burnin_steps</span><span class="o">=</span><span class="n">num_burnin_steps</span><span class="p">,</span>
        <span class="n">current_state</span><span class="o">=</span><span class="n">hmc_helper</span><span class="o">.</span><span class="n">current_state</span><span class="p">,</span>
        <span class="n">kernel</span><span class="o">=</span><span class="n">adaptive_hmc</span><span class="p">,</span>
        <span class="n">trace_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">_</span><span class="p">,</span> <span class="n">pkr</span><span class="p">:</span> <span class="n">pkr</span><span class="o">.</span><span class="n">inner_results</span><span class="o">.</span><span class="n">is_accepted</span><span class="p">,</span>
    <span class="p">)</span>


<span class="n">samples</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">run_chain_fn</span><span class="p">()</span>
<span class="n">constrained_samples</span> <span class="o">=</span> <span class="n">hmc_helper</span><span class="o">.</span><span class="n">convert_to_constrained_values</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Statistics of the posterior samples can now be reported.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_from_samples</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">,</span> <span class="n">constrained_samples</span><span class="p">,</span> <span class="n">thin</span><span class="o">=</span><span class="mi">10</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_38_0.png" src="../../_images/notebooks_advanced_mcmc_38_0.png" />
</div>
</div>
<p>You can also display the sequence of sampled hyperparameters.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">param_to_name</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">param</span><span class="p">:</span> <span class="n">name</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">parameter_dict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="p">}</span>
<span class="n">name_to_index</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">param_to_name</span><span class="p">[</span><span class="n">param</span><span class="p">]:</span> <span class="n">i</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">)</span>
<span class="p">}</span>
<span class="n">hyperparameters</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;.kernel.kernels[0].lengthscales&quot;</span><span class="p">,</span>
    <span class="s2">&quot;.kernel.kernels[0].variance&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">hyperparameters</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">constrained_samples</span><span class="p">[</span><span class="n">name_to_index</span><span class="p">[</span><span class="n">param_name</span><span class="p">]],</span> <span class="n">label</span><span class="o">=</span><span class="n">param_name</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;HMC iteration&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;hyperparameter value&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_40_0.png" src="../../_images/notebooks_advanced_mcmc_40_0.png" />
</div>
</div>
</section>
<section id="Example-3:-Fully-Bayesian-inference-for-generalized-GP-models-with-HMC">
<h2>Example 3: Fully Bayesian inference for generalized GP models with HMC<a class="headerlink" href="#Example-3:-Fully-Bayesian-inference-for-generalized-GP-models-with-HMC" title="Permalink to this heading">#</a></h2>
<p>You can construct very flexible models with Gaussian processes by combining them with different likelihoods (sometimes called ‘families’ in the GLM literature). This makes inference of the GP intractable because the likelihoods are not generally conjugate to the Gaussian process. The general form of the model is <span class="math">\begin{align}
\theta &\sim p(\theta) \\
f &\sim \mathcal {GP}(m(x; \theta),\, k(x, x'; \theta)) \\
y_i &\sim p(y | g(f(x_i))\,.
\end{align}</span></p>
<p>To perform inference in this model, we’ll run MCMC using Hamiltonian Monte Carlo (HMC) over the function values and the parameters <span class="math notranslate nohighlight">\(\theta\)</span> jointly. The key to an effective scheme is rotation of the field using the Cholesky decomposition. We write:</p>
<p><span class="math">\begin{align}
\theta &\sim p(\theta) \\
v &\sim \mathcal {N}(0,\, I) \\
LL^\top &= K \\
f &= m + Lv \\
y_i &\sim p(y | g(f(x_i))\,.
\end{align}</span></p>
<p>Joint HMC over <span class="math notranslate nohighlight">\(v\)</span> and the function values is not widely adopted in the literature because of the difficulty in differentiating <span class="math notranslate nohighlight">\(LL^\top=K\)</span>. We’ve made this derivative available in TensorFlow, and so application of HMC is relatively straightforward.</p>
<section id="Exponential-Regression">
<h3>Exponential Regression<a class="headerlink" href="#Exponential-Regression" title="Permalink to this heading">#</a></h3>
<p>We consider an exponential regression model: <span class="math">\begin{align}
\theta &\sim p(\theta) \\
f &\sim \mathcal {GP}(0, k(x, x'; \theta)) \\
f_i &= f(x_i) \\
y_i &\sim \mathcal {Exp} (e^{f_i})
\end{align}</span></p>
<p>We’ll use MCMC to deal with both the kernel parameters <span class="math notranslate nohighlight">\(\theta\)</span> and the latent function values <span class="math notranslate nohighlight">\(f\)</span>. Firstly, generate a data set.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">14</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">exponential</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;input $X$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;output $Y$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;toy dataset&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="n">Y</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_44_0.png" src="../../_images/notebooks_advanced_mcmc_44_0.png" />
</div>
</div>
<p>GPflow’s model for fully-Bayesian MCMC is called GPMC. It’s constructed like any other model, but contains a parameter <code class="docutils literal notranslate"><span class="pre">V</span></code> which represents the centered values of the function.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Matern32</span><span class="p">()</span> <span class="o">+</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Constant</span><span class="p">()</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">Exponential</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPMC</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">V</span></code> parameter already has a prior applied. We’ll add priors to the parameters also (these are rather arbitrary, for illustration).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lengthscales</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">),</span> <span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>

<span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">print_summary</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                               </th><th>class    </th><th>transform  </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th>value  </th></tr>
</thead>
<tbody>
<tr><td>GPMC.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus   </td><td>Gamma  </td><td>True       </td><td>()     </td><td>float64</td><td>1.0    </td></tr>
<tr><td>GPMC.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus   </td><td>Gamma  </td><td>True       </td><td>()     </td><td>float64</td><td>1.0    </td></tr>
<tr><td>GPMC.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus   </td><td>Gamma  </td><td>True       </td><td>()     </td><td>float64</td><td>1.0    </td></tr>
<tr><td>GPMC.V                             </td><td>Parameter</td><td>Identity   </td><td>Normal </td><td>True       </td><td>(20, 1)</td><td>float64</td><td>[[0....</td></tr>
</tbody>
</table></div>
</div>
<p>Running HMC is pretty similar to optimizing a model. GPflow builds on top of <a class="reference external" href="https://www.tensorflow.org/probability/api_docs/python/tfp/mcmc">tensorflow_probability’s mcmc module</a> and provides a SamplingHelper class to make interfacing easier.</p>
<p>We initialize HMC at the maximum a posteriori parameter values of the model.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>
<span class="n">maxiter</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">3000</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span>
    <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span><span class="p">),</span>
<span class="p">)</span>
<span class="c1"># We can now start HMC near maximum a posteriori (MAP)</span>
</pre></div>
</div>
</div>
<p>We then run the sampler,</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_burnin_steps</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">600</span><span class="p">)</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Note that here we need model.trainable_parameters, not trainable_variables - only parameters can have priors!</span>
<span class="n">hmc_helper</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SamplingHelper</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">log_posterior_density</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span>
<span class="p">)</span>

<span class="n">hmc</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">HamiltonianMonteCarlo</span><span class="p">(</span>
    <span class="n">target_log_prob_fn</span><span class="o">=</span><span class="n">hmc_helper</span><span class="o">.</span><span class="n">target_log_prob_fn</span><span class="p">,</span>
    <span class="n">num_leapfrog_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">step_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">adaptive_hmc</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">SimpleStepSizeAdaptation</span><span class="p">(</span>
    <span class="n">hmc</span><span class="p">,</span>
    <span class="n">num_adaptation_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">target_accept_prob</span><span class="o">=</span><span class="n">f64</span><span class="p">(</span><span class="mf">0.75</span><span class="p">),</span>
    <span class="n">adaptation_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="p">)</span>


<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">run_chain_fn</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">sample_chain</span><span class="p">(</span>
        <span class="n">num_results</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">num_burnin_steps</span><span class="o">=</span><span class="n">num_burnin_steps</span><span class="p">,</span>
        <span class="n">current_state</span><span class="o">=</span><span class="n">hmc_helper</span><span class="o">.</span><span class="n">current_state</span><span class="p">,</span>
        <span class="n">kernel</span><span class="o">=</span><span class="n">adaptive_hmc</span><span class="p">,</span>
        <span class="n">trace_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">_</span><span class="p">,</span> <span class="n">pkr</span><span class="p">:</span> <span class="n">pkr</span><span class="o">.</span><span class="n">inner_results</span><span class="o">.</span><span class="n">is_accepted</span><span class="p">,</span>
    <span class="p">)</span>


<span class="n">samples</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">run_chain_fn</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>And compute the posterior prediction on a grid for plotting purposes.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xtest</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">100</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
<span class="n">f_samples</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_samples</span><span class="p">):</span>
    <span class="c1"># Note that hmc_helper.current_state contains the unconstrained variables</span>
    <span class="k">for</span> <span class="n">var</span><span class="p">,</span> <span class="n">var_samples</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">hmc_helper</span><span class="o">.</span><span class="n">current_state</span><span class="p">,</span> <span class="n">samples</span><span class="p">):</span>
        <span class="n">var</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">var_samples</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_f_samples</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">f_samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
<span class="n">f_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">f_samples</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rate_samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">f_samples</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">])</span>

<span class="p">(</span><span class="n">line</span><span class="p">,)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">rate_samples</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
    <span class="n">Xtest</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
    <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">rate_samples</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">rate_samples</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">color</span><span class="o">=</span><span class="n">line</span><span class="o">.</span><span class="n">get_color</span><span class="p">(),</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;kx&quot;</span><span class="p">,</span> <span class="n">mew</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">rate_samples</span><span class="p">,</span> <span class="mi">95</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_56_0.png" src="../../_images/notebooks_advanced_mcmc_56_0.png" />
</div>
</div>
<p>You can also display the sequence of sampled hyperparameters.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">parameter_samples</span> <span class="o">=</span> <span class="n">hmc_helper</span><span class="o">.</span><span class="n">convert_to_constrained_values</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="n">param_to_name</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">param</span><span class="p">:</span> <span class="n">name</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">parameter_dict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="p">}</span>
<span class="n">name_to_index</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">param_to_name</span><span class="p">[</span><span class="n">param</span><span class="p">]:</span> <span class="n">i</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">)</span>
<span class="p">}</span>
<span class="n">hyperparameters</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;.kernel.kernels[0].lengthscales&quot;</span><span class="p">,</span>
    <span class="s2">&quot;.kernel.kernels[0].variance&quot;</span><span class="p">,</span>
    <span class="s2">&quot;.kernel.kernels[1].variance&quot;</span><span class="p">,</span>
<span class="p">]</span>


<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="n">hyperparameters</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">parameter_samples</span><span class="p">[</span><span class="n">name_to_index</span><span class="p">[</span><span class="n">param_name</span><span class="p">]],</span> <span class="n">label</span><span class="o">=</span><span class="n">param_name</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;HMC iteration&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;hyperparameter value&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_58_0.png" src="../../_images/notebooks_advanced_mcmc_58_0.png" />
</div>
</div>
<p>You can also inspect the marginal of the posterior samples.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hyperparameters</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">hyperparameters</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">parameter_samples</span><span class="p">[</span><span class="n">name_to_index</span><span class="p">[</span><span class="n">param_name</span><span class="p">]],</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">param_name</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_60_0.png" src="../../_images/notebooks_advanced_mcmc_60_0.png" />
</div>
</div>
</section>
</section>
<section id="Prior-on-constrained-and-unconstrained-parameters">
<h2>Prior on constrained and unconstrained parameters<a class="headerlink" href="#Prior-on-constrained-and-unconstrained-parameters" title="Permalink to this heading">#</a></h2>
<p>GPflow’s <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> class provides options for setting a prior. <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> wraps a constrained tensor and provides computation of the gradient with respect to unconstrained transformation of that tensor. The user can set a prior either in <strong>constrained</strong> space or <strong>unconstrained</strong> space.</p>
<p>By default, the prior for the <code class="docutils literal notranslate"><span class="pre">Parameter</span></code> is set on the <em>constrained</em> space. To explicitly set the space on which the prior is defined, use the <code class="docutils literal notranslate"><span class="pre">prior_on</span></code> keyword argument:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prior_distribution</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">f64</span><span class="p">(</span><span class="mf">0.0</span><span class="p">),</span> <span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">prior_on</span><span class="o">=</span><span class="s2">&quot;unconstrained&quot;</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior_distribution</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">prior_on</span><span class="o">=</span><span class="s2">&quot;constrained&quot;</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior_distribution</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">gpflow.optimizers.SamplingHelper</span></code> makes sure that the prior density correctly reflects the space in which the prior is defined.</p>
<p>Below we repeat the same experiment as before, but with some priors defined in the <code class="docutils literal notranslate"><span class="pre">unconstrained</span></code> space. We are using the exponential transform to ensure positivity of the kernel parameters (<code class="docutils literal notranslate"><span class="pre">set_default_positive_bijector(&quot;exp&quot;)</span></code>), so a log-normal prior on a constrained parameter corresponds to a normal prior on the unconstrained space:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_positive_bijector</span><span class="p">(</span><span class="s2">&quot;exp&quot;</span><span class="p">)</span>
<span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_positive_minimum</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">)</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">synthetic_data</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">rng</span><span class="p">)</span>

<span class="n">kernel</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Matern52</span><span class="p">(</span><span class="n">lengthscales</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">meanf</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">mean_functions</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPR</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">meanf</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>

<span class="n">mu</span> <span class="o">=</span> <span class="n">f64</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">f64</span><span class="p">(</span><span class="mf">4.0</span><span class="p">)</span>
<span class="n">one</span> <span class="o">=</span> <span class="n">f64</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">lengthscales</span><span class="o">.</span><span class="n">prior_on</span> <span class="o">=</span> <span class="s2">&quot;unconstrained&quot;</span>
<span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">lengthscales</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior_on</span> <span class="o">=</span> <span class="s2">&quot;unconstrained&quot;</span>
<span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior_on</span> <span class="o">=</span> <span class="s2">&quot;unconstrained&quot;</span>
<span class="n">model</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">mean_function</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">prior_on</span> <span class="o">=</span> <span class="s2">&quot;constrained&quot;</span>
<span class="n">model</span><span class="o">.</span><span class="n">mean_function</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">mean_function</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">prior_on</span> <span class="o">=</span> <span class="s2">&quot;constrained&quot;</span>
<span class="n">model</span><span class="o">.</span><span class="n">mean_function</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfd</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">std</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">lengthscales</span><span class="o">.</span><span class="n">prior_on</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;PriorOn.UNCONSTRAINED: &#39;unconstrained&#39;&gt;
</pre></div></div>
</div>
<p>Let’s run HMC and plot chain traces:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_burnin_steps</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">300</span><span class="p">)</span>
<span class="n">num_samples</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>

<span class="n">hmc_helper</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SamplingHelper</span><span class="p">(</span>
    <span class="n">model</span><span class="o">.</span><span class="n">log_posterior_density</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span>
<span class="p">)</span>

<span class="n">hmc</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">HamiltonianMonteCarlo</span><span class="p">(</span>
    <span class="n">target_log_prob_fn</span><span class="o">=</span><span class="n">hmc_helper</span><span class="o">.</span><span class="n">target_log_prob_fn</span><span class="p">,</span>
    <span class="n">num_leapfrog_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">step_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">adaptive_hmc</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">SimpleStepSizeAdaptation</span><span class="p">(</span>
    <span class="n">hmc</span><span class="p">,</span>
    <span class="n">num_adaptation_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">target_accept_prob</span><span class="o">=</span><span class="n">f64</span><span class="p">(</span><span class="mf">0.75</span><span class="p">),</span>
    <span class="n">adaptation_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<span class="p">)</span>


<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">run_chain_fn_unconstrained</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">tfp</span><span class="o">.</span><span class="n">mcmc</span><span class="o">.</span><span class="n">sample_chain</span><span class="p">(</span>
        <span class="n">num_results</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
        <span class="n">num_burnin_steps</span><span class="o">=</span><span class="n">num_burnin_steps</span><span class="p">,</span>
        <span class="n">current_state</span><span class="o">=</span><span class="n">hmc_helper</span><span class="o">.</span><span class="n">current_state</span><span class="p">,</span>
        <span class="n">kernel</span><span class="o">=</span><span class="n">adaptive_hmc</span><span class="p">,</span>
        <span class="n">trace_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">_</span><span class="p">,</span> <span class="n">pkr</span><span class="p">:</span> <span class="n">pkr</span><span class="o">.</span><span class="n">inner_results</span><span class="o">.</span><span class="n">is_accepted</span><span class="p">,</span>
    <span class="p">)</span>


<span class="n">samples</span><span class="p">,</span> <span class="n">traces</span> <span class="o">=</span> <span class="n">run_chain_fn_unconstrained</span><span class="p">()</span>
<span class="n">parameter_samples</span> <span class="o">=</span> <span class="n">hmc_helper</span><span class="o">.</span><span class="n">convert_to_constrained_values</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>

<span class="n">param_to_name</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">param</span><span class="p">:</span> <span class="n">name</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">parameter_dict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
<span class="p">}</span>
<span class="n">marginal_samples</span><span class="p">(</span>
    <span class="n">samples</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">,</span> <span class="s2">&quot;unconstrained variable samples&quot;</span>
<span class="p">)</span>
<span class="n">marginal_samples</span><span class="p">(</span>
    <span class="n">parameter_samples</span><span class="p">,</span>
    <span class="n">model</span><span class="o">.</span><span class="n">trainable_parameters</span><span class="p">,</span>
    <span class="s2">&quot;constrained parameter samples&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_69_0.png" src="../../_images/notebooks_advanced_mcmc_69_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_advanced_mcmc_69_1.png" src="../../_images/notebooks_advanced_mcmc_69_1.png" />
</div>
</div>
</section>
</section>


            </article>
            
            
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Example-1:-GP-regression">
   Example 1: GP regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Data-for-a-one-dimensional-regression-problem">
     Data for a one-dimensional regression problem
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#MCMC-for-hyperparameters-\theta">
     MCMC for hyperparameters
     <span class="math notranslate nohighlight">
      \(\theta\)
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Example-2:-Sparse-MC-for-multiclass-classification">
   Example 2: Sparse MC for multiclass classification
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Example-3:-Fully-Bayesian-inference-for-generalized-GP-models-with-HMC">
   Example 3: Fully Bayesian inference for generalized GP models with HMC
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Exponential-Regression">
     Exponential Regression
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Prior-on-constrained-and-unconstrained-parameters">
   Prior on constrained and unconstrained parameters
  </a>
 </li>
</ul>

</nav>
</div>

<div class="toc-item">
  
<div id="searchbox"></div>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1e1de1a1873e13ef5536"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022, The GPflow Contributors.<br>

</p>

  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.2.3.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>