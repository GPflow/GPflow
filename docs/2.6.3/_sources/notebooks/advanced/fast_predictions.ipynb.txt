{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240052b1",
   "metadata": {
    "id": "eYrSpUncKGSk"
   },
   "source": [
    "# Faster predictions by caching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d5b28",
   "metadata": {
    "id": "PLuPjfS7KLQ-"
   },
   "source": [
    "The default behaviour of `predict_f` in GPflow models is to compute the predictions from scratch on each call. This is convenient when predicting and training are interleaved, and simplifies the use of these models. There are some use cases, such as Bayesian optimisation, where prediction (at different test points) happens much more frequently than training. In these cases it is convenient to cache parts of the calculation which do not depend upon the test points, and reuse those parts between predictions.\n",
    "\n",
    "There are three models to which we want to add this caching capability: GPR, (S)VGP and SGPR. The VGP and SVGP can be considered together; the difference between the models is whether to condition on the full training data set (VGP) or on the inducing variables (SVGP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef46dae",
   "metadata": {
    "id": "EACkO-iRKM5T"
   },
   "source": [
    "## Posterior predictive distribution\n",
    "\n",
    "The posterior predictive distribution evaluated at a set of test points $\\mathbf{x}_*$ for a Gaussian process model is given by:\n",
    "\\begin{equation*}\n",
    "p(\\mathbf{f}_*|X, Y) = \\mathcal{N}(\\mu, \\Sigma)\n",
    "\\end{equation*}\n",
    "\n",
    "In the case of the GPR model, the parameters $\\mu$ and $\\Sigma$ are given by:\n",
    "\\begin{equation*}\n",
    "\\mu = K_{nm}[K_{mm} + \\sigma^2I]^{-1}\\mathbf{y}\n",
    "\\end{equation*}\n",
    "and\n",
    "\\begin{equation*}\n",
    "\\Sigma = K_{nn} - K_{nm}[K_{mm} + \\sigma^2I]^{-1}K_{mn}\n",
    "\\end{equation*}\n",
    "\n",
    "The posterior predictive distribution for the VGP and SVGP model is parameterised as follows:\n",
    "\\begin{equation*}\n",
    "\\mu = K_{nu}K_{uu}^{-1}\\mathbf{u}\n",
    "\\end{equation*}\n",
    "and\n",
    "\\begin{equation*}\n",
    "\\Sigma = K_{nn} - K_{nu}K_{uu}^{-1}K_{un}\n",
    "\\end{equation*}\n",
    "\n",
    "Finally, the parameters for the SGPR model are:\n",
    "\\begin{equation*}\n",
    "\\mu = K_{nu}L^{-T}L_B^{-T}\\mathbf{c}\n",
    "\\end{equation*}\n",
    "and\n",
    "\\begin{equation*}\n",
    "\\Sigma = K_{nn} - K_{nu}L^{-T}(I - B^{-1})L^{-1}K_{un}\n",
    "\\end{equation*}\n",
    "\n",
    "Where the mean function is not the zero function, the predictive mean should have the mean function evaluated at the test points added to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0646b0",
   "metadata": {
    "id": "GX1U-fYPKPrt"
   },
   "source": [
    "## What can be cached?\n",
    "\n",
    "We cache two separate values: $\\alpha$ and $Q^{-1}$. These correspond to the parts of the mean and covariance functions respectively which do not depend upon the test points. In the case of the GPR these are the same value:\n",
    "\\begin{equation*}\n",
    "\\alpha = Q^{-1} = [K_{mm} + \\sigma^2I]^{-1}\n",
    "\\end{equation*}\n",
    "in the case of the VGP and SVGP model these are:\n",
    "\\begin{equation*}\n",
    "\\alpha = K_{uu}^{-1}\\mathbf{u}\\\\ Q^{-1} = K_{uu}^{-1}\n",
    "\\end{equation*}\n",
    "and in the case of the SGPR model these are:\n",
    "\\begin{equation*}\n",
    "\\alpha = L^{-T}L_B^{-T}\\mathbf{c}\\\\ Q^{-1} = L^{-T}(I - B^{-1})L^{-1}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Note that in the (S)VGP case, $\\alpha$ is the parameter as proposed by Opper and Archambeau for the mean of the predictive distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2278a41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:13:36.074928Z",
     "iopub.status.busy": "2022-12-02T11:13:36.074629Z",
     "iopub.status.idle": "2022-12-02T11:13:39.907337Z",
     "shell.execute_reply": "2022-12-02T11:13:39.906713Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 11:13:36.352200: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-02 11:13:36.481785: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-02 11:13:36.481812: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-02 11:13:36.510589: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 11:13:37.115475: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-02 11:13:37.115549: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-02 11:13:37.115558: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import gpflow\n",
    "from gpflow.ci_utils import reduce_in_tests\n",
    "\n",
    "# Create some data\n",
    "n_data = reduce_in_tests(1000)\n",
    "X = np.linspace(-1.1, 1.1, n_data)[:, None]\n",
    "Y = np.sin(X)\n",
    "Xnew = np.linspace(-1.1, 1.1, n_data)[:, None]\n",
    "inducing_points = Xnew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5998f2",
   "metadata": {
    "id": "FzCgor4nKUcW"
   },
   "source": [
    "\n",
    "## GPR Example\n",
    "\n",
    "We will construct a GPR model to demonstrate the faster predictions from using the cached data in the GPFlow posterior classes (subclasses of `gpflow.posteriors.AbstractPosterior`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2fe8d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:13:39.911709Z",
     "iopub.status.busy": "2022-12-02T11:13:39.911227Z",
     "iopub.status.idle": "2022-12-02T11:13:40.029113Z",
     "shell.execute_reply": "2022-12-02T11:13:40.028384Z"
    },
    "id": "BMnIdXNiKU6t"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You're calling gpflow.experimental.check_shapes.checker.ShapeChecker.__init__ which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.\n",
      "  warn(\n",
      "2022-12-02 11:13:39.914660: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-02 11:13:39.914918: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-02 11:13:39.914940: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (7394a4ccd063): /proc/driver/nvidia/version does not exist\n",
      "2022-12-02 11:13:39.915558: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = gpflow.models.GPR(\n",
    "    (X, Y),\n",
    "    gpflow.kernels.SquaredExponential(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8448aeef",
   "metadata": {},
   "source": [
    "The `predict_f` method on the `GPModel` class performs no caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d2fa515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:13:40.031772Z",
     "iopub.status.busy": "2022-12-02T11:13:40.031482Z",
     "iopub.status.idle": "2022-12-02T11:13:41.400396Z",
     "shell.execute_reply": "2022-12-02T11:13:41.399769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 ms ± 4.12 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model.predict_f(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be701aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:13:41.402968Z",
     "iopub.status.busy": "2022-12-02T11:13:41.402682Z",
     "iopub.status.idle": "2022-12-02T11:13:41.452772Z",
     "shell.execute_reply": "2022-12-02T11:13:41.451992Z"
    }
   },
   "outputs": [],
   "source": [
    "# To make use of the caching, first retrieve the posterior class from the model. The posterior class has methods to predict the parameters of marginal distributions at test points, in the same way as the `predict_f` method of the `GPModel`.\n",
    "posterior = model.posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd4d8742",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:13:41.455624Z",
     "iopub.status.busy": "2022-12-02T11:13:41.455339Z",
     "iopub.status.idle": "2022-12-02T11:13:51.097403Z",
     "shell.execute_reply": "2022-12-02T11:13:51.096569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119 ms ± 3.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "posterior.predict_f(Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedece59",
   "metadata": {},
   "source": [
    "## SVGP Example\n",
    "\n",
    "Likewise, we will construct an SVGP model to demonstrate the faster predictions from using the cached data in the GPFlow posterior classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db98d4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:13:51.100247Z",
     "iopub.status.busy": "2022-12-02T11:13:51.099939Z",
     "iopub.status.idle": "2022-12-02T11:13:51.174561Z",
     "shell.execute_reply": "2022-12-02T11:13:51.173870Z"
    },
    "id": "BMnIdXNiKU6t"
   },
   "outputs": [],
   "source": [
    "model = gpflow.models.SVGP(\n",
    "    gpflow.kernels.SquaredExponential(),\n",
    "    gpflow.likelihoods.Gaussian(),\n",
    "    inducing_points,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0483342",
   "metadata": {},
   "source": [
    "The `predict_f` method on the `GPModel` class performs no caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3c5139",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:13:51.177509Z",
     "iopub.status.busy": "2022-12-02T11:13:51.177216Z",
     "iopub.status.idle": "2022-12-02T11:14:08.546644Z",
     "shell.execute_reply": "2022-12-02T11:14:08.546045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 ms ± 4.89 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model.predict_f(Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887bd4e6",
   "metadata": {},
   "source": [
    "And again using the posterior object and caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4be92cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:14:08.549149Z",
     "iopub.status.busy": "2022-12-02T11:14:08.548870Z",
     "iopub.status.idle": "2022-12-02T11:14:08.818412Z",
     "shell.execute_reply": "2022-12-02T11:14:08.817771Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior = model.posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2653db2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:14:08.821275Z",
     "iopub.status.busy": "2022-12-02T11:14:08.820997Z",
     "iopub.status.idle": "2022-12-02T11:14:17.549170Z",
     "shell.execute_reply": "2022-12-02T11:14:17.548544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109 ms ± 3.23 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "posterior.predict_f(Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a8b31b",
   "metadata": {},
   "source": [
    "## SGPR Example\n",
    "\n",
    "And finally, we follow the same approach this time for the SGPR case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f96f24e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:14:17.551817Z",
     "iopub.status.busy": "2022-12-02T11:14:17.551522Z",
     "iopub.status.idle": "2022-12-02T11:14:17.573848Z",
     "shell.execute_reply": "2022-12-02T11:14:17.573267Z"
    }
   },
   "outputs": [],
   "source": [
    "model = gpflow.models.SGPR(\n",
    "    (X, Y), gpflow.kernels.SquaredExponential(), inducing_points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be83d893",
   "metadata": {},
   "source": [
    "The predict_f method on the instance performs no caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b84c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:14:17.576684Z",
     "iopub.status.busy": "2022-12-02T11:14:17.576411Z",
     "iopub.status.idle": "2022-12-02T11:14:20.092028Z",
     "shell.execute_reply": "2022-12-02T11:14:20.091416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301 ms ± 8.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model.predict_f(Xnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14840d96",
   "metadata": {},
   "source": [
    "Using the posterior object instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a700e5b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:14:20.094668Z",
     "iopub.status.busy": "2022-12-02T11:14:20.094390Z",
     "iopub.status.idle": "2022-12-02T11:14:20.278399Z",
     "shell.execute_reply": "2022-12-02T11:14:20.277753Z"
    }
   },
   "outputs": [],
   "source": [
    "posterior = model.posterior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c00884e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T11:14:20.281334Z",
     "iopub.status.busy": "2022-12-02T11:14:20.281046Z",
     "iopub.status.idle": "2022-12-02T11:14:29.001102Z",
     "shell.execute_reply": "2022-12-02T11:14:29.000432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 ms ± 352 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "posterior.predict_f(Xnew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
