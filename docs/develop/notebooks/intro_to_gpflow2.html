
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>GPflow with TensorFlow 2 &#8212; GPflow 2.6.2 documentation</title>
  <script>
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1e1de1a1873e13ef5536" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1e1de1a1873e13ef5536" rel="stylesheet">

  
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/6.1.2/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/pydata-custom.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1e1de1a1873e13ef5536">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@^1.0.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/intro_to_gpflow2';</script>
    <script>
        DOCUMENTATION_OPTIONS.theme_switcher_json_url = 'https://gpflow.github.io/GPflow/versions.json';
        DOCUMENTATION_OPTIONS.theme_switcher_version_match = 'develop';
        </script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Notebooks" href="../notebooks_file.html" />
    <link rel="prev" title="GPflow manual" href="../manual.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">

  
  <input type="checkbox" class="sidebar-toggle" name="__primary" id="__primary">
  <label class="overlay overlay-primary" for="__primary"></label>

  
  <input type="checkbox" class="sidebar-toggle" name="__secondary" id="__secondary">
  <label class="overlay overlay-secondary" for="__secondary"></label>

  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
      
<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false">
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
    </div>
  </div>

  
  <nav class="bd-header navbar navbar-expand-lg bd-navbar" id="navbar-main"><div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
      <span class="fa-solid fa-bars"></span>
  </label>
  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../index.html">

  
  
  
  
  
  
  

  
    <img src="../_static/gpflow_logo.svg" class="logo__image only-light" alt="Logo image">
    <img src="../_static/gpflow_logo.svg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  
  <div class="col-lg-9 navbar-header-items">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../intro.html">
                        Introduction
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../manual.html">
                        GPflow manual
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="#">
                        GPflow with TensorFlow 2
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../notebooks_file.html">
                        Notebooks
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../derivations.html">
                        Derivations
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../api/gpflow/index.html">
                        API reference
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../bibliography.html">
                        Bibliography
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
    </div>

    <div id="navbar-end">
      <div class="navbar-end-item navbar-end__search-button-container">
        
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
      </div>
      
      <div class="navbar-end-item">
        <div class="version-switcher__container dropdown">
    <button type="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-toggle="dropdown">
        develop  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div class="version-switcher__menu dropdown-menu list-group-flush py-0">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>
      </div>
      
    </div>
  </div>


  
  <div class="search-button-container--mobile">
<button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" data-toggle="tooltip">
  <i class="fa-solid fa-magnifying-glass"></i>
</button>
  </div>

  
  <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
  </label>
  

</div>
  </nav>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar hide-on-wide">
        
  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
      
      <div class="navbar-center-item">
        <nav class="navbar-nav">
    <p class="sidebar-header-items__title" role="heading" aria-level="1" aria-label="Site Navigation">
        Site Navigation
    </p>
    <ul id="navbar-main-elements" class="navbar-nav">
        
                <li class="nav-item">
                    <a class="nav-link" href="../intro.html">
                        Introduction
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../manual.html">
                        GPflow manual
                    </a>
                </li>
                

                <li class="nav-item current active">
                    <a class="nav-link" href="#">
                        GPflow with TensorFlow 2
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../notebooks_file.html">
                        Notebooks
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../derivations.html">
                        Derivations
                    </a>
                </li>
                
            <div class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                    More
                </button>
                <div class="dropdown-menu">
                    
                <li class="nav-item">
                    <a class="nav-link" href="../api/gpflow/index.html">
                        API reference
                    </a>
                </li>
                

                <li class="nav-item">
                    <a class="nav-link" href="../bibliography.html">
                        Bibliography
                    </a>
                </li>
                
                </div>
            </div>
            
    </ul>
</nav>
      </div>
      
      </div>
    

    
    
    <div class="sidebar-header-items__end">
      
      <div class="navbar-end-item">
        <div class="version-switcher__container dropdown">
    <button type="button" class="version-switcher__button btn btn-sm navbar-btn dropdown-toggle" data-toggle="dropdown">
        develop  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div class="version-switcher__menu dropdown-menu list-group-flush py-0">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>
      </div>
      
    </div>
    
  </div>

  

  
  <div class="sidebar-end-items sidebar-primary__section">
    <div class="sidebar-end-items__item">
    </div>
  </div>

      </div>
      <main class="bd-main">
        
        
        <div class="bd-content">
          <div class="bd-article-container">
            
            <div class="bd-header-article">
                
            </div>
            
            
            <article class="bd-article" role="main">
              
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="GPflow-with-TensorFlow-2">
<h1>GPflow with TensorFlow 2<a class="headerlink" href="#GPflow-with-TensorFlow-2" title="Permalink to this heading">#</a></h1>
<section id="Small-steps-big-changes">
<h2>Small steps big changes<a class="headerlink" href="#Small-steps-big-changes" title="Permalink to this heading">#</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>

<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">pathlib</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="kn">import</span> <span class="nn">gpflow</span>
<span class="kn">from</span> <span class="nn">gpflow.ci_utils</span> <span class="kn">import</span> <span class="n">reduce_in_tests</span>
<span class="kn">from</span> <span class="nn">gpflow.config</span> <span class="kn">import</span> <span class="n">default_float</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-10-12 09:22:25.868040: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-10-12 09:22:25.998980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-10-12 09:22:25.999005: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2022-10-12 09:22:26.027516: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2022-10-12 09:22:26.687855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer.so.7&#39;; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory
2022-10-12 09:22:26.687922: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libnvinfer_plugin.so.7&#39;; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory
2022-10-12 09:22:26.687931: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
</pre></div></div>
</div>
<p>Make <code class="docutils literal notranslate"><span class="pre">tensorboard</span></code> work inside notebook:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output_logdir</span> <span class="o">=</span> <span class="s2">&quot;/tmp/tensorboard&quot;</span>

<span class="o">!</span>rm -rf <span class="s2">&quot;{output_logdir}&quot;</span>
<span class="o">!</span>mkdir <span class="s2">&quot;{output_logdir}&quot;</span>

<span class="o">%</span><span class="k">load_ext</span> tensorboard
<span class="o">%</span><span class="k">matplotlib</span> inline


<span class="k">def</span> <span class="nf">enumerated_logdir</span><span class="p">(</span><span class="n">_logdir_id</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">logdir</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">output_logdir</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">_logdir_id</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    <span class="n">_logdir_id</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="n">logdir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Set up random seeds and default float for <code class="docutils literal notranslate"><span class="pre">gpflow</span></code> tensors:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_float</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="Loading-data-using-TensorFlow-Datasets">
<h3>Loading data using TensorFlow Datasets<a class="headerlink" href="#Loading-data-using-TensorFlow-Datasets" title="Permalink to this heading">#</a></h3>
<p>For this example, we create a synthetic dataset (noisy sine function):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">noisy_sin</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span>
        <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">default_float</span><span class="p">()</span>
    <span class="p">)</span>


<span class="n">num_train_data</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">num_test_data</span> <span class="o">=</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="n">num_train_data</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">default_float</span><span class="p">())</span> <span class="o">*</span> <span class="mi">10</span>
<span class="n">Xtest</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">((</span><span class="n">num_test_data</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">default_float</span><span class="p">())</span> <span class="o">*</span> <span class="mi">10</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">noisy_sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">Ytest</span> <span class="o">=</span> <span class="n">noisy_sin</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;xk&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-10-12 09:22:29.645247: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-10-12 09:22:29.645275: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)
2022-10-12 09:22:29.645293: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (13d968f1c517): /proc/driver/nvidia/version does not exist
2022-10-12 09:22:29.645610: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_intro_to_gpflow2_7_1.png" src="../_images/notebooks_intro_to_gpflow2_7_1.png" />
</div>
</div>
<p>Working with TensorFlow Datasets is an efficient way to rapidly shuffle, iterate, and batch from data. For <code class="docutils literal notranslate"><span class="pre">prefetch</span></code> size we use <code class="docutils literal notranslate"><span class="pre">tf.data.experimental.AUTOTUNE</span></code> as recommended by TensorFlow <a class="reference external" href="https://www.tensorflow.org/guide/data_performance">guidelines</a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">))</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">Xtest</span><span class="p">,</span> <span class="n">Ytest</span><span class="p">))</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">num_features</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">prefetch_size</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">experimental</span><span class="o">.</span><span class="n">AUTOTUNE</span>
<span class="n">shuffle_buffer_size</span> <span class="o">=</span> <span class="n">num_train_data</span> <span class="o">//</span> <span class="mi">2</span>
<span class="n">num_batches_per_epoch</span> <span class="o">=</span> <span class="n">num_train_data</span> <span class="o">//</span> <span class="n">batch_size</span>

<span class="n">original_train_dataset</span> <span class="o">=</span> <span class="n">train_dataset</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">train_dataset</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span>
    <span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">prefetch_size</span><span class="p">)</span>
    <span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">shuffle_buffer_size</span><span class="p">)</span>
    <span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;prefetch_size=</span><span class="si">{</span><span class="n">prefetch_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;shuffle_buffer_size=</span><span class="si">{</span><span class="n">shuffle_buffer_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;num_batches_per_epoch=</span><span class="si">{</span><span class="n">num_batches_per_epoch</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
prefetch_size=-1
shuffle_buffer_size=50
num_batches_per_epoch=3
</pre></div></div>
</div>
</section>
<section id="Define-a-GP-model">
<h3>Define a GP model<a class="headerlink" href="#Define-a-GP-model" title="Permalink to this heading">#</a></h3>
<p>In GPflow 2.0, we use <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code> (or the very thin <code class="docutils literal notranslate"><span class="pre">gpflow.base.Module</span></code> wrapper) to build all our models, as well as their components (kernels, likelihoods, parameters, and so on).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">SquaredExponential</span><span class="p">(</span><span class="n">variance</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
<span class="n">likelihood</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">likelihoods</span><span class="o">.</span><span class="n">Gaussian</span><span class="p">()</span>
<span class="n">inducing_variable</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num_features</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">(</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">inducing_variable</span><span class="o">=</span><span class="n">inducing_variable</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>You can set a module (or a particular parameter) to be non-trainable using the auxiliary method <code class="docutils literal notranslate"><span class="pre">set_trainable(module,</span> <span class="pre">False)</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gpflow</span> <span class="kn">import</span> <span class="n">set_trainable</span>

<span class="n">set_trainable</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">set_trainable</span><span class="p">(</span><span class="n">kernel</span><span class="o">.</span><span class="n">variance</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>

<span class="n">set_trainable</span><span class="p">(</span><span class="n">likelihood</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">set_trainable</span><span class="p">(</span><span class="n">kernel</span><span class="o">.</span><span class="n">variance</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We can use <code class="docutils literal notranslate"><span class="pre">param.assign(value)</span></code> to assign a value to a parameter:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel</span><span class="o">.</span><span class="n">lengthscales</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=float64, numpy=-0.43275212956718856&gt;
</pre></div></div>
</div>
<p>All these changes are reflected when we use <code class="docutils literal notranslate"><span class="pre">print_summary(model)</span></code> to print a detailed summary of the model. By default the output is displayed in a minimalistic and simple table.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gpflow.utilities</span> <span class="kn">import</span> <span class="n">print_summary</span>

<span class="n">print_summary</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>  <span class="c1"># same as print_summary(model, fmt=&quot;fancy_table&quot;)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
╒══════════════════════════╤═══════════╤══════════════════╤═════════╤═════════════╤═════════════╤═════════╤══════════════════╕
│ name                     │ class     │ transform        │ prior   │ trainable   │ shape       │ dtype   │ value            │
╞══════════════════════════╪═══════════╪══════════════════╪═════════╪═════════════╪═════════════╪═════════╪══════════════════╡
│ SVGP.kernel.variance     │ Parameter │ Softplus         │         │ True        │ ()          │ float64 │ 2.0              │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────────┼─────────┼──────────────────┤
│ SVGP.kernel.lengthscales │ Parameter │ Softplus         │         │ True        │ ()          │ float64 │ 0.5              │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────────┼─────────┼──────────────────┤
│ SVGP.likelihood.variance │ Parameter │ Softplus + Shift │         │ True        │ ()          │ float64 │ 1.0              │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────────┼─────────┼──────────────────┤
│ SVGP.inducing_variable.Z │ Parameter │ Identity         │         │ True        │ (10, 1)     │ float64 │ [[0....          │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────────┼─────────┼──────────────────┤
│ SVGP.q_mu                │ Parameter │ Identity         │         │ True        │ (10, 1)     │ float64 │ [[0....          │
├──────────────────────────┼───────────┼──────────────────┼─────────┼─────────────┼─────────────┼─────────┼──────────────────┤
│ SVGP.q_sqrt              │ Parameter │ FillTriangular   │         │ True        │ (1, 10, 10) │ float64 │ [[[1., 0., 0.... │
╘══════════════════════════╧═══════════╧══════════════════╧═════════╧═════════════╧═════════════╧═════════╧══════════════════╛
</pre></div></div>
</div>
<p>We can change default printing so that it will look nicer in our notebook:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_summary_fmt</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>

<span class="n">print_summary</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>  <span class="c1"># same as print_summary(model, fmt=&quot;notebook&quot;)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                    </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value           </th></tr>
</thead>
<tbody>
<tr><td>SVGP.kernel.variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>2.0             </td></tr>
<tr><td>SVGP.kernel.lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.5             </td></tr>
<tr><td>SVGP.likelihood.variance</td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0             </td></tr>
<tr><td>SVGP.inducing_variable.Z</td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(10, 1)    </td><td>float64</td><td>[[0....         </td></tr>
<tr><td>SVGP.q_mu               </td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(10, 1)    </td><td>float64</td><td>[[0....         </td></tr>
<tr><td>SVGP.q_sqrt             </td><td>Parameter</td><td>FillTriangular  </td><td>       </td><td>True       </td><td>(1, 10, 10)</td><td>float64</td><td>[[[1., 0., 0....</td></tr>
</tbody>
</table></div>
</div>
<p>Jupyter notebooks also format GPflow classes (that are subclasses of <code class="docutils literal notranslate"><span class="pre">gpflow.base.Module</span></code>) in the same nice way when at the end of a cell (this is independent of the <code class="docutils literal notranslate"><span class="pre">default_summary_fmt</span></code>):</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
&lt;gpflow.models.svgp.SVGP object at 0x7fb3b4d7e710&gt;
<table>
<thead>
<tr><th>name                    </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value           </th></tr>
</thead>
<tbody>
<tr><td>SVGP.kernel.variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>2.0             </td></tr>
<tr><td>SVGP.kernel.lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.5             </td></tr>
<tr><td>SVGP.likelihood.variance</td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>1.0             </td></tr>
<tr><td>SVGP.inducing_variable.Z</td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(10, 1)    </td><td>float64</td><td>[[0....         </td></tr>
<tr><td>SVGP.q_mu               </td><td>Parameter</td><td>Identity        </td><td>       </td><td>True       </td><td>(10, 1)    </td><td>float64</td><td>[[0....         </td></tr>
<tr><td>SVGP.q_sqrt             </td><td>Parameter</td><td>FillTriangular  </td><td>       </td><td>True       </td><td>(1, 10, 10)</td><td>float64</td><td>[[[1., 0., 0....</td></tr>
</tbody>
</table></div>
</div>
</section>
<section id="Training-using-training_loss-and-training_loss_closure">
<h3>Training using training_loss and training_loss_closure<a class="headerlink" href="#Training-using-training_loss-and-training_loss_closure" title="Permalink to this heading">#</a></h3>
<p>GPflow models come with training_loss and training_loss_closure methods to make it easy to train your models. There is a slight difference between models that own their own data (most of them, e.g. GPR, VGP, …) and models that do not own the data (SVGP).</p>
<section id="Model-internal-data">
<h4>Model-internal data<a class="headerlink" href="#Model-internal-data" title="Permalink to this heading">#</a></h4>
<p>For models that own their own data (inheriting from InternalDataTrainingLossMixin), data is provided at model construction time. In this case, model.training_loss does not take any arguments, and can be directly passed to an optimizer’s <code class="docutils literal notranslate"><span class="pre">minimize()</span></code> method:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vgp_model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">VGP</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
    <span class="n">vgp_model</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span> <span class="n">vgp_model</span><span class="o">.</span><span class="n">trainable_variables</span>
<span class="p">)</span>  <span class="c1"># Note: this does a single step</span>
<span class="c1"># In practice, you will need to call minimize() many times, this will be further discussed below.</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=int64, numpy=1&gt;
</pre></div></div>
</div>
<p>This also works for the Scipy optimizer, though it will do the full optimization on a single call to minimize():</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
    <span class="n">vgp_model</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span>
    <span class="n">vgp_model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">,</span>
    <span class="n">options</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">maxiter</span><span class="o">=</span><span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">1000</span><span class="p">)),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
      fun: -67.28079600584473
 hess_inv: &lt;5153x5153 LbfgsInvHessProduct with dtype=float64&gt;
      jac: array([ 0.00639123, -0.00635877, -0.00583661, ..., -0.02814375,
        0.00295686,  0.00134197])
  message: &#39;CONVERGENCE: REL_REDUCTION_OF_F_&lt;=_FACTR*EPSMCH&#39;
     nfev: 686
      nit: 648
     njev: 686
   status: 0
  success: True
        x: array([-0.19034939,  1.64051246,  0.0252172 , ...,  1.71755914,
        0.78426537, -4.65251939])
</pre></div></div>
</div>
<p>You can obtain a compiled version using training_loss_closure, whose <code class="docutils literal notranslate"><span class="pre">compile</span></code> argument is True by default:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vgp_model</span><span class="o">.</span><span class="n">training_loss_closure</span><span class="p">()</span>  <span class="c1"># compiled</span>
<span class="n">vgp_model</span><span class="o">.</span><span class="n">training_loss_closure</span><span class="p">(</span><span class="nb">compile</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># compiled</span>
<span class="n">vgp_model</span><span class="o">.</span><span class="n">training_loss_closure</span><span class="p">(</span>
    <span class="nb">compile</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>  <span class="c1"># uncompiled, same as vgp_model.training_loss</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;bound method InternalDataTrainingLossMixin.training_loss of &lt;gpflow.models.vgp.VGP object at 0x7fb2a2d15060&gt;&gt;
</pre></div></div>
</div>
</section>
<section id="External-data">
<h4>External data<a class="headerlink" href="#External-data" title="Permalink to this heading">#</a></h4>
<p>The SVGP model inherits from ExternalDataTrainingLossMixin and expects the data to be passed to training_loss(). For SVGP as for the other regression models, <code class="docutils literal notranslate"><span class="pre">data</span></code> is a two-tuple of <code class="docutils literal notranslate"><span class="pre">(X,</span> <span class="pre">Y)</span></code>, where <code class="docutils literal notranslate"><span class="pre">X</span></code> is an array/tensor with shape <code class="docutils literal notranslate"><span class="pre">(num_data,</span> <span class="pre">input_dim)</span></code> and <code class="docutils literal notranslate"><span class="pre">Y</span></code> is an array/tensor with shape <code class="docutils literal notranslate"><span class="pre">(num_data,</span> <span class="pre">output_dim)</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">training_loss</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Tensor: shape=(), dtype=float64, numpy=8183.981124497032&gt;
</pre></div></div>
</div>
<p>To make optimizing it easy, it has a <code class="docutils literal notranslate"><span class="pre">training_loss_closure()</span></code> method, that takes the data and returns a closure that computes the training loss on this data:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">()</span>
<span class="n">training_loss</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">training_loss_closure</span><span class="p">(</span>
    <span class="n">data</span>
<span class="p">)</span>  <span class="c1"># We save the compiled closure in a variable so as not to re-compile it each step</span>
<span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
    <span class="n">training_loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span>
<span class="p">)</span>  <span class="c1"># Note that this does a single step</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=int64, numpy=1&gt;
</pre></div></div>
</div>
<p>SVGP can handle mini-batching, and an iterator from a batched tf.data.Dataset can be passed to the model’s training_loss_closure():</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">batched_dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">training_loss</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">training_loss_closure</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">batched_dataset</span><span class="p">))</span>

<span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span>
    <span class="n">training_loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span>
<span class="p">)</span>  <span class="c1"># Note that this does a single step</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Variable &#39;UnreadVariable&#39; shape=() dtype=int64, numpy=2&gt;
</pre></div></div>
</div>
<p>As previously, training_loss_closure takes an optional <code class="docutils literal notranslate"><span class="pre">compile</span></code> argument for tf.function compilation (True by default).</p>
</section>
</section>
<section id="Training-using-Gradient-Tapes">
<h3>Training using Gradient Tapes<a class="headerlink" href="#Training-using-Gradient-Tapes" title="Permalink to this heading">#</a></h3>
<p>For a more elaborate example of a gradient update we can define an <code class="docutils literal notranslate"><span class="pre">optimization_step</span></code> that explicitly computes and applies gradients to the model. In TensorFlow 2, we can optimize (trainable) model parameters with TensorFlow optimizers using <code class="docutils literal notranslate"><span class="pre">tf.GradientTape</span></code>. In this simple example, we perform one gradient update of the Adam optimizer to minimize the training_loss (in this case the negative ELBO) of our model. The <code class="docutils literal notranslate"><span class="pre">optimization_step</span></code> can (and should) be wrapped in <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> to be
compiled to a graph if executing it many times.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">optimization_step</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">,</span> <span class="n">batch</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
<span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">(</span><span class="n">watch_accessed_variables</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">tape</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">training_loss</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
</div>
<p>We can use the functionality of TensorFlow Datasets to define a simple training loop that iterates over batches of the training dataset:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simple_training_loop</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">logging_epoch_freq</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span>
<span class="p">):</span>
    <span class="n">tf_optimization_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">optimization_step</span><span class="p">)</span>

    <span class="n">batches</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reduce_in_tests</span><span class="p">(</span><span class="n">epochs</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reduce_in_tests</span><span class="p">(</span><span class="n">num_batches_per_epoch</span><span class="p">)):</span>
            <span class="n">tf_optimization_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches</span><span class="p">))</span>

        <span class="n">epoch_id</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">epoch_id</span> <span class="o">%</span> <span class="n">logging_epoch_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch_id</span><span class="si">}</span><span class="s2">: ELBO (train) </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simple_training_loop</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">logging_epoch_freq</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 2: ELBO (train) -7913.1929941921935
Epoch 4: ELBO (train) -7709.468598155783
Epoch 6: ELBO (train) -7503.5176386383
Epoch 8: ELBO (train) -7299.591081344768
Epoch 10: ELBO (train) -7099.074410864153
</pre></div></div>
</div>
</section>
<section id="Monitoring">
<h3>Monitoring<a class="headerlink" href="#Monitoring" title="Permalink to this heading">#</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">gpflow.monitor</span></code> provides a thin wrapper on top of tf.summary that makes it easy to monitor the training procedure. For a more detailed tutorial see the <a class="reference external" href="./basics/monitoring.pct.py">monitoring notebook</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">gpflow.monitor</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ExecuteCallback</span><span class="p">,</span>
    <span class="n">ImageToTensorBoard</span><span class="p">,</span>
    <span class="n">ModelToTensorBoard</span><span class="p">,</span>
    <span class="n">Monitor</span><span class="p">,</span>
    <span class="n">MonitorTaskGroup</span><span class="p">,</span>
    <span class="n">ScalarToTensorBoard</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">samples_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">reduce_in_tests</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_model</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="s2">&quot;Plotting...&quot;</span><span class="p">)</span>
    <span class="n">mean</span><span class="p">,</span> <span class="n">var</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_f</span><span class="p">(</span><span class="n">samples_input</span><span class="p">)</span>
    <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_f_samples</span><span class="p">(</span><span class="n">samples_input</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples_input</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
        <span class="n">samples_input</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
        <span class="n">mean</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span>
        <span class="n">mean</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.96</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">var</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]),</span>
        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;C0&quot;</span><span class="p">,</span>
        <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="s2">&quot;kx&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">samples_input</span><span class="p">,</span> <span class="n">samples</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s2">&quot;C0&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">2.0</span><span class="p">,</span> <span class="o">+</span><span class="mf">2.0</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">print_cb</span><span class="p">(</span><span class="n">epoch_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch_id</span><span class="si">}</span><span class="s2">: ELBO (train)&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">elbo_cb</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">_</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>


<span class="n">output_logdir</span> <span class="o">=</span> <span class="n">enumerated_logdir</span><span class="p">()</span>

<span class="n">model_task</span> <span class="o">=</span> <span class="n">ModelToTensorBoard</span><span class="p">(</span><span class="n">output_logdir</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="n">elbo_task</span> <span class="o">=</span> <span class="n">ScalarToTensorBoard</span><span class="p">(</span><span class="n">output_logdir</span><span class="p">,</span> <span class="n">elbo_cb</span><span class="p">,</span> <span class="s2">&quot;elbo&quot;</span><span class="p">)</span>
<span class="n">print_task</span> <span class="o">=</span> <span class="n">ExecuteCallback</span><span class="p">(</span><span class="n">callback</span><span class="o">=</span><span class="n">print_cb</span><span class="p">)</span>

<span class="c1"># We group these tasks and specify a period of `100` steps for them</span>
<span class="n">fast_tasks</span> <span class="o">=</span> <span class="n">MonitorTaskGroup</span><span class="p">([</span><span class="n">model_task</span><span class="p">,</span> <span class="n">elbo_task</span><span class="p">,</span> <span class="n">print_task</span><span class="p">],</span> <span class="n">period</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># We also want to see the model&#39;s fit during the optimisation</span>
<span class="n">image_task</span> <span class="o">=</span> <span class="n">ImageToTensorBoard</span><span class="p">(</span><span class="n">output_logdir</span><span class="p">,</span> <span class="n">plot_model</span><span class="p">,</span> <span class="s2">&quot;samples_image&quot;</span><span class="p">)</span>

<span class="c1"># We typically don&#39;t want to plot too frequently during optimisation,</span>
<span class="c1"># which is why we specify a larger period for this task.</span>
<span class="n">slow_taks</span> <span class="o">=</span> <span class="n">MonitorTaskGroup</span><span class="p">(</span><span class="n">image_task</span><span class="p">,</span> <span class="n">period</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">monitor</span> <span class="o">=</span> <span class="n">Monitor</span><span class="p">(</span><span class="n">fast_tasks</span><span class="p">,</span> <span class="n">slow_taks</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">monitored_training_loop</span><span class="p">(</span><span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="n">tf_optimization_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">optimization_step</span><span class="p">)</span>

    <span class="n">batches</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reduce_in_tests</span><span class="p">(</span><span class="n">num_batches_per_epoch</span><span class="p">)):</span>
            <span class="n">batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches</span><span class="p">)</span>
            <span class="n">tf_optimization_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>

        <span class="n">epoch_id</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">monitor</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">epoch_id</span><span class="o">=</span><span class="n">epoch_id</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>NOTE: for optimal performance it is recommended to wrap the monitoring inside <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>. This is detailed in the <a class="reference internal" href="basics/monitoring.html"><span class="doc">monitoring notebook</span></a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">(</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">inducing_variable</span><span class="o">=</span><span class="n">inducing_variable</span>
<span class="p">)</span>

<span class="n">monitored_training_loop</span><span class="p">(</span><span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1: ELBO (train) -7776.86024303905
Plotting...
Epoch 101: ELBO (train) -2018.964474034811
Epoch 201: ELBO (train) -839.55018631600012
Epoch 301: ELBO (train) -369.83054936654463
Epoch 401: ELBO (train) -155.97372720424897
Epoch 501: ELBO (train) -53.974071371746284
Plotting...
Epoch 601: ELBO (train) -7.36371388163936
Epoch 701: ELBO (train) 14.765824306449829
Epoch 801: ELBO (train) 26.914388333901755
Epoch 901: ELBO (train) 34.579448404854759
</pre></div></div>
</div>
<p>Then, we can use TensorBoard to examine the training procedure in more detail</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %tensorboard --logdir &quot;{output_logdir}&quot;</span>
</pre></div>
</div>
</div>
</section>
<section id="Saving-and-loading-models">
<h3>Saving and loading models<a class="headerlink" href="#Saving-and-loading-models" title="Permalink to this heading">#</a></h3>
<section id="Checkpointing">
<h4>Checkpointing<a class="headerlink" href="#Checkpointing" title="Permalink to this heading">#</a></h4>
<p>With the help of <code class="docutils literal notranslate"><span class="pre">tf.train.CheckpointManager</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.train.Checkpoint</span></code>, we can checkpoint the model throughout the training procedure. Let’s start with a simple example using checkpointing to save and load a <code class="docutils literal notranslate"><span class="pre">tf.Variable</span></code>:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">initial_value</span> <span class="o">=</span> <span class="mf">1.2</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">initial_value</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Create <code class="docutils literal notranslate"><span class="pre">Checkpoint</span></code> object:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">a</span><span class="p">)</span>
<span class="n">manager</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointManager</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="n">output_logdir</span><span class="p">,</span> <span class="n">max_to_keep</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Save the variable <code class="docutils literal notranslate"><span class="pre">a</span></code> and change its value right after:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">manager</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mf">0.33</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now we can restore the old variable value:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Current value of variable a: </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="si">:</span><span class="s2">0.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">ckpt</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Value of variable a after restore: </span><span class="si">{</span><span class="n">a</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="si">:</span><span class="s2">0.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Current value of variable a: 0.330
Value of variable a after restore: 1.200
</pre></div></div>
</div>
<p>In the example below, we modify a simple training loop to save the model every 100 epochs using the <code class="docutils literal notranslate"><span class="pre">CheckpointManager</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">(</span>
    <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">likelihood</span><span class="o">=</span><span class="n">likelihood</span><span class="p">,</span> <span class="n">inducing_variable</span><span class="o">=</span><span class="n">inducing_variable</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">checkpointing_training_loop</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SVGP</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">manager</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointManager</span><span class="p">,</span>
    <span class="n">logging_epoch_freq</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">epoch_var</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">step_var</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="n">tf_optimization_step</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">optimization_step</span><span class="p">)</span>

    <span class="n">batches</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">reduce_in_tests</span><span class="p">(</span><span class="n">num_batches_per_epoch</span><span class="p">)):</span>
            <span class="n">tf_optimization_step</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="n">batches</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">step_var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">step_var</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">epoch</span> <span class="o">*</span> <span class="n">num_batches_per_epoch</span> <span class="o">+</span> <span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">epoch_var</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">epoch_var</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">epoch_id</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">epoch_id</span> <span class="o">%</span> <span class="n">logging_epoch_freq</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">ckpt_path</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">print</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch_id</span><span class="si">}</span><span class="s2">: ELBO (train) </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">, saved at </span><span class="si">{</span><span class="n">ckpt_path</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">step_var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">epoch_var</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step_var</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch_var</span><span class="p">)</span>
<span class="n">manager</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointManager</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="n">output_logdir</span><span class="p">,</span> <span class="n">max_to_keep</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Checkpoint folder path at: </span><span class="si">{</span><span class="n">output_logdir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">checkpointing_training_loop</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">manager</span><span class="o">=</span><span class="n">manager</span><span class="p">,</span>
    <span class="n">epoch_var</span><span class="o">=</span><span class="n">epoch_var</span><span class="p">,</span>
    <span class="n">step_var</span><span class="o">=</span><span class="n">step_var</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Checkpoint folder path at: /tmp/tensorboard/0
Epoch 100: ELBO (train) -149.15494727967928, saved at /tmp/tensorboard/0/ckpt-1
Epoch 200: ELBO (train) -8.421502159170839, saved at /tmp/tensorboard/0/ckpt-2
Epoch 300: ELBO (train) 24.782835896532845, saved at /tmp/tensorboard/0/ckpt-3
Epoch 400: ELBO (train) 36.742774484611004, saved at /tmp/tensorboard/0/ckpt-4
Epoch 500: ELBO (train) 42.11155832402494, saved at /tmp/tensorboard/0/ckpt-5
Epoch 600: ELBO (train) 45.03015224854348, saved at /tmp/tensorboard/0/ckpt-6
Epoch 700: ELBO (train) 46.8830577823748, saved at /tmp/tensorboard/0/ckpt-7
Epoch 800: ELBO (train) 48.214091697705406, saved at /tmp/tensorboard/0/ckpt-8
Epoch 900: ELBO (train) 49.26585648203592, saved at /tmp/tensorboard/0/ckpt-9
Epoch 1000: ELBO (train) 50.16361862034715, saved at /tmp/tensorboard/0/ckpt-10
</pre></div></div>
</div>
<p>After the models have been saved, we can restore them using <code class="docutils literal notranslate"><span class="pre">tf.train.Checkpoint.restore</span></code> and assert that their performance corresponds to that logged during training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">recorded_checkpoint</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">manager</span><span class="o">.</span><span class="n">checkpoints</span><span class="p">):</span>
    <span class="n">ckpt</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">recorded_checkpoint</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2"> restored model from epoch </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">epoch_var</span><span class="p">)</span><span class="si">}</span><span class="s2"> [step:</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">step_var</span><span class="p">)</span><span class="si">}</span><span class="s2">] : ELBO training set </span><span class="si">{</span><span class="n">model</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0 restored model from epoch 600 [step:1800] : ELBO training set 45.03015224854348
1 restored model from epoch 700 [step:2100] : ELBO training set 46.8830577823748
2 restored model from epoch 800 [step:2400] : ELBO training set 48.214091697705406
3 restored model from epoch 900 [step:2700] : ELBO training set 49.26585648203592
4 restored model from epoch 1000 [step:3000] : ELBO training set 50.16361862034715
</pre></div></div>
</div>
</section>
<section id="Copying-(hyper)parameter-values-between-models">
<h4>Copying (hyper)parameter values between models<a class="headerlink" href="#Copying-(hyper)parameter-values-between-models" title="Permalink to this heading">#</a></h4>
<p>It is easy to interact with the set of all parameters of a model or a subcomponent programmatically.</p>
<p>The following returns a dictionary of all parameters within</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">SGPR</span><span class="p">(</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">inducing_variable</span><span class="o">=</span><span class="n">inducing_variable</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">parameter_dict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;.kernel.variance&#39;: &lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=0.8890651823586637&gt;,
 &#39;.kernel.lengthscales&#39;: &lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=1.6808082106211253&gt;,
 &#39;.likelihood.variance&#39;: &lt;Parameter: name=chain_of_shift_of_softplus, dtype=float64, shape=[], fn=&#34;chain_of_shift_of_softplus&#34;, numpy=1.0&gt;,
 &#39;.inducing_variable.Z&#39;: &lt;Parameter: name=identity, dtype=float64, shape=[10, 1], fn=&#34;identity&#34;, numpy=
 array([[ 0.        ],
        [ 1.11111111],
        [ 2.22222222],
        [ 3.33333333],
        [ 4.44444444],
        [ 5.55555556],
        [ 6.66666667],
        [ 7.77777778],
        [ 8.88888889],
        [10.        ]])&gt;}
</pre></div></div>
</div>
<p>Such a dictionary can be assigned back to this model (or another model with the same tree of parameters) as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[33]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">parameter_dict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">multiple_assign</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="TensorFlow-saved_model">
<h4>TensorFlow <code class="docutils literal notranslate"><span class="pre">saved_model</span></code><a class="headerlink" href="#TensorFlow-saved_model" title="Permalink to this heading">#</a></h4>
<p>In order to save the model we need to explicitly store the <code class="docutils literal notranslate"><span class="pre">tf.function</span></code>-compiled functions that we wish to export:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predict_f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">Xnew</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_f</span><span class="p">(</span><span class="n">Xnew</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">predict_f_compiled</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span>
    <span class="n">predict_f</span><span class="p">,</span>
    <span class="n">input_signature</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">TensorSpec</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float64</span><span class="p">)],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>We also save the original prediction for later comparison. Here <code class="docutils literal notranslate"><span class="pre">samples_input</span></code> needs to be a tensor so that <code class="docutils literal notranslate"><span class="pre">tf.function</span></code> will compile a single graph:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[35]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">samples_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">convert_to_tensor</span><span class="p">(</span><span class="n">samples_input</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">default_float</span><span class="p">())</span>
<span class="n">original_result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_f_compiled</span><span class="p">(</span><span class="n">samples_input</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Let’s save the model:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[36]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">save_dir</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="n">tempfile</span><span class="o">.</span><span class="n">gettempdir</span><span class="p">()))</span>
<span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">save_dir</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
WARNING:absl:Function `&lt;lambda&gt;` contains input name(s) Xnew with unsupported characters which will be renamed to xnew in the SavedModel.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /tmp/max_venv/lib/python3.10/site-packages/tensorflow/python/trackable/autotrackable.py:95: Bijector.has_static_min_event_ndims (from tensorflow_probability.python.bijectors.bijector) is deprecated and will be removed after 2021-08-01.
Instructions for updating:
`min_event_ndims` is now static for all bijectors; this property is no longer needed.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
WARNING:tensorflow:From /tmp/max_venv/lib/python3.10/site-packages/tensorflow/python/trackable/autotrackable.py:95: Bijector.has_static_min_event_ndims (from tensorflow_probability.python.bijectors.bijector) is deprecated and will be removed after 2021-08-01.
Instructions for updating:
`min_event_ndims` is now static for all bijectors; this property is no longer needed.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
INFO:tensorflow:Assets written to: /tmp/assets
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
INFO:tensorflow:Assets written to: /tmp/assets
</pre></div></div>
</div>
<p>We can load the module back as a new instance and compare the prediction results:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loaded_model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">save_dir</span><span class="p">)</span>
<span class="n">loaded_result</span> <span class="o">=</span> <span class="n">loaded_model</span><span class="o">.</span><span class="n">predict_f_compiled</span><span class="p">(</span><span class="n">samples_input</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_equal</span><span class="p">(</span><span class="n">loaded_result</span><span class="p">,</span> <span class="n">original_result</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="User-config-update">
<h3>User config update<a class="headerlink" href="#User-config-update" title="Permalink to this heading">#</a></h3>
<p>In this notebook, we used a lot <code class="docutils literal notranslate"><span class="pre">gpflow.config</span></code> methods for setting and getting default attributes from global configuration. However, GPflow provides a way for local config modification without updating values in global. As you can see below, using <code class="docutils literal notranslate"><span class="pre">gpflow.config.as_context</span></code> replaces temporarily global config with your instance. At creation time, custom config instance uses standard values from the global config:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">user_config</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">Config</span><span class="p">(</span><span class="nb">float</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">positive_bijector</span><span class="o">=</span><span class="s2">&quot;exp&quot;</span><span class="p">)</span>

<span class="n">user_str</span> <span class="o">=</span> <span class="s2">&quot;User config</span><span class="se">\t</span><span class="s2">&quot;</span>
<span class="n">global_str</span> <span class="o">=</span> <span class="s2">&quot;Global config</span><span class="se">\t</span><span class="s2">&quot;</span>

<span class="k">with</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">as_context</span><span class="p">(</span><span class="n">user_config</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user_str</span><span class="si">}</span><span class="s2"> gpflow.config.default_float = </span><span class="si">{</span><span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">default_float</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user_str</span><span class="si">}</span><span class="s2"> gpflow.config.positive_bijector = </span><span class="si">{</span><span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">default_positive_bijector</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">global_str</span><span class="si">}</span><span class="s2"> gpflow.config.default_float = </span><span class="si">{</span><span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">default_float</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">global_str</span><span class="si">}</span><span class="s2"> gpflow.config.positive_bijector = </span><span class="si">{</span><span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">default_positive_bijector</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
User config      gpflow.config.default_float = &lt;dtype: &#39;float32&#39;&gt;
User config      gpflow.config.positive_bijector = exp
Global config    gpflow.config.default_float = &lt;class &#39;numpy.float64&#39;&gt;
Global config    gpflow.config.positive_bijector = softplus
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[39]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">as_context</span><span class="p">(</span><span class="n">user_config</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">positive</span><span class="p">())</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">user_str</span><span class="si">}{</span><span class="n">p</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="mf">1.1</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">utilities</span><span class="o">.</span><span class="n">positive</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">global_str</span><span class="si">}{</span><span class="n">p</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
User config     &lt;Parameter: name=exp, dtype=float32, shape=[], fn=&#34;exp&#34;, numpy=1.1&gt;
Global config   &lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=1.1&gt;
</pre></div></div>
</div>
</section>
</section>
</section>


            </article>
            
            
            
          </div>
          
          
          
            <div class="bd-sidebar-secondary bd-toc">
              
<div class="toc-item">
  
<div class="tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
</div>
<nav id="bd-toc-nav" class="page-toc">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Small-steps-big-changes">
   Small steps big changes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Loading-data-using-TensorFlow-Datasets">
     Loading data using TensorFlow Datasets
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Define-a-GP-model">
     Define a GP model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Training-using-training_loss-and-training_loss_closure">
     Training using training_loss and training_loss_closure
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#Model-internal-data">
       Model-internal data
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#External-data">
       External data
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Training-using-Gradient-Tapes">
     Training using Gradient Tapes
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Monitoring">
     Monitoring
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#Saving-and-loading-models">
     Saving and loading models
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#Checkpointing">
       Checkpointing
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#Copying-(hyper)parameter-values-between-models">
       Copying (hyper)parameter values between models
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#TensorFlow-saved_model">
       TensorFlow
       <code class="docutils literal notranslate">
        <span class="pre">
         saved_model
        </span>
       </code>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#User-config-update">
     User config update
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
</div>

<div class="toc-item">
  
<div id="searchbox"></div>
</div>

<div class="toc-item">
  
</div>

<div class="toc-item">
  
</div>

            </div>
          
          
        </div>
        <footer class="bd-footer-content">
          <div class="bd-footer-content__inner">
            
          </div>
        </footer>
        
      </main>
    </div>
  </div>

  
    
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1e1de1a1873e13ef5536"></script>

  <footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    
<p class="copyright">

    &copy; Copyright 2022, The GPflow Contributors.<br>

</p>

  </div>
  
  <div class="footer-item">
    
<p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.2.3.<br>
</p>

  </div>
  
</div>
  </footer>
  </body>
</html>