
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Derivation of VGP equations &#8212; GPflow 2.5.1 documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/pydata-custom.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Architecture" href="../understanding/architecture.html" />
    <link rel="prev" title="Discussion of the GP marginal likelihood upper bound" href="upper_bound.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../index.html">
  <img src="../../_static/gpflow_logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../intro.html">
  Introduction
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro.html">
  GPflow manual
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro_to_gpflow2.html">
  GPflow with TensorFlow 2
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../gpflow2_upgrade_guide.html">
  GPflow 2 Upgrade Guide
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../notebooks_file.html">
  Notebooks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../derivations.html">
  Derivations
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/gpflow/index.html">
  API reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../bibliography.html">
  Bibliography
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-primary btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        develop  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables notebooks/theory/vgp_notes and {'json_url': 'https://gpflow.github.io/GPflow/versions.json', 'version_match': 'develop'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "notebooks/theory/vgp_notes.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://gpflow.github.io/GPflow/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "notebooks/theory/vgp_notes.html";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's  variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "develop") {
                node.classList.add("active");
                let btn = document.getElementById("version_switcher_button");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../basics/GPLVM.html">
   Bayesian Gaussian process latent variable model (Bayesian GPLVM)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basics/classification.html">
   Basic (binary) GP classification model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basics/monitoring.html">
   Monitoring Optimisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basics/regression.html">
   Basic (Gaussian likelihood) GP regression model
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/advanced_many_points.html">
   More details on models with many observation points
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/changepoints.html">
   Change points
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/convolutional.html">
   Convolutional Gaussian Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/coregionalisation.html">
   A simple demonstration of coregionalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/fast_predictions.html">
   Faster predictions by caching
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/gps_for_big_data.html">
   Stochastic Variational Inference for scalability with SVGP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/heteroskedastic.html">
   Heteroskedastic Likelihood and Multi-Latent GP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/kernels.html">
   Manipulating kernels
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/mcmc.html">
   MCMC (Markov Chain Monte Carlo)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/multiclass_classification.html">
   Multiclass classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/multioutput.html">
   Multi-output Gaussian processes in GPflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/natural_gradients.html">
   Natural gradients
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/optimisation.html">
   Optimizers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/ordinal_regression.html">
   Ordinal regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/variational_fourier_features.html">
   Variational Fourier Features in the GPflow framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/varying_noise.html">
   Gaussian process regression with varying output noise
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/external-mean-function.html">
   Custom mean functions: metalearning with GPs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/gp_nn.html">
   Mixing TensorFlow models with GPflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/kernel_design.html">
   Kernel Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/likelihood_design.html">
   Likelihood Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/mixture_density_network.html">
   Mixture Density Networks in GPflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/models_with_latent_variables.html">
   Models with observed and latent variables
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/updating_models_with_new_data.html">
   Updating model with new data
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="FITCvsVFE.html">
   Comparing FITC approximation to VFE approximation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="SGPR_notes.html">
   Derivation of SGPR equations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Sanity_check.html">
   Sanity checking when model behaviours should overlap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cglb.html">
   Conjugate Gradient Lower Bound
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="upper_bound.html">
   Discussion of the GP marginal likelihood upper bound
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Derivation of VGP equations
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../understanding/architecture.html">
   Architecture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../understanding/models.html">
   Manipulating GPflow models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../understanding/utilities.html">
   Utilities
  </a>
 </li>
</ul>

  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Optimal-distribution">
   Optimal distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Marginals-of-q(\mathbf-f)">
   Marginals of
   <span class="math notranslate nohighlight">
    \(q(\mathbf f)\)
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#KL-divergence">
   KL divergence
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Prediction">
   Prediction
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="Derivation-of-VGP-equations">
<h1>Derivation of VGP equations<a class="headerlink" href="#Derivation-of-VGP-equations" title="Permalink to this headline">#</a></h1>
<p><em>James Hensman, 2016</em></p>
<p>This notebook contains some implementation notes on the variational Gaussian approximation model in GPflow, <code class="docutils literal notranslate"><span class="pre">gpflow.models.VGP</span></code>. The reference for this work is <a class="reference external" href="http://www.mitpressjournals.org/doi/abs/10.1162/neco.2008.08-07-592">Opper and Archambeau 2009, The variational Gaussian approximation revisited</a>; these notes serve to map the conclusions of that paper to their implementation in GPflow. We’ll give derivations for the expressions that are implemented in the <code class="docutils literal notranslate"><span class="pre">VGP</span></code> class.</p>
<p>Two things are not covered by this notebook: prior mean functions, and the extension to multiple independent outputs. Extensions are straightforward in theory but we have taken care in the code to ensure they are handled efficiently.</p>
<section id="Optimal-distribution">
<h2>Optimal distribution<a class="headerlink" href="#Optimal-distribution" title="Permalink to this headline">#</a></h2>
<p>The key insight in the work of Opper and Archambeau is that for a Gaussian process with a non-Gaussian likelihood, the optimal Gaussian approximation (in the KL sense) is given by:</p>
<p><span class="math">\begin{equation}
\hat q(\mathbf f) = \mathcal N\left(\mathbf m, [\mathbf K^{-1} + \textrm{diag}(\boldsymbol \lambda)]^{-1}\right)\,
\end{equation}</span></p>
<p>We follow their advice in reparameterizing the mean as:</p>
<p><span class="math">\begin{equation}
\mathbf m = \mathbf K \boldsymbol \alpha
\end{equation}</span></p>
<p>Additionally, to avoid having to constrain the parameter <span class="math notranslate nohighlight">\(\lambda\)</span> to be positive, we take the square. The approximation then becomes:</p>
<p><span class="math">\begin{equation}
\hat q(\mathbf f) = \mathcal N\left(\mathbf K \boldsymbol \alpha, [\mathbf K^{-1} + \textrm{diag}(\boldsymbol \lambda)^2]^{-1}\right)\,
\end{equation}</span></p>
<p>The ELBO is:</p>
<p><span class="math">\begin{equation}
\textrm{ELBO} = \sum_n\mathbb E_{q(f_n)}\left[ \log p(y_n\,|\,f_n)\right] - \textrm{KL}\left[q(\mathbf f)||p(\mathbf f)\right]
\end{equation}</span></p>
<p>We split the rest of this document into firstly considering the marginals of <span class="math notranslate nohighlight">\(q(f)\)</span>, and then the KL term. Given these, it is straightforward to compute the ELBO; GPflow uses quadrature to compute one-dimensional expectations where no closed form is available.</p>
</section>
<section id="Marginals-of-q(\mathbf-f)">
<h2>Marginals of <span class="math notranslate nohighlight">\(q(\mathbf f)\)</span><a class="headerlink" href="#Marginals-of-q(\mathbf-f)" title="Permalink to this headline">#</a></h2>
<p>Given the above form for <span class="math notranslate nohighlight">\(q(\mathbf f)\)</span>, what is a quick and stable way to compute the marginals of this Gaussian? The means are trivial, but it would be better if we could obtain the variance without having to perform two matrix inversions.</p>
<p>Let <span class="math notranslate nohighlight">\(\boldsymbol \Lambda = \textrm{diag}(\boldsymbol \lambda)\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol \Sigma\)</span> be the covariance in question: <span class="math notranslate nohighlight">\(\boldsymbol \Sigma = [\mathbf K^{-1} + \boldsymbol \Lambda^2]^{-1}\)</span>. By the matrix inversion lemma we have:</p>
<p><span class="math">\begin{align}
\boldsymbol \Sigma &= [\mathbf K^{-1} + \boldsymbol \Lambda^2]^{-1} \\
&= \boldsymbol \Lambda^{-2} - \boldsymbol \Lambda^{-2}[\mathbf K + \boldsymbol \Lambda^{-2}]^{-1}\boldsymbol \Lambda^{-2} \\
&= \boldsymbol \Lambda^{-2} - \boldsymbol \Lambda^{-1}\mathbf A^{-1}\boldsymbol \Lambda^{-1}
\end{align}</span></p>
<p>where <span class="math notranslate nohighlight">\(\mathbf A = \boldsymbol \Lambda\mathbf K \boldsymbol \Lambda + \mathbf I\,.\)</span></p>
<p>Working with this form means that only one matrix decomposition is needed, and taking the Cholesky factor of <span class="math notranslate nohighlight">\(\mathbf A\)</span> should be numerically stable because the eigenvalues are bounded by 1.</p>
</section>
<section id="KL-divergence">
<h2>KL divergence<a class="headerlink" href="#KL-divergence" title="Permalink to this headline">#</a></h2>
<p>The KL divergence term would benefit from a similar reorganisation. The KL is:</p>
<p><span class="math">\begin{equation}
\textrm{KL} = -0.5 \log |\boldsymbol \Sigma| + 0.5 \log |\mathbf K| +0.5\mathbf m^\top\mathbf K^{-1}\mathbf m + 0.5\textrm{tr}(\mathbf K^{-1} \boldsymbol \Sigma) - 0.5 N
\end{equation}</span></p>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol N\)</span> is the number of data points. Recalling our parameterization <span class="math notranslate nohighlight">\(\boldsymbol \alpha\)</span> and combining like terms:</p>
<p><span class="math">\begin{equation}
\textrm{KL} = 0.5 (-\log |\mathbf K^{-1}\boldsymbol \Sigma | +\boldsymbol \alpha^\top\mathbf K\boldsymbol \alpha + \textrm{tr}(\mathbf K^{-1} \boldsymbol \Sigma) - N)\,
\end{equation}</span></p>
<p>with a little manipulation it’s possible to show that <span class="math notranslate nohighlight">\(\textrm{tr}(\mathbf K^{-1} \boldsymbol \Sigma) = \textrm{tr}(\mathbf A^{-1})\)</span> and <span class="math notranslate nohighlight">\(|\mathbf K^{-1} \boldsymbol \Sigma| = |\mathbf A^{-1}|\)</span>, giving the final expression:</p>
<p><span class="math">\begin{equation}
\textrm{KL} = 0.5 (\log |\mathbf A| +\boldsymbol \alpha^\top\mathbf K\boldsymbol \alpha + \textrm{tr}(\mathbf A^{-1}) - N)\,
\end{equation}</span></p>
<p>This expression is not ideal because we have to compute the diagonal elements of <span class="math notranslate nohighlight">\(\mathbf A^{-1}\)</span>. We do this with an extra back substitution (into the identity matrix), although it might be possible to do this faster in theory (though not in TensorFlow, to the best of our knowledge).</p>
</section>
<section id="Prediction">
<h2>Prediction<a class="headerlink" href="#Prediction" title="Permalink to this headline">#</a></h2>
<p>To make predictions with the Gaussian approximation, we need to integrate:</p>
<p><span class="math">\begin{equation}
q(f^\star \,|\,\mathbf y) = \int p(f^\star \,|\, \mathbf f)q(\mathbf f)\,\textrm d \mathbf f
\end{equation}</span></p>
<p>The integral is a Gaussian. We can substitute the equations for these quantities:</p>
<p><span class="math">\begin{align}
q(f^\star \,|\,\mathbf y) &= \int \mathcal N(f^\star \,|\, \mathbf K_{\star \mathbf f}\mathbf K^{-1}\mathbf f,\, \mathbf K_{\star \star} - \mathbf K_{\star \mathbf f}\mathbf K^{-1}\mathbf K_{\mathbf f \star})\mathcal N (\mathbf f\,|\, \mathbf K \boldsymbol\alpha, \boldsymbol \Sigma)\,\textrm d \mathbf f
q(f^\star \,|\,\mathbf y) \\
&= \mathcal N\left(f^\star \,|\, \mathbf K_{\star \mathbf f}\boldsymbol \alpha,\, \mathbf K_{\star \star} - \mathbf K_{\star \mathbf f}(\mathbf K^{-1} - \mathbf K^{-1}\boldsymbol \Sigma\mathbf K^{-1})\mathbf K_{\mathbf f \star}\right)
\end{align}</span></p>
<p>where the notation <span class="math notranslate nohighlight">\(\mathbf K_{\star \mathbf f}\)</span> means the covariance between the prediction points and the data points, and the matrix <span class="math notranslate nohighlight">\(\mathbf K\)</span> is shorthand for <span class="math notranslate nohighlight">\(\mathbf K_{\mathbf{ff}}\)</span>.</p>
<p>The matrix <span class="math notranslate nohighlight">\(\mathbf K^{-1} - \mathbf K^{-1}\boldsymbol \Sigma\mathbf K^{-1}\)</span> can be expanded:</p>
<p><span class="math">\begin{equation}
\mathbf K^{-1} - \mathbf K^{-1}\boldsymbol \Sigma\mathbf K^{-1} = \mathbf K^{-1} - \mathbf K^{-1}[\mathbf K^{-1} + \boldsymbol\Lambda^2]^{-1}\mathbf K^{-1}\,
\end{equation}</span></p>
<p>and simplified by recognising the form of the matrix inverse lemma:</p>
<p><span class="math">\begin{equation}
\mathbf K^{-1} - \mathbf K^{-1}\boldsymbol \Sigma\mathbf K^{-1} = [\mathbf K +  \boldsymbol\Lambda^2]^{-1}\,
\end{equation}</span></p>
<p>This leads to the final expression for the prediction:</p>
<p><span class="math">\begin{equation}
q(f^\star \,|\,\mathbf y) = \mathcal N\left(f^\star \,|\, \mathbf K_{\star \mathbf f}\boldsymbol \alpha,\, \mathbf K_{\star \star} - \mathbf K_{\star \mathbf f}[\mathbf K + \boldsymbol \Lambda^2]^{-1}\mathbf K_{\mathbf f \star}\right)
\end{equation}</span></p>
<p><strong>NOTE:</strong> The <code class="docutils literal notranslate"><span class="pre">VGP</span></code> class in GPflow has extra functionality to compute the marginal variance of the prediction when the full covariance matrix is not required.</p>
</section>
</section>


              </div>
              
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, The GPflow Contributors.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>