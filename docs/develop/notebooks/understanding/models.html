
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Manipulating GPflow models &#8212; GPflow 2.5.2 documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/pydata-custom.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Derivations" href="../../derivations.html" />
    <link rel="prev" title="Derivation of VGP equations" href="../theory/vgp_notes.html" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="en">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
    <img src="../../_static/gpflow_logo.svg" class="logo__image only-light" alt="Logo image">
    <img src="../../_static/gpflow_logo.svg" class="logo__image only-dark" alt="Logo image">
  
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../intro.html">
  Introduction
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../manual.html">
  GPflow manual
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../intro_to_gpflow2.html">
  GPflow with TensorFlow 2
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../notebooks_file.html">
  Notebooks
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../derivations.html">
  Derivations
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../api/gpflow/index.html">
  API reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../bibliography.html">
  Bibliography
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <div class="dropdown" id="version_switcher">
    <button type="button" class="btn btn-sm navbar-btn dropdown-toggle" id="version_switcher_button" data-toggle="dropdown">
        develop  <!-- this text may get changed later by javascript -->
        <span class="caret"></span>
    </button>
    <div id="version_switcher_menu" class="dropdown-menu list-group-flush py-0" aria-labelledby="version_switcher_button">
    <!-- dropdown will be populated by javascript on page load -->
    </div>
</div>

<!-- NOTE: this JS must live here (not in our global JS file) because it relies
     on being processed by Jinja before it is run (specifically for replacing
     variables notebooks/understanding/models and {'json_url': 'https://gpflow.github.io/GPflow/versions.json', 'version_match': 'develop'}.
-->

<script type="text/javascript">
// Check if corresponding page path exists in other version of docs
// and, if so, go there instead of the homepage of the other docs version
function checkPageExistsAndRedirect(event) {
    const currentFilePath = "notebooks/understanding/models.html",
          tryUrl = event.target.getAttribute("href");
    let otherDocsHomepage = tryUrl.replace(currentFilePath, "");
    $.ajax({
        type: 'HEAD',
        url: tryUrl,
        // if the page exists, go there
        success: function() {
            location.href = tryUrl;
        }
    }).fail(function() {
        location.href = otherDocsHomepage;
    });
    // this prevents the browser from following the href of the clicked node
    // (which is fine because this function takes care of redirecting)
    return false;
}

// Populate the version switcher from the JSON config file
(function () {
    $.getJSON("https://gpflow.github.io/GPflow/versions.json", function(data, textStatus, jqXHR) {
        const currentFilePath = "notebooks/understanding/models.html";
        let btn = document.getElementById("version_switcher_button");
        // Set empty strings by default so that these attributes exist and can be used in CSS selectors
        btn.dataset["activeVersionName"] = "";
        btn.dataset["activeVersion"] = "";
        // create links to the corresponding page in the other docs versions
        $.each(data, function(index, entry) {
            // if no custom name specified (e.g., "latest"), use version string
            if (!("name" in entry)) {
                entry.name = entry.version;
            }
            // create the node
            const node = document.createElement("a");
            node.setAttribute("class", "list-group-item list-group-item-action py-1");
            node.textContent = `${entry.name}`;
            node.setAttribute("href", `${entry.url}${currentFilePath}`);
            // on click, AJAX calls will check if the linked page exists before
            // trying to redirect, and if not, will redirect to the homepage
            // for that version of the docs.
            node.onclick = checkPageExistsAndRedirect;
            // Add dataset values for the version and name in case people want
            // to apply CSS styling based on this information.
            node.dataset["versionName"] = entry.name;
            node.dataset["version"] = entry.version;

            $("#version_switcher_menu").append(node);
            // replace dropdown button text with the preferred display name of
            // this version, rather than using sphinx's  variable.
            // also highlight the dropdown entry for the currently-viewed
            // version's entry
            if (entry.version == "develop") {
                node.classList.add("active");
                btn.innerText = btn.dataset["activeVersionName"] = entry.name;
                btn.dataset["activeVersion"] = entry.version;
            }
        });
    });
})();
</script>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../basics/GPLVM.html">
   Bayesian Gaussian process latent variable model (Bayesian GPLVM)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basics/classification.html">
   Basic (binary) GP classification model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basics/monitoring.html">
   Monitoring Optimisation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../basics/regression.html">
   Basic (Gaussian likelihood) GP regression model
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/changepoints.html">
   Change points
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/convolutional.html">
   Convolutional Gaussian Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/coregionalisation.html">
   A simple demonstration of coregionalization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/fast_predictions.html">
   Faster predictions by caching
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/gps_for_big_data.html">
   Stochastic Variational Inference for scalability with SVGP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/heteroskedastic.html">
   Heteroskedastic Likelihood and Multi-Latent GP
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/kernels.html">
   Manipulating kernels
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/mcmc.html">
   MCMC (Markov Chain Monte Carlo)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/multiclass_classification.html">
   Multiclass classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/multioutput.html">
   Multi-output Gaussian processes in GPflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/natural_gradients.html">
   Natural gradients
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/ordinal_regression.html">
   Ordinal regression
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/variational_fourier_features.html">
   Variational Fourier Features in the GPflow framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../advanced/varying_noise.html">
   Gaussian process regression with varying output noise
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/external-mean-function.html">
   Custom mean functions: metalearning with GPs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/gp_nn.html">
   Mixing TensorFlow models with GPflow
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/kernel_design.html">
   Kernel Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../tailor/mixture_density_network.html">
   Mixture Density Networks in GPflow
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/FITCvsVFE.html">
   Comparing FITC approximation to VFE approximation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/SGPR_notes.html">
   Derivation of SGPR equations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/Sanity_check.html">
   Sanity checking when model behaviours should overlap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/cglb.html">
   Conjugate Gradient Lower Bound
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/upper_bound.html">
   Discussion of the GP marginal likelihood upper bound
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../theory/vgp_notes.html">
   Derivation of VGP equations
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Manipulating GPflow models
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Viewing,-getting,-and-setting-parameters">
   Viewing, getting, and setting parameters
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Constraints-and-trainable-variables">
   Constraints and trainable variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Changing-whether-a-parameter-will-be-trained-in-optimization">
   Changing whether a parameter will be trained in optimization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Priors">
   Priors
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Optimization">
   Optimization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#Building-new-models">
   Building new models
  </a>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<section id="Manipulating-GPflow-models">
<h1>Manipulating GPflow models<a class="headerlink" href="#Manipulating-GPflow-models" title="Permalink to this heading">#</a></h1>
<p>One of the key ingredients in GPflow is the model class, which enables you to carefully control parameters. This notebook shows how some of these parameter control features work, and how to build your own model with GPflow. First we’ll look at:</p>
<ul class="simple">
<li><p>how to view models and parameters</p></li>
<li><p>how to set parameter values</p></li>
<li><p>how to constrain parameters (for example, variance &gt; 0)</p></li>
<li><p>how to fix model parameters</p></li>
<li><p>how to apply priors to parameters</p></li>
<li><p>how to optimize models</p></li>
</ul>
<p>Then we’ll show how to build a simple logistic regression model, demonstrating the ease of the parameter framework.</p>
<p>GPy users should feel right at home, but there are some small differences.</p>
<p>First, let’s deal with the usual notebook boilerplate and make a simple GP regression model. See <a class="reference internal" href="../basics/regression.html"><span class="doc">Basic (Gaussian likelihood) GP regression model</span></a> for specifics of the model; we just want some parameters to play with.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">gpflow</span>
<span class="kn">import</span> <span class="nn">tensorflow_probability</span> <span class="k">as</span> <span class="nn">tfp</span>
<span class="kn">from</span> <span class="nn">gpflow.utilities</span> <span class="kn">import</span> <span class="n">print_summary</span><span class="p">,</span> <span class="n">set_trainable</span><span class="p">,</span> <span class="n">to_default_float</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-07-20 13:44:09.220979: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-07-20 13:44:09.221005: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You&#39;re calling gpflow.experimental.check_shapes.decorator.check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.
  warn(
/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You&#39;re calling gpflow.experimental.check_shapes.inheritance.inherit_check_shapes which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.
  warn(
</pre></div></div>
</div>
<p>We begin by creating a very simple GP regression model:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># generate toy data</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">12</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.66</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">25</span> <span class="o">*</span> <span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">GPR</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">),</span> <span class="n">kernel</span><span class="o">=</span><span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Matern32</span><span class="p">()</span> <span class="o">+</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Linear</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/circleci/project/gpflow/experimental/utils.py:42: UserWarning: You&#39;re calling gpflow.experimental.check_shapes.checker.ShapeChecker.__init__ which is considered *experimental*. Expect: breaking changes, poor documentation, and bugs.
  warn(
2022-07-20 13:44:12.198681: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcuda.so.1&#39;; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-07-20 13:44:12.198713: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-07-20 13:44:12.198733: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (743ae1591448): /proc/driver/nvidia/version does not exist
2022-07-20 13:44:12.198982: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</pre></div></div>
</div>
<section id="Viewing,-getting,-and-setting-parameters">
<h2>Viewing, getting, and setting parameters<a class="headerlink" href="#Viewing,-getting,-and-setting-parameters" title="Permalink to this heading">#</a></h2>
<p>You can display the state of the model in a terminal by using <code class="docutils literal notranslate"><span class="pre">print_summary(m)</span></code>. You can change the display format using the <code class="docutils literal notranslate"><span class="pre">fmt</span></code> keyword argument, e.g. <code class="docutils literal notranslate"><span class="pre">'html'</span></code>. In a notebook, you can also use <code class="docutils literal notranslate"><span class="pre">fmt='notebook'</span></code> or set the default printing format as <code class="docutils literal notranslate"><span class="pre">notebook</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                              </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>GPR.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">      1</td></tr>
<tr><td>GPR.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">      1</td></tr>
<tr><td>GPR.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">      1</td></tr>
<tr><td>GPR.likelihood.variance           </td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">      1</td></tr>
</tbody>
</table></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpflow</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">set_default_summary_fmt</span><span class="p">(</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>This model has four parameters. The kernel is made of the sum of two parts. The first (counting from zero) is a Matern32 kernel that has a variance parameter and a lengthscales parameter; the second is a linear kernel that has only a variance parameter. There is also a parameter that controls the variance of the noise, as part of the likelihood.</p>
<p>All the model variables have been initialized at <code class="docutils literal notranslate"><span class="pre">1.0</span></code>. You can access individual parameters in the same way that you display the state of the model in a terminal; for example, to see all the parameters that are part of the likelihood, run:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">likelihood</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name             </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>Gaussian.variance</td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">      1</td></tr>
</tbody>
</table></div>
</div>
<p>This gets more useful with more complex models!</p>
<p>To set the value of a parameter, just use <code class="docutils literal notranslate"><span class="pre">assign()</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lengthscales</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">likelihood</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                              </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>GPR.kernel.kernels[0].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.5 </td></tr>
<tr><td>GPR.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.likelihood.variance           </td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.01</td></tr>
</tbody>
</table></div>
</div>
</section>
<section id="Constraints-and-trainable-variables">
<h2>Constraints and trainable variables<a class="headerlink" href="#Constraints-and-trainable-variables" title="Permalink to this heading">#</a></h2>
<p>GPflow helpfully creates an unconstrained representation of all the variables. In the previous example, all the variables are constrained positively (see the <strong>transform</strong> column in the table); the unconstrained representation is given by <span class="math notranslate nohighlight">\(\alpha = \log(\exp(\theta)-1)\)</span>. The <code class="docutils literal notranslate"><span class="pre">trainable_parameters</span></code> property returns the constrained values:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">trainable_parameters</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(&lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=0.5&gt;,
 &lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=1.0&gt;,
 &lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;softplus&#34;, numpy=1.0&gt;,
 &lt;Parameter: name=chain_of_shift_of_softplus, dtype=float64, shape=[], fn=&#34;chain_of_shift_of_softplus&#34;, numpy=0.009999999999999998&gt;)
</pre></div></div>
</div>
<p>Each parameter has an <code class="docutils literal notranslate"><span class="pre">unconstrained_variable</span></code> attribute that enables you to access the unconstrained value as a TensorFlow <code class="docutils literal notranslate"><span class="pre">Variable</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lengthscales</span>
<span class="n">p</span><span class="o">.</span><span class="n">unconstrained_variable</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Variable &#39;softplus:0&#39; shape=() dtype=float64, numpy=-0.43275212956718856&gt;
</pre></div></div>
</div>
<p>You can also check the unconstrained value as follows:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Tensor: shape=(), dtype=float64, numpy=-0.43275212956718856&gt;
</pre></div></div>
</div>
<p>Constraints are handled by the Bijector classes from the <code class="docutils literal notranslate"><span class="pre">tensorflow_probability</span></code> package. You might prefer to use the constraint <span class="math notranslate nohighlight">\(\alpha = \log(\theta)\)</span>; this is easily done by replacing the parameter with one that has a different <code class="docutils literal notranslate"><span class="pre">transform</span></code> attribute (here we make sure to copy all other attributes across from the old parameter; this is not necessary when there is no <code class="docutils literal notranslate"><span class="pre">prior</span></code> and the <code class="docutils literal notranslate"><span class="pre">trainable</span></code> state is still the default of <code class="docutils literal notranslate"><span class="pre">True</span></code>):</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">old_parameter</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lengthscales</span>
<span class="n">new_parameter</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
    <span class="n">old_parameter</span><span class="p">,</span>
    <span class="n">trainable</span><span class="o">=</span><span class="n">old_parameter</span><span class="o">.</span><span class="n">trainable</span><span class="p">,</span>
    <span class="n">prior</span><span class="o">=</span><span class="n">old_parameter</span><span class="o">.</span><span class="n">prior</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="n">old_parameter</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;:&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span>  <span class="c1"># tensorflow is weird and adds &#39;:0&#39; to the name</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">tfp</span><span class="o">.</span><span class="n">bijectors</span><span class="o">.</span><span class="n">Exp</span><span class="p">(),</span>
<span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lengthscales</span> <span class="o">=</span> <span class="n">new_parameter</span>
</pre></div>
</div>
</div>
<p>Though the lengthscale itself remains the same, the unconstrained lengthscale has changed:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;tf.Tensor: shape=(), dtype=float64, numpy=-0.43275212956718856&gt;
</pre></div></div>
</div>
<p>To replace the <code class="docutils literal notranslate"><span class="pre">transform</span></code> of a parameter you need to recreate the parameter with updated transform:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">variance</span>
<span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">variance</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">transform</span><span class="o">=</span><span class="n">tfp</span><span class="o">.</span><span class="n">bijectors</span><span class="o">.</span><span class="n">Exp</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s2">&quot;notebook&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                              </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>GPR.kernel.kernels[0].variance    </td><td>Parameter</td><td>Exp             </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Exp             </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.5 </td></tr>
<tr><td>GPR.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.likelihood.variance           </td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.01</td></tr>
</tbody>
</table></div>
</div>
</section>
<section id="Changing-whether-a-parameter-will-be-trained-in-optimization">
<h2>Changing whether a parameter will be trained in optimization<a class="headerlink" href="#Changing-whether-a-parameter-will-be-trained-in-optimization" title="Permalink to this heading">#</a></h2>
<p>Another helpful feature is the ability to fix parameters. To do this, simply set the <code class="docutils literal notranslate"><span class="pre">trainable</span></code> attribute to <code class="docutils literal notranslate"><span class="pre">False</span></code>; this is shown in the <strong>trainable</strong> column of the representation, and the corresponding variable is removed from the free state.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_trainable</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">variance</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                              </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>GPR.kernel.kernels[0].variance    </td><td>Parameter</td><td>Exp             </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Exp             </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.5 </td></tr>
<tr><td>GPR.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>False      </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.likelihood.variance           </td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.01</td></tr>
</tbody>
</table></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">trainable_parameters</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(&lt;Parameter: name=softplus, dtype=float64, shape=[], fn=&#34;exp&#34;, numpy=0.5&gt;,
 &lt;Parameter: name=exp, dtype=float64, shape=[], fn=&#34;exp&#34;, numpy=1.0&gt;,
 &lt;Parameter: name=chain_of_shift_of_softplus, dtype=float64, shape=[], fn=&#34;chain_of_shift_of_softplus&#34;, numpy=0.009999999999999998&gt;)
</pre></div></div>
</div>
<p>To unfix a parameter, just set the <code class="docutils literal notranslate"><span class="pre">trainable</span></code> attribute to <code class="docutils literal notranslate"><span class="pre">True</span></code> again.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_trainable</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">variance</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                              </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>GPR.kernel.kernels[0].variance    </td><td>Parameter</td><td>Exp             </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Exp             </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.5 </td></tr>
<tr><td>GPR.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.likelihood.variance           </td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.01</td></tr>
</tbody>
</table></div>
</div>
<p><strong>NOTE:</strong> If you want to recursively change the <code class="docutils literal notranslate"><span class="pre">trainable</span></code> status of an object that <em>contains</em> parameters, you <strong>must</strong> use the <code class="docutils literal notranslate"><span class="pre">set_trainable()</span></code> utility function.</p>
<p>A module (e.g. a model, kernel, likelihood, … instance) does not have a <code class="docutils literal notranslate"><span class="pre">trainable</span></code> attribute:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">trainable</span>
<span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> does not have a trainable attribute&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sum does not have a trainable attribute
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_trainable</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                              </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>GPR.kernel.kernels[0].variance    </td><td>Parameter</td><td>Exp             </td><td>       </td><td>False      </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Exp             </td><td>       </td><td>False      </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.5 </td></tr>
<tr><td>GPR.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>False      </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.likelihood.variance           </td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.01</td></tr>
</tbody>
</table></div>
</div>
</section>
<section id="Priors">
<h2>Priors<a class="headerlink" href="#Priors" title="Permalink to this heading">#</a></h2>
<p>You can set priors in the same way as transforms and trainability, by using <code class="docutils literal notranslate"><span class="pre">tensorflow_probability</span></code> distribution objects. Let’s set a Gamma prior on the variance of the Matern32 kernel.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">kernels</span><span class="o">.</span><span class="n">Matern32</span><span class="p">()</span>
<span class="n">k</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span><span class="n">to_default_float</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">to_default_float</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>

<span class="n">print_summary</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                 </th><th>class    </th><th>transform  </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>Matern32.variance    </td><td>Parameter</td><td>Softplus   </td><td>Gamma  </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">      1</td></tr>
<tr><td>Matern32.lengthscales</td><td>Parameter</td><td>Softplus   </td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">      1</td></tr>
</tbody>
</table></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span><span class="o">.</span><span class="n">kernel</span><span class="o">.</span><span class="n">kernels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">variance</span><span class="o">.</span><span class="n">prior</span> <span class="o">=</span> <span class="n">tfp</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Gamma</span><span class="p">(</span>
    <span class="n">to_default_float</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">to_default_float</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">print_summary</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table>
<thead>
<tr><th>name                              </th><th>class    </th><th>transform       </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th style="text-align: right;">  value</th></tr>
</thead>
<tbody>
<tr><td>GPR.kernel.kernels[0].variance    </td><td>Parameter</td><td>Exp             </td><td>Gamma  </td><td>False      </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.kernel.kernels[0].lengthscales</td><td>Parameter</td><td>Exp             </td><td>       </td><td>False      </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.5 </td></tr>
<tr><td>GPR.kernel.kernels[1].variance    </td><td>Parameter</td><td>Softplus        </td><td>       </td><td>False      </td><td>()     </td><td>float64</td><td style="text-align: right;">   1   </td></tr>
<tr><td>GPR.likelihood.variance           </td><td>Parameter</td><td>Softplus + Shift</td><td>       </td><td>True       </td><td>()     </td><td>float64</td><td style="text-align: right;">   0.01</td></tr>
</tbody>
</table></div>
</div>
</section>
<section id="Optimization">
<h2>Optimization<a class="headerlink" href="#Optimization" title="Permalink to this heading">#</a></h2>
<p>To optimize your model, first create an instance of an optimizer (in this case, <code class="docutils literal notranslate"><span class="pre">gpflow.optimizers.Scipy</span></code>), which has optional arguments that are passed to <code class="docutils literal notranslate"><span class="pre">scipy.optimize.minimize</span></code> (we minimize the negative log likelihood). Then, call the <code class="docutils literal notranslate"><span class="pre">minimize</span></code> method of that optimizer, with your model as the optimization target. Variables that have priors are maximum a priori (MAP) estimated, that is, we add the log prior to the log likelihood, and otherwise use Maximum Likelihood.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>
<span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span> <span class="n">variables</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
      fun: 27.184339014098022
 hess_inv: &lt;1x1 LbfgsInvHessProduct with dtype=float64&gt;
      jac: array([-1.02640284e-06])
  message: &#39;CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL&#39;
     nfev: 8
      nit: 7
     njev: 8
   status: 0
  success: True
        x: array([-0.36990459])
</pre></div></div>
</div>
</section>
<section id="Building-new-models">
<h2>Building new models<a class="headerlink" href="#Building-new-models" title="Permalink to this heading">#</a></h2>
<p>To build new models, you’ll need to inherit from <code class="docutils literal notranslate"><span class="pre">gpflow.models.BayesianModel</span></code>. Parameters are instantiated with <code class="docutils literal notranslate"><span class="pre">gpflow.Parameter</span></code>. You might also be interested in <code class="docutils literal notranslate"><span class="pre">gpflow.Module</span></code> (a subclass of <code class="docutils literal notranslate"><span class="pre">tf.Module</span></code>), which acts as a ‘container’ for <code class="docutils literal notranslate"><span class="pre">Parameter</span></code>s (for example, kernels are <code class="docutils literal notranslate"><span class="pre">gpflow.Module</span></code>s).</p>
<p>In this very simple demo, we’ll implement linear multiclass classification.</p>
<p>There are two parameters: a weight matrix and a bias (offset). You can use Parameter objects directly, like any TensorFlow tensor.</p>
<p>The training objective depends on the type of model; it may be possible to implement the exact (log)marginal likelihood, or only a lower bound to the log marginal likelihood (ELBO). You need to implement this as the <code class="docutils literal notranslate"><span class="pre">maximum_log_likelihood_objective</span></code> method. The <code class="docutils literal notranslate"><span class="pre">BayesianModel</span></code> parent class provides a <code class="docutils literal notranslate"><span class="pre">log_posterior_density</span></code> method that returns the <code class="docutils literal notranslate"><span class="pre">maximum_log_likelihood_objective</span></code> plus the sum of the log-density of any priors on hyperparameters, which can be used for MCMC. GPflow
provides mixin classes that define a <code class="docutils literal notranslate"><span class="pre">training_loss</span></code> method that returns the negative of (maximum likelihood objective + log prior density) for MLE/MAP estimation to be passed to optimizer’s <code class="docutils literal notranslate"><span class="pre">minimize</span></code> method. Models that derive from <code class="docutils literal notranslate"><span class="pre">InternalDataTrainingLossMixin</span></code> are expected to store the data internally, and their <code class="docutils literal notranslate"><span class="pre">training_loss</span></code> does not take any arguments and can be passed directly to <code class="docutils literal notranslate"><span class="pre">minimize</span></code>. Models that take data as an argument to their <code class="docutils literal notranslate"><span class="pre">maximum_log_likelihood_objective</span></code>
method derive from <code class="docutils literal notranslate"><span class="pre">ExternalDataTrainingLossMixin</span></code>, which provides a <code class="docutils literal notranslate"><span class="pre">training_loss_closure</span></code> to take the data and return the appropriate closure for <code class="docutils literal notranslate"><span class="pre">optimizer.minimize</span></code>. This is also discussed in the <a class="reference internal" href="../intro_to_gpflow2.html"><span class="doc">GPflow with TensorFlow 2 notebook</span></a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>


<span class="k">class</span> <span class="nc">LinearMulticlass</span><span class="p">(</span><span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">BayesianModel</span><span class="p">,</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">InternalDataTrainingLossMixin</span><span class="p">):</span>
    <span class="c1"># The InternalDataTrainingLossMixin provides the training_loss method.</span>
    <span class="c1"># (There is also an ExternalDataTrainingLossMixin for models that do not encapsulate data.)</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>  <span class="c1"># always call the parent constructor</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># X is a NumPy array of inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>  <span class="c1"># Y is a 1-of-k (one-hot) representation of the labels</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">num_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># make some parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_classes</span><span class="p">))</span>

        <span class="c1"># ^^ You must make the parameters attributes of the class for</span>
        <span class="c1"># them to be picked up by the model. i.e. this won&#39;t work:</span>
        <span class="c1">#</span>
        <span class="c1"># W = gpflow.Parameter(...    &lt;-- must be self.W</span>

    <span class="k">def</span> <span class="nf">maximum_log_likelihood_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b</span>
        <span class="p">)</span>  <span class="c1"># Parameters can be used like a tf.Tensor</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">)</span>  <span class="c1"># be sure to return a scalar</span>
</pre></div>
</div>
</div>
<p>…and that’s it. Let’s build a really simple demo to show that it works.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">123</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;ggplot&quot;</span><span class="p">)</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_understanding_models_41_0.png" src="../../_images/notebooks_understanding_models_41_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="n">LinearMulticlass</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">m</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
&lt;__main__.LinearMulticlass object at 0x7f390049e140&gt;
<table>
<thead>
<tr><th>name              </th><th>class    </th><th>transform  </th><th>prior  </th><th>trainable  </th><th>shape  </th><th>dtype  </th><th>value                          </th></tr>
</thead>
<tbody>
<tr><td>LinearMulticlass.W</td><td>Parameter</td><td>Identity   </td><td>       </td><td>True       </td><td>(2, 3) </td><td>float64</td><td>[[-0.77271, 0.79486, 0.31427...</td></tr>
<tr><td>LinearMulticlass.b</td><td>Parameter</td><td>Identity   </td><td>       </td><td>True       </td><td>(3,)   </td><td>float64</td><td>[ 0.04549 -0.23309 -1.1983 ]   </td></tr>
</tbody>
</table></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">opt</span> <span class="o">=</span> <span class="n">gpflow</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Scipy</span><span class="p">()</span>
<span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">training_loss</span><span class="p">,</span> <span class="n">variables</span><span class="o">=</span><span class="n">m</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
      fun: 1.2560984620758726e-05
 hess_inv: &lt;9x9 LbfgsInvHessProduct with dtype=float64&gt;
      jac: array([ 4.28392990e-06,  1.15665823e-06, -5.44058813e-06, -2.77570188e-06,
        2.97110223e-06, -1.95400347e-07, -8.81900274e-07,  2.52856127e-06,
       -1.64666099e-06])
  message: &#39;CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_&lt;=_PGTOL&#39;
     nfev: 27
      nit: 26
     njev: 27
   status: 0
  success: True
        x: array([  8.55849743, -30.63655328,  22.4144818 ,  23.79332963,
        21.27896803, -44.17402754,  11.85784428, -12.94743432,
        -0.29631308])
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mgrid</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:</span><span class="mi">4</span><span class="p">:</span><span class="mi">200</span><span class="n">j</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">:</span><span class="mi">4</span><span class="p">:</span><span class="mi">200</span><span class="n">j</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">xx</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">flatten</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>
<span class="n">f_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">W</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="o">+</span> <span class="n">m</span><span class="o">.</span><span class="n">b</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">p_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">f_test</span><span class="p">)</span>
<span class="n">p_test</span> <span class="o">/=</span> <span class="n">p_test</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">p_test</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">200</span><span class="p">),</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">],</span> <span class="n">colors</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linewidths</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="mi">100</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_understanding_models_45_0.png" src="../../_images/notebooks_understanding_models_45_0.png" />
</div>
</div>
<p>That concludes the new model example and this notebook. You might want to see for yourself that the <code class="docutils literal notranslate"><span class="pre">LinearMulticlass</span></code> model and its parameters have all the functionality demonstrated here. You could also add some priors and run Hamiltonian Monte Carlo using the HMC optimizer <code class="docutils literal notranslate"><span class="pre">gpflow.train.HMC</span></code> and its <code class="docutils literal notranslate"><span class="pre">sample</span></code> method. See <a class="reference internal" href="../advanced/mcmc.html"><span class="doc">Markov Chain Monte Carlo (MCMC)</span></a> for more information on running the sampler.</p>
</section>
</section>


              </article>
              

              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2022, The GPflow Contributors.<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 5.0.2.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>